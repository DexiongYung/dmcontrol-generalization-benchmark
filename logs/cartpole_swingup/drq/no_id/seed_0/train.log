{"episode_reward": 0.0, "episode": 1.0, "duration": 2.1876115798950195, "step": 125}
{"episode_reward": 180.47110058644063, "episode": 2.0, "duration": 0.29920530319213867, "step": 250}
{"episode_reward": 48.52626484966922, "episode": 3.0, "duration": 0.28913116455078125, "step": 375}
{"episode_reward": 106.030169546403, "episode": 4.0, "duration": 0.2857046127319336, "step": 500}
{"episode_reward": 153.95059426464144, "episode": 5.0, "duration": 0.29990100860595703, "step": 625}
{"episode_reward": 59.72123608737102, "episode": 6.0, "duration": 0.2823207378387451, "step": 750}
{"episode_reward": 108.39820293463187, "episode": 7.0, "duration": 0.28784966468811035, "step": 875}
{"episode_reward": 66.9949003284935, "episode": 8.0, "duration": 0.2892749309539795, "step": 1000}
{"episode_reward": 211.25384590482398, "episode": 9.0, "critic_loss": 9.997184758508757, "critic_target_Q_variance_m=2": 14.497556470440587, "critic_Q1_variance_k=2": 0.29089491156407454, "critic_Q2_variance_k=2": 0.2911612052874238, "actor_loss": -5.789738542840531, "actor_mean_entropy": 1.1845111532624384, "alpha_loss": 0.11924158008997161, "alpha_value": 0.09533303571820786, "duration": 319.1063811779022, "step": 1125}
{"episode_reward": 160.39489955698747, "episode": 10.0, "critic_loss": 14.165562446594238, "critic_target_Q_variance_m=2": 36.04900804138184, "critic_Q1_variance_k=2": 0.4757903101444244, "critic_Q2_variance_k=2": 0.47458919072151184, "actor_loss": -10.714345608988117, "actor_mean_entropy": 1.1035049500003937, "alpha_loss": 0.08020207892742849, "alpha_value": 0.09110272062139915, "duration": 34.79624819755554, "step": 1250}
{"episode_reward": 149.08592689152394, "episode": 11.0, "critic_loss": 12.42209432220459, "critic_target_Q_variance_m=2": 38.986554214477536, "critic_Q1_variance_k=2": 0.4542358226776123, "critic_Q2_variance_k=2": 0.45405174815654753, "actor_loss": -11.301038030594114, "actor_mean_entropy": 1.05250093388179, "alpha_loss": 0.08225052496270528, "alpha_value": 0.09069540137795414, "duration": 34.65989136695862, "step": 1375}
{"episode_reward": 180.74257799478602, "episode": 12.0, "critic_loss": 17.05177293395996, "critic_target_Q_variance_m=2": 45.99962078857422, "critic_Q1_variance_k=2": 0.559118700504303, "critic_Q2_variance_k=2": 0.5576131312847138, "actor_loss": -12.238863422024634, "actor_mean_entropy": 0.9928973644010483, "alpha_loss": 0.08375647682095727, "alpha_value": 0.09027489138906174, "duration": 34.84343242645264, "step": 1500}
{"episode_reward": 242.8334506882569, "episode": 13.0, "critic_loss": 15.858837524414062, "critic_target_Q_variance_m=2": 51.05226516723633, "critic_Q1_variance_k=2": 0.492115709066391, "critic_Q2_variance_k=2": 0.4925980715751648, "actor_loss": -13.049054085262238, "actor_mean_entropy": 0.8937826468831017, "alpha_loss": 0.08467134555417394, "alpha_value": 0.08984053940055427, "duration": 35.087477684020996, "step": 1625}
{"episode_reward": 229.35454862695863, "episode": 14.0, "critic_loss": 15.43270336151123, "critic_target_Q_variance_m=2": 57.07592950439453, "critic_Q1_variance_k=2": 0.4832355319261551, "critic_Q2_variance_k=2": 0.4819772948026657, "actor_loss": -13.86356698313067, "actor_mean_entropy": 0.7445093907656208, "alpha_loss": 0.08209535022897105, "alpha_value": 0.08940188282070854, "duration": 34.713422775268555, "step": 1750}
{"episode_reward": 206.82014706308263, "episode": 15.0, "critic_loss": 15.946615737915039, "critic_target_Q_variance_m=2": 63.630554290771485, "critic_Q1_variance_k=2": 0.47127266907691956, "critic_Q2_variance_k=2": 0.47301825165748596, "actor_loss": -14.941386919172983, "actor_mean_entropy": 0.7469518605678801, "alpha_loss": 0.07504382971969861, "alpha_value": 0.08898312436698114, "duration": 34.76644945144653, "step": 1875}
{"episode_reward": 211.9140380443002, "episode": 16.0, "critic_loss": 19.175246505737306, "critic_target_Q_variance_m=2": 72.16960656738281, "critic_Q1_variance_k=2": 0.5451989079713822, "critic_Q2_variance_k=2": 0.5442464413642883, "actor_loss": -15.96599277373283, "actor_mean_entropy": 0.7097107734410993, "alpha_loss": 0.06476084281119608, "alpha_value": 0.08860482848378856, "duration": 34.85097312927246, "step": 2000}
{"episode_reward": 281.4616865047378, "episode": 17.0, "critic_loss": 18.040505500793458, "critic_target_Q_variance_m=2": 82.79826727294922, "critic_Q1_variance_k=2": 0.526442451953888, "critic_Q2_variance_k=2": 0.5251387834548951, "actor_loss": -17.020952027941508, "actor_mean_entropy": 0.6686738407801068, "alpha_loss": 0.056017882678480374, "alpha_value": 0.08828448136498288, "duration": 34.74730038642883, "step": 2125}
{"episode_reward": 300.19607595172204, "episode": 18.0, "critic_loss": 22.034252922058105, "critic_target_Q_variance_m=2": 93.6727163696289, "critic_Q1_variance_k=2": 0.6358490271568298, "critic_Q2_variance_k=2": 0.6324158685207367, "actor_loss": -18.09354385252922, "actor_mean_entropy": 0.6378312283946622, "alpha_loss": 0.04754237022491232, "alpha_value": 0.08800098999338225, "duration": 34.89666724205017, "step": 2250}
{"episode_reward": 188.47553488821933, "episode": 19.0, "critic_loss": 20.38782783508301, "critic_target_Q_variance_m=2": 101.38308166503906, "critic_Q1_variance_k=2": 0.5676043204069138, "critic_Q2_variance_k=2": 0.5688292896747589, "actor_loss": -19.010480608258927, "actor_mean_entropy": 0.6414018817364223, "alpha_loss": 0.04444607446295402, "alpha_value": 0.08773121402161148, "duration": 35.298187255859375, "step": 2375}
{"episode_reward": 216.36695100858256, "episode": 20.0, "critic_loss": 20.303060569763183, "critic_target_Q_variance_m=2": 107.35400451660156, "critic_Q1_variance_k=2": 0.5814713408946991, "critic_Q2_variance_k=2": 0.5837778565883637, "actor_loss": -19.506818217615926, "actor_mean_entropy": 0.6537806507079832, "alpha_loss": 0.04054471492887505, "alpha_value": 0.08747813727106227, "duration": 34.24011993408203, "step": 2500}
{"episode_reward": 202.43114354777703, "episode": 21.0, "critic_loss": 23.198819244384765, "critic_target_Q_variance_m=2": 118.7132872314453, "critic_Q1_variance_k=2": 0.674395269036293, "critic_Q2_variance_k=2": 0.6692417874336243, "actor_loss": -20.713802216544984, "actor_mean_entropy": 0.6265143501380134, "alpha_loss": 0.04300775495727384, "alpha_value": 0.0872274661231636, "duration": 35.62615466117859, "step": 2625}
{"episode_reward": 231.92935156794266, "episode": 22.0, "critic_loss": 29.881205757141114, "critic_target_Q_variance_m=2": 131.74790716552735, "critic_Q1_variance_k=2": 0.814282113313675, "critic_Q2_variance_k=2": 0.8179935185909272, "actor_loss": -21.739113623096095, "actor_mean_entropy": 0.5845420735497628, "alpha_loss": 0.04124096546682619, "alpha_value": 0.08696384648802417, "duration": 34.6204149723053, "step": 2750}
{"episode_reward": 260.201232718894, "episode": 23.0, "critic_loss": 32.06123806762695, "critic_target_Q_variance_m=2": 147.23426977539063, "critic_Q1_variance_k=2": 0.8848041715621948, "critic_Q2_variance_k=2": 0.8820786263942718, "actor_loss": -22.937661640227788, "actor_mean_entropy": 0.5644234700335397, "alpha_loss": 0.031750090131979616, "alpha_value": 0.08673155863261592, "duration": 34.88485503196716, "step": 2875}
{"episode_reward": 283.9468042412285, "episode": 24.0, "critic_loss": 30.177665817260742, "critic_target_Q_variance_m=2": 160.68030749511718, "critic_Q1_variance_k=2": 0.9008014154434204, "critic_Q2_variance_k=2": 0.9048433926105499, "actor_loss": -24.06917292071927, "actor_mean_entropy": 0.4981217865020998, "alpha_loss": 0.03093371097178709, "alpha_value": 0.08653020655153604, "duration": 34.6210081577301, "step": 3000}
{"episode_reward": 282.21567636286767, "episode": 25.0, "critic_loss": 30.66883769226074, "critic_target_Q_variance_m=2": 172.6167919921875, "critic_Q1_variance_k=2": 0.9074707746505737, "critic_Q2_variance_k=2": 0.9128017802238464, "actor_loss": -25.153039266192724, "actor_mean_entropy": 0.4579172084728877, "alpha_loss": 0.026200572235716715, "alpha_value": 0.08632144979346683, "duration": 35.177122831344604, "step": 3125}
{"episode_reward": 366.8649987527494, "episode": 26.0, "critic_loss": 47.047538146972656, "critic_target_Q_variance_m=2": 196.63294580078124, "critic_Q1_variance_k=2": 1.2198463406562805, "critic_Q2_variance_k=2": 1.216813359260559, "actor_loss": -26.635926800389445, "actor_mean_entropy": 0.4783112983549795, "alpha_loss": 0.0235458014930989, "alpha_value": 0.08615629161658375, "duration": 34.57536244392395, "step": 3250}
{"episode_reward": 244.29442882276044, "episode": 27.0, "critic_loss": 35.88763830566406, "critic_target_Q_variance_m=2": 206.814607421875, "critic_Q1_variance_k=2": 1.0844904460906983, "critic_Q2_variance_k=2": 1.0833874521255493, "actor_loss": -27.38402817741273, "actor_mean_entropy": 0.4369169681791275, "alpha_loss": 0.01933320824219476, "alpha_value": 0.08601143300323379, "duration": 34.78635334968567, "step": 3375}
{"episode_reward": 232.995452257285, "episode": 28.0, "critic_loss": 34.15962902832031, "critic_target_Q_variance_m=2": 222.27619567871093, "critic_Q1_variance_k=2": 1.0643309988975524, "critic_Q2_variance_k=2": 1.0672525362968446, "actor_loss": -28.61255012019988, "actor_mean_entropy": 0.3637201363040555, "alpha_loss": 0.019063515892823138, "alpha_value": 0.08586672973388716, "duration": 34.703651428222656, "step": 3500}
{"episode_reward": 274.4918868010651, "episode": 29.0, "critic_loss": 35.60351068115234, "critic_target_Q_variance_m=2": 239.6345909423828, "critic_Q1_variance_k=2": 1.1155939321517945, "critic_Q2_variance_k=2": 1.1224623551368713, "actor_loss": -29.603713989257812, "actor_mean_entropy": 0.42322456860353075, "alpha_loss": 0.017512533939369614, "alpha_value": 0.08572063708329221, "duration": 34.831164836883545, "step": 3625}
{"episode_reward": 283.9098477123428, "episode": 30.0, "critic_loss": 34.341627090454104, "critic_target_Q_variance_m=2": 256.043927734375, "critic_Q1_variance_k=2": 1.0655682439804077, "critic_Q2_variance_k=2": 1.069676393032074, "actor_loss": -30.618299791889807, "actor_mean_entropy": 0.4012629579632513, "alpha_loss": 0.015097884342990696, "alpha_value": 0.08560621940078025, "duration": 34.62284278869629, "step": 3750}
{"episode_reward": 338.99352358700037, "episode": 31.0, "critic_loss": 39.22650932312012, "critic_target_Q_variance_m=2": 280.1808843994141, "critic_Q1_variance_k=2": 1.162070810317993, "critic_Q2_variance_k=2": 1.174500997543335, "actor_loss": -32.19275883265904, "actor_mean_entropy": 0.37491484080988263, "alpha_loss": 0.01286752983402934, "alpha_value": 0.08547869400664815, "duration": 34.73219656944275, "step": 3875}
{"episode_reward": 248.60667829895257, "episode": 32.0, "critic_loss": 37.12922509765625, "critic_target_Q_variance_m=2": 296.40386474609375, "critic_Q1_variance_k=2": 1.134249029159546, "critic_Q2_variance_k=2": 1.1402051949501038, "actor_loss": -33.13028917004985, "actor_mean_entropy": 0.4075038380199863, "alpha_loss": 0.012832257819677433, "alpha_value": 0.0853880555357101, "duration": 34.43302869796753, "step": 4000}
{"episode_reward": 258.4808723446924, "episode": 33.0, "critic_loss": 38.68976988220215, "critic_target_Q_variance_m=2": 315.8083493652344, "critic_Q1_variance_k=2": 1.1793449745178222, "critic_Q2_variance_k=2": 1.1817199177742004, "actor_loss": -34.147530116732156, "actor_mean_entropy": 0.35125753851163954, "alpha_loss": 0.011314435425909266, "alpha_value": 0.08527330030327976, "duration": 34.75394868850708, "step": 4125}
{"episode_reward": 245.4270677194614, "episode": 34.0, "critic_loss": 37.71400210571289, "critic_target_Q_variance_m=2": 338.6092548828125, "critic_Q1_variance_k=2": 1.1695460481643676, "critic_Q2_variance_k=2": 1.1848990392684937, "actor_loss": -35.49722203900737, "actor_mean_entropy": 0.28393819189119723, "alpha_loss": 0.005073798232666788, "alpha_value": 0.0851934834901776, "duration": 34.34006690979004, "step": 4250}
{"episode_reward": 267.42298109237555, "episode": 35.0, "critic_loss": 39.15957992553711, "critic_target_Q_variance_m=2": 357.81246508789064, "critic_Q1_variance_k=2": 1.2505349855422974, "critic_Q2_variance_k=2": 1.2536409282684327, "actor_loss": -36.627305227612695, "actor_mean_entropy": 0.2958877373427626, "alpha_loss": 0.001524008507470763, "alpha_value": 0.08516914213005662, "duration": 34.87498664855957, "step": 4375}
