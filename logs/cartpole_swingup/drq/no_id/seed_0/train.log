{"episode_reward": 0.0, "episode": 1.0, "duration": 2.1876115798950195, "step": 125}
{"episode_reward": 180.47110058644063, "episode": 2.0, "duration": 0.29920530319213867, "step": 250}
{"episode_reward": 48.52626484966922, "episode": 3.0, "duration": 0.28913116455078125, "step": 375}
{"episode_reward": 106.030169546403, "episode": 4.0, "duration": 0.2857046127319336, "step": 500}
{"episode_reward": 153.95059426464144, "episode": 5.0, "duration": 0.29990100860595703, "step": 625}
{"episode_reward": 59.72123608737102, "episode": 6.0, "duration": 0.2823207378387451, "step": 750}
{"episode_reward": 108.39820293463187, "episode": 7.0, "duration": 0.28784966468811035, "step": 875}
{"episode_reward": 66.9949003284935, "episode": 8.0, "duration": 0.2892749309539795, "step": 1000}
{"episode_reward": 211.25384590482398, "episode": 9.0, "critic_loss": 9.997184758508757, "critic_target_Q_variance_m=2": 14.497556470440587, "critic_Q1_variance_k=2": 0.29089491156407454, "critic_Q2_variance_k=2": 0.2911612052874238, "actor_loss": -5.789738542840531, "actor_mean_entropy": 1.1845111532624384, "alpha_loss": 0.11924158008997161, "alpha_value": 0.09533303571820786, "duration": 319.1063811779022, "step": 1125}
{"episode_reward": 160.39489955698747, "episode": 10.0, "critic_loss": 14.165562446594238, "critic_target_Q_variance_m=2": 36.04900804138184, "critic_Q1_variance_k=2": 0.4757903101444244, "critic_Q2_variance_k=2": 0.47458919072151184, "actor_loss": -10.714345608988117, "actor_mean_entropy": 1.1035049500003937, "alpha_loss": 0.08020207892742849, "alpha_value": 0.09110272062139915, "duration": 34.79624819755554, "step": 1250}
{"episode_reward": 149.08592689152394, "episode": 11.0, "critic_loss": 12.42209432220459, "critic_target_Q_variance_m=2": 38.986554214477536, "critic_Q1_variance_k=2": 0.4542358226776123, "critic_Q2_variance_k=2": 0.45405174815654753, "actor_loss": -11.301038030594114, "actor_mean_entropy": 1.05250093388179, "alpha_loss": 0.08225052496270528, "alpha_value": 0.09069540137795414, "duration": 34.65989136695862, "step": 1375}
{"episode_reward": 180.74257799478602, "episode": 12.0, "critic_loss": 17.05177293395996, "critic_target_Q_variance_m=2": 45.99962078857422, "critic_Q1_variance_k=2": 0.559118700504303, "critic_Q2_variance_k=2": 0.5576131312847138, "actor_loss": -12.238863422024634, "actor_mean_entropy": 0.9928973644010483, "alpha_loss": 0.08375647682095727, "alpha_value": 0.09027489138906174, "duration": 34.84343242645264, "step": 1500}
{"episode_reward": 242.8334506882569, "episode": 13.0, "critic_loss": 15.858837524414062, "critic_target_Q_variance_m=2": 51.05226516723633, "critic_Q1_variance_k=2": 0.492115709066391, "critic_Q2_variance_k=2": 0.4925980715751648, "actor_loss": -13.049054085262238, "actor_mean_entropy": 0.8937826468831017, "alpha_loss": 0.08467134555417394, "alpha_value": 0.08984053940055427, "duration": 35.087477684020996, "step": 1625}
{"episode_reward": 229.35454862695863, "episode": 14.0, "critic_loss": 15.43270336151123, "critic_target_Q_variance_m=2": 57.07592950439453, "critic_Q1_variance_k=2": 0.4832355319261551, "critic_Q2_variance_k=2": 0.4819772948026657, "actor_loss": -13.86356698313067, "actor_mean_entropy": 0.7445093907656208, "alpha_loss": 0.08209535022897105, "alpha_value": 0.08940188282070854, "duration": 34.713422775268555, "step": 1750}
{"episode_reward": 206.82014706308263, "episode": 15.0, "critic_loss": 15.946615737915039, "critic_target_Q_variance_m=2": 63.630554290771485, "critic_Q1_variance_k=2": 0.47127266907691956, "critic_Q2_variance_k=2": 0.47301825165748596, "actor_loss": -14.941386919172983, "actor_mean_entropy": 0.7469518605678801, "alpha_loss": 0.07504382971969861, "alpha_value": 0.08898312436698114, "duration": 34.76644945144653, "step": 1875}
{"episode_reward": 211.9140380443002, "episode": 16.0, "critic_loss": 19.175246505737306, "critic_target_Q_variance_m=2": 72.16960656738281, "critic_Q1_variance_k=2": 0.5451989079713822, "critic_Q2_variance_k=2": 0.5442464413642883, "actor_loss": -15.96599277373283, "actor_mean_entropy": 0.7097107734410993, "alpha_loss": 0.06476084281119608, "alpha_value": 0.08860482848378856, "duration": 34.85097312927246, "step": 2000}
{"episode_reward": 281.4616865047378, "episode": 17.0, "critic_loss": 18.040505500793458, "critic_target_Q_variance_m=2": 82.79826727294922, "critic_Q1_variance_k=2": 0.526442451953888, "critic_Q2_variance_k=2": 0.5251387834548951, "actor_loss": -17.020952027941508, "actor_mean_entropy": 0.6686738407801068, "alpha_loss": 0.056017882678480374, "alpha_value": 0.08828448136498288, "duration": 34.74730038642883, "step": 2125}
{"episode_reward": 300.19607595172204, "episode": 18.0, "critic_loss": 22.034252922058105, "critic_target_Q_variance_m=2": 93.6727163696289, "critic_Q1_variance_k=2": 0.6358490271568298, "critic_Q2_variance_k=2": 0.6324158685207367, "actor_loss": -18.09354385252922, "actor_mean_entropy": 0.6378312283946622, "alpha_loss": 0.04754237022491232, "alpha_value": 0.08800098999338225, "duration": 34.89666724205017, "step": 2250}
{"episode_reward": 188.47553488821933, "episode": 19.0, "critic_loss": 20.38782783508301, "critic_target_Q_variance_m=2": 101.38308166503906, "critic_Q1_variance_k=2": 0.5676043204069138, "critic_Q2_variance_k=2": 0.5688292896747589, "actor_loss": -19.010480608258927, "actor_mean_entropy": 0.6414018817364223, "alpha_loss": 0.04444607446295402, "alpha_value": 0.08773121402161148, "duration": 35.298187255859375, "step": 2375}
{"episode_reward": 216.36695100858256, "episode": 20.0, "critic_loss": 20.303060569763183, "critic_target_Q_variance_m=2": 107.35400451660156, "critic_Q1_variance_k=2": 0.5814713408946991, "critic_Q2_variance_k=2": 0.5837778565883637, "actor_loss": -19.506818217615926, "actor_mean_entropy": 0.6537806507079832, "alpha_loss": 0.04054471492887505, "alpha_value": 0.08747813727106227, "duration": 34.24011993408203, "step": 2500}
{"episode_reward": 202.43114354777703, "episode": 21.0, "critic_loss": 23.198819244384765, "critic_target_Q_variance_m=2": 118.7132872314453, "critic_Q1_variance_k=2": 0.674395269036293, "critic_Q2_variance_k=2": 0.6692417874336243, "actor_loss": -20.713802216544984, "actor_mean_entropy": 0.6265143501380134, "alpha_loss": 0.04300775495727384, "alpha_value": 0.0872274661231636, "duration": 35.62615466117859, "step": 2625}
{"episode_reward": 231.92935156794266, "episode": 22.0, "critic_loss": 29.881205757141114, "critic_target_Q_variance_m=2": 131.74790716552735, "critic_Q1_variance_k=2": 0.814282113313675, "critic_Q2_variance_k=2": 0.8179935185909272, "actor_loss": -21.739113623096095, "actor_mean_entropy": 0.5845420735497628, "alpha_loss": 0.04124096546682619, "alpha_value": 0.08696384648802417, "duration": 34.6204149723053, "step": 2750}
{"episode_reward": 260.201232718894, "episode": 23.0, "critic_loss": 32.06123806762695, "critic_target_Q_variance_m=2": 147.23426977539063, "critic_Q1_variance_k=2": 0.8848041715621948, "critic_Q2_variance_k=2": 0.8820786263942718, "actor_loss": -22.937661640227788, "actor_mean_entropy": 0.5644234700335397, "alpha_loss": 0.031750090131979616, "alpha_value": 0.08673155863261592, "duration": 34.88485503196716, "step": 2875}
{"episode_reward": 283.9468042412285, "episode": 24.0, "critic_loss": 30.177665817260742, "critic_target_Q_variance_m=2": 160.68030749511718, "critic_Q1_variance_k=2": 0.9008014154434204, "critic_Q2_variance_k=2": 0.9048433926105499, "actor_loss": -24.06917292071927, "actor_mean_entropy": 0.4981217865020998, "alpha_loss": 0.03093371097178709, "alpha_value": 0.08653020655153604, "duration": 34.6210081577301, "step": 3000}
{"episode_reward": 282.21567636286767, "episode": 25.0, "critic_loss": 30.66883769226074, "critic_target_Q_variance_m=2": 172.6167919921875, "critic_Q1_variance_k=2": 0.9074707746505737, "critic_Q2_variance_k=2": 0.9128017802238464, "actor_loss": -25.153039266192724, "actor_mean_entropy": 0.4579172084728877, "alpha_loss": 0.026200572235716715, "alpha_value": 0.08632144979346683, "duration": 35.177122831344604, "step": 3125}
{"episode_reward": 366.8649987527494, "episode": 26.0, "critic_loss": 47.047538146972656, "critic_target_Q_variance_m=2": 196.63294580078124, "critic_Q1_variance_k=2": 1.2198463406562805, "critic_Q2_variance_k=2": 1.216813359260559, "actor_loss": -26.635926800389445, "actor_mean_entropy": 0.4783112983549795, "alpha_loss": 0.0235458014930989, "alpha_value": 0.08615629161658375, "duration": 34.57536244392395, "step": 3250}
{"episode_reward": 244.29442882276044, "episode": 27.0, "critic_loss": 35.88763830566406, "critic_target_Q_variance_m=2": 206.814607421875, "critic_Q1_variance_k=2": 1.0844904460906983, "critic_Q2_variance_k=2": 1.0833874521255493, "actor_loss": -27.38402817741273, "actor_mean_entropy": 0.4369169681791275, "alpha_loss": 0.01933320824219476, "alpha_value": 0.08601143300323379, "duration": 34.78635334968567, "step": 3375}
{"episode_reward": 232.995452257285, "episode": 28.0, "critic_loss": 34.15962902832031, "critic_target_Q_variance_m=2": 222.27619567871093, "critic_Q1_variance_k=2": 1.0643309988975524, "critic_Q2_variance_k=2": 1.0672525362968446, "actor_loss": -28.61255012019988, "actor_mean_entropy": 0.3637201363040555, "alpha_loss": 0.019063515892823138, "alpha_value": 0.08586672973388716, "duration": 34.703651428222656, "step": 3500}
{"episode_reward": 274.4918868010651, "episode": 29.0, "critic_loss": 35.60351068115234, "critic_target_Q_variance_m=2": 239.6345909423828, "critic_Q1_variance_k=2": 1.1155939321517945, "critic_Q2_variance_k=2": 1.1224623551368713, "actor_loss": -29.603713989257812, "actor_mean_entropy": 0.42322456860353075, "alpha_loss": 0.017512533939369614, "alpha_value": 0.08572063708329221, "duration": 34.831164836883545, "step": 3625}
{"episode_reward": 283.9098477123428, "episode": 30.0, "critic_loss": 34.341627090454104, "critic_target_Q_variance_m=2": 256.043927734375, "critic_Q1_variance_k=2": 1.0655682439804077, "critic_Q2_variance_k=2": 1.069676393032074, "actor_loss": -30.618299791889807, "actor_mean_entropy": 0.4012629579632513, "alpha_loss": 0.015097884342990696, "alpha_value": 0.08560621940078025, "duration": 34.62284278869629, "step": 3750}
{"episode_reward": 338.99352358700037, "episode": 31.0, "critic_loss": 39.22650932312012, "critic_target_Q_variance_m=2": 280.1808843994141, "critic_Q1_variance_k=2": 1.162070810317993, "critic_Q2_variance_k=2": 1.174500997543335, "actor_loss": -32.19275883265904, "actor_mean_entropy": 0.37491484080988263, "alpha_loss": 0.01286752983402934, "alpha_value": 0.08547869400664815, "duration": 34.73219656944275, "step": 3875}
{"episode_reward": 248.60667829895257, "episode": 32.0, "critic_loss": 37.12922509765625, "critic_target_Q_variance_m=2": 296.40386474609375, "critic_Q1_variance_k=2": 1.134249029159546, "critic_Q2_variance_k=2": 1.1402051949501038, "actor_loss": -33.13028917004985, "actor_mean_entropy": 0.4075038380199863, "alpha_loss": 0.012832257819677433, "alpha_value": 0.0853880555357101, "duration": 34.43302869796753, "step": 4000}
{"episode_reward": 258.4808723446924, "episode": 33.0, "critic_loss": 38.68976988220215, "critic_target_Q_variance_m=2": 315.8083493652344, "critic_Q1_variance_k=2": 1.1793449745178222, "critic_Q2_variance_k=2": 1.1817199177742004, "actor_loss": -34.147530116732156, "actor_mean_entropy": 0.35125753851163954, "alpha_loss": 0.011314435425909266, "alpha_value": 0.08527330030327976, "duration": 34.75394868850708, "step": 4125}
{"episode_reward": 245.4270677194614, "episode": 34.0, "critic_loss": 37.71400210571289, "critic_target_Q_variance_m=2": 338.6092548828125, "critic_Q1_variance_k=2": 1.1695460481643676, "critic_Q2_variance_k=2": 1.1848990392684937, "actor_loss": -35.49722203900737, "actor_mean_entropy": 0.28393819189119723, "alpha_loss": 0.005073798232666788, "alpha_value": 0.0851934834901776, "duration": 34.34006690979004, "step": 4250}
{"episode_reward": 267.42298109237555, "episode": 35.0, "critic_loss": 39.15957992553711, "critic_target_Q_variance_m=2": 357.81246508789064, "critic_Q1_variance_k=2": 1.2505349855422974, "critic_Q2_variance_k=2": 1.2536409282684327, "actor_loss": -36.627305227612695, "actor_mean_entropy": 0.2958877373427626, "alpha_loss": 0.001524008507470763, "alpha_value": 0.08516914213005662, "duration": 34.87498664855957, "step": 4375}
{"episode_reward": 278.8360752005516, "episode": 36.0, "critic_loss": 36.385999298095705, "critic_target_Q_variance_m=2": 378.13237475585936, "critic_Q1_variance_k=2": 1.1566765904426575, "critic_Q2_variance_k=2": 1.1560256819725037, "actor_loss": -37.79567060162944, "actor_mean_entropy": 0.2995621169046048, "alpha_loss": 0.0023390044657243115, "alpha_value": 0.08515304430705108, "duration": 34.38462162017822, "step": 4500}
{"episode_reward": 277.80350017533823, "episode": 37.0, "critic_loss": 41.11070426940918, "critic_target_Q_variance_m=2": 409.43191918945314, "critic_Q1_variance_k=2": 1.3111951966285706, "critic_Q2_variance_k=2": 1.3158322381973266, "actor_loss": -39.2021369934082, "actor_mean_entropy": 0.31722765049291035, "alpha_loss": 0.0030889425792598297, "alpha_value": 0.08512868097877262, "duration": 34.79376983642578, "step": 4625}
{"episode_reward": 385.1277191434907, "episode": 38.0, "critic_loss": 38.995280944824216, "critic_target_Q_variance_m=2": 438.4162333984375, "critic_Q1_variance_k=2": 1.2606564359664918, "critic_Q2_variance_k=2": 1.2708286747932434, "actor_loss": -40.661507391160534, "actor_mean_entropy": 0.2677807229901514, "alpha_loss": 0.003517548948894405, "alpha_value": 0.08508801421158418, "duration": 34.615941762924194, "step": 4750}
{"episode_reward": 456.89630980929707, "episode": 39.0, "critic_loss": 56.911150268554685, "critic_target_Q_variance_m=2": 486.02413500976564, "critic_Q1_variance_k=2": 1.5589512939453125, "critic_Q2_variance_k=2": 1.5483444414138794, "actor_loss": -42.63823397197421, "actor_mean_entropy": 0.23421434437235197, "alpha_loss": 0.002846982594328149, "alpha_value": 0.0850591941520271, "duration": 34.81231665611267, "step": 4875}
{"episode_reward": 278.513674891568, "episode": 40.0, "critic_loss": 42.96402149963379, "critic_target_Q_variance_m=2": 515.7004223632813, "critic_Q1_variance_k=2": 1.4315123138427734, "critic_Q2_variance_k=2": 1.43558091878891, "actor_loss": -44.03403688246204, "actor_mean_entropy": 0.19187277519414503, "alpha_loss": -0.0003927457221453228, "alpha_value": 0.08504576927887826, "duration": 34.71156120300293, "step": 5000}
{"episode_reward": 340.92126221546897, "episode": 41.0, "critic_loss": 47.19765982055664, "critic_target_Q_variance_m=2": 537.5366623535157, "critic_Q1_variance_k=2": 1.4662188405990602, "critic_Q2_variance_k=2": 1.4814022436141967, "actor_loss": -44.982662322029235, "actor_mean_entropy": 0.2466125607727066, "alpha_loss": -0.004068007173445371, "alpha_value": 0.08507282082886337, "duration": 34.47430467605591, "step": 5125}
{"episode_reward": 373.3936560308274, "episode": 42.0, "critic_loss": 49.04123760986328, "critic_target_Q_variance_m=2": 577.8829931640626, "critic_Q1_variance_k=2": 1.5569111323356628, "critic_Q2_variance_k=2": 1.556541124343872, "actor_loss": -46.59762351743637, "actor_mean_entropy": 0.20124490979698398, "alpha_loss": -0.00047779630028432416, "alpha_value": 0.08510656696639486, "duration": 34.554187059402466, "step": 5250}
{"episode_reward": 478.1559229309394, "episode": 43.0, "critic_loss": 46.88001475524902, "critic_target_Q_variance_m=2": 616.6083911132813, "critic_Q1_variance_k=2": 1.6014992909431458, "critic_Q2_variance_k=2": 1.5892289452552795, "actor_loss": -48.114982423328215, "actor_mean_entropy": 0.20549997586816077, "alpha_loss": -0.008494456479739811, "alpha_value": 0.08516751849430018, "duration": 34.63420605659485, "step": 5375}
{"episode_reward": 402.1095442642532, "episode": 44.0, "critic_loss": 54.43279992675781, "critic_target_Q_variance_m=2": 660.2168583984375, "critic_Q1_variance_k=2": 1.7147944250106812, "critic_Q2_variance_k=2": 1.7138140249252318, "actor_loss": -49.8255672454834, "actor_mean_entropy": 0.13149462171619938, "alpha_loss": -0.014307066024611554, "alpha_value": 0.08527432307402723, "duration": 34.46954035758972, "step": 5500}
{"episode_reward": 352.7037870304743, "episode": 45.0, "critic_loss": 52.71977020263672, "critic_target_Q_variance_m=2": 702.80973046875, "critic_Q1_variance_k=2": 1.7007281613349914, "critic_Q2_variance_k=2": 1.6944488258361816, "actor_loss": -51.447911398751394, "actor_mean_entropy": 0.13739550143243776, "alpha_loss": -0.009427524792651335, "alpha_value": 0.08544356694744401, "duration": 34.720937728881836, "step": 5625}
{"episode_reward": 413.4739642139609, "episode": 46.0, "critic_loss": 53.83067233276367, "critic_target_Q_variance_m=2": 748.499150390625, "critic_Q1_variance_k=2": 1.6453729963302612, "critic_Q2_variance_k=2": 1.6530785703659057, "actor_loss": -52.84655903231713, "actor_mean_entropy": 0.10640212989622547, "alpha_loss": -0.016679890115835493, "alpha_value": 0.08559240098042623, "duration": 34.67683291435242, "step": 5750}
{"episode_reward": 301.68653756388795, "episode": 47.0, "critic_loss": 55.307128051757815, "critic_target_Q_variance_m=2": 798.6912763671875, "critic_Q1_variance_k=2": 1.7724883852005004, "critic_Q2_variance_k=2": 1.7735364646911622, "actor_loss": -54.97052292596726, "actor_mean_entropy": 0.14214948960949506, "alpha_loss": -0.013274161119220985, "alpha_value": 0.08579393886037245, "duration": 34.66921305656433, "step": 5875}
{"episode_reward": 248.68185887114993, "episode": 48.0, "critic_loss": 57.80965428161621, "critic_target_Q_variance_m=2": 847.35427734375, "critic_Q1_variance_k=2": 1.691788496017456, "critic_Q2_variance_k=2": 1.6945181179046631, "actor_loss": -56.75470382936539, "actor_mean_entropy": 0.11662456489378406, "alpha_loss": -0.020303349309195313, "alpha_value": 0.08599832224616391, "duration": 34.64674210548401, "step": 6000}
{"episode_reward": 304.44873211753844, "episode": 49.0, "critic_loss": 53.73362687683105, "critic_target_Q_variance_m=2": 897.7133627929687, "critic_Q1_variance_k=2": 1.6487930879592896, "critic_Q2_variance_k=2": 1.650457971572876, "actor_loss": -58.446443285260884, "actor_mean_entropy": 0.08986192918013013, "alpha_loss": -0.018844889842772057, "alpha_value": 0.08629289286476752, "duration": 35.044328451156616, "step": 6125}
{"episode_reward": 485.22516327256653, "episode": 50.0, "critic_loss": 53.441584075927736, "critic_target_Q_variance_m=2": 959.8574047851563, "critic_Q1_variance_k=2": 1.7132517547607422, "critic_Q2_variance_k=2": 1.7151681470870972, "actor_loss": -60.62877008991857, "actor_mean_entropy": 0.12870925959319837, "alpha_loss": -0.02362760729456861, "alpha_value": 0.08656676943700553, "duration": 34.643627643585205, "step": 6250}
{"episode_reward": 366.2172771933742, "episode": 51.0, "critic_loss": 53.54393823242187, "critic_target_Q_variance_m=2": 1020.008990234375, "critic_Q1_variance_k=2": 1.6973797554969787, "critic_Q2_variance_k=2": 1.686551003932953, "actor_loss": -62.37655246068561, "actor_mean_entropy": 0.1284921925574068, "alpha_loss": -0.017740372259775917, "alpha_value": 0.08688423063282784, "duration": 35.11442947387695, "step": 6375}
{"episode_reward": 534.8956384488343, "episode": 52.0, "critic_loss": 56.88528762817383, "critic_target_Q_variance_m=2": 1080.9222485351563, "critic_Q1_variance_k=2": 1.8303254079818725, "critic_Q2_variance_k=2": 1.8141424369812011, "actor_loss": -64.08330966580299, "actor_mean_entropy": 0.1360186357952414, "alpha_loss": -0.021966793979968754, "alpha_value": 0.08717324165601144, "duration": 34.8607063293457, "step": 6500}
{"episode_reward": 470.8330929494518, "episode": 53.0, "critic_loss": 54.58041662597656, "critic_target_Q_variance_m=2": 1156.433107421875, "critic_Q1_variance_k=2": 1.7802871007919312, "critic_Q2_variance_k=2": 1.7715939860343932, "actor_loss": -66.59507799905444, "actor_mean_entropy": 0.049137679120850944, "alpha_loss": -0.024920356570787373, "alpha_value": 0.08750952537411898, "duration": 33.66441583633423, "step": 6625}
{"episode_reward": 341.7421859967541, "episode": 54.0, "critic_loss": 56.16580865478516, "critic_target_Q_variance_m=2": 1204.0019775390624, "critic_Q1_variance_k=2": 1.8611130561828613, "critic_Q2_variance_k=2": 1.8533522996902465, "actor_loss": -67.88270568847656, "actor_mean_entropy": 0.07209390239609827, "alpha_loss": -0.027531735674147646, "alpha_value": 0.08792558289819292, "duration": 34.41356825828552, "step": 6750}
{"episode_reward": 585.6522724578625, "episode": 55.0, "critic_loss": 63.40604598999023, "critic_target_Q_variance_m=2": 1309.5483271484375, "critic_Q1_variance_k=2": 1.937562479019165, "critic_Q2_variance_k=2": 1.9286032104492188, "actor_loss": -70.54945688399057, "actor_mean_entropy": 0.11169114265413511, "alpha_loss": -0.022264078381426987, "alpha_value": 0.0883186210337776, "duration": 34.60250496864319, "step": 6875}
{"episode_reward": 690.15585320597, "episode": 56.0, "critic_loss": 68.14586700439453, "critic_target_Q_variance_m=2": 1409.9123408203125, "critic_Q1_variance_k=2": 2.0656266465187074, "critic_Q2_variance_k=2": 2.062735641479492, "actor_loss": -72.97062670799994, "actor_mean_entropy": 0.06067322464960237, "alpha_loss": -0.0302051835423035, "alpha_value": 0.08871310474474035, "duration": 34.30313682556152, "step": 7000}
{"episode_reward": 611.0789206227263, "episode": 57.0, "critic_loss": 68.10240173339844, "critic_target_Q_variance_m=2": 1482.971123046875, "critic_Q1_variance_k=2": 2.1882746772766115, "critic_Q2_variance_k=2": 2.171342551231384, "actor_loss": -75.0447507585798, "actor_mean_entropy": 0.019792138938865965, "alpha_loss": -0.028191668513630117, "alpha_value": 0.08916722758899262, "duration": 34.62588810920715, "step": 7125}
{"episode_reward": 476.5599493235826, "episode": 58.0, "critic_loss": 77.84230737304688, "critic_target_Q_variance_m=2": 1575.2511181640625, "critic_Q1_variance_k=2": 2.3572072887420656, "critic_Q2_variance_k=2": 2.351413927078247, "actor_loss": -76.91384481614635, "actor_mean_entropy": 0.07014466083097842, "alpha_loss": -0.025148300386424505, "alpha_value": 0.08963008910911982, "duration": 34.53558540344238, "step": 7250}
{"episode_reward": 445.41046470891695, "episode": 59.0, "critic_loss": 75.83216104125977, "critic_target_Q_variance_m=2": 1638.98102734375, "critic_Q1_variance_k=2": 2.300085676193237, "critic_Q2_variance_k=2": 2.3205765867233277, "actor_loss": -78.59659709627667, "actor_mean_entropy": -0.06510915657475827, "alpha_loss": -0.03670115162071491, "alpha_value": 0.09010879666785301, "duration": 34.52183222770691, "step": 7375}
{"episode_reward": 546.1922961124963, "episode": 60.0, "critic_loss": 79.74479483032226, "critic_target_Q_variance_m=2": 1741.3173935546874, "critic_Q1_variance_k=2": 2.4274719295501708, "critic_Q2_variance_k=2": 2.426041787147522, "actor_loss": -80.8733178415606, "actor_mean_entropy": -0.018393167985543128, "alpha_loss": -0.03214293059652611, "alpha_value": 0.09068234678790373, "duration": 35.43136286735535, "step": 7500}
{"episode_reward": 619.9511048265606, "episode": 61.0, "critic_loss": 80.06850784301758, "critic_target_Q_variance_m=2": 1861.0084912109376, "critic_Q1_variance_k=2": 2.5618027572631834, "critic_Q2_variance_k=2": 2.56801735496521, "actor_loss": -83.72161695692274, "actor_mean_entropy": -0.018959604440227387, "alpha_loss": -0.03228838953913914, "alpha_value": 0.09120734046549746, "duration": 34.9543182849884, "step": 7625}
{"episode_reward": 752.0722704711767, "episode": 62.0, "critic_loss": 85.99429733276367, "critic_target_Q_variance_m=2": 1981.305796875, "critic_Q1_variance_k=2": 2.7897652378082274, "critic_Q2_variance_k=2": 2.788625507354736, "actor_loss": -86.435363892586, "actor_mean_entropy": -0.06435305979703704, "alpha_loss": -0.03589656018471766, "alpha_value": 0.09178602740651429, "duration": 34.98735594749451, "step": 7750}
{"episode_reward": 593.9056470391245, "episode": 63.0, "critic_loss": 90.4430060119629, "critic_target_Q_variance_m=2": 2105.3844765625, "critic_Q1_variance_k=2": 2.9939860763549806, "critic_Q2_variance_k=2": 2.985359932899475, "actor_loss": -88.59188806442987, "actor_mean_entropy": -0.033733160604560185, "alpha_loss": -0.03715310492626731, "alpha_value": 0.09236120392258736, "duration": 34.51370143890381, "step": 7875}
{"episode_reward": 667.1875174401026, "episode": 64.0, "critic_loss": 95.56715319824218, "critic_target_Q_variance_m=2": 2220.2029736328127, "critic_Q1_variance_k=2": 2.9941356649398805, "critic_Q2_variance_k=2": 2.9780734329223635, "actor_loss": -91.65041215958134, "actor_mean_entropy": -0.04700774609321548, "alpha_loss": -0.04132637354515253, "alpha_value": 0.09303139293969938, "duration": 34.512929916381836, "step": 8000}
{"episode_reward": 740.0694425514413, "episode": 65.0, "critic_loss": 105.69698974609375, "critic_target_Q_variance_m=2": 2388.608994140625, "critic_Q1_variance_k=2": 3.211337863922119, "critic_Q2_variance_k=2": 3.2003200988769533, "actor_loss": -94.06880757165334, "actor_mean_entropy": -0.06063634494230861, "alpha_loss": -0.049280953046584884, "alpha_value": 0.09377212721297908, "duration": 34.68764090538025, "step": 8125}
{"episode_reward": 745.4538557616612, "episode": 66.0, "critic_loss": 106.34523004150391, "critic_target_Q_variance_m=2": 2546.119060546875, "critic_Q1_variance_k=2": 3.416139150619507, "critic_Q2_variance_k=2": 3.4041393756866456, "actor_loss": -96.75070030458512, "actor_mean_entropy": -0.032095021057513454, "alpha_loss": -0.04995839625236488, "alpha_value": 0.09454327369815406, "duration": 34.34772181510925, "step": 8250}
{"episode_reward": 678.2228808633095, "episode": 67.0, "critic_loss": 115.33865441894531, "critic_target_Q_variance_m=2": 2721.30511328125, "critic_Q1_variance_k=2": 3.659301305770874, "critic_Q2_variance_k=2": 3.6784911956787107, "actor_loss": -100.01209912981305, "actor_mean_entropy": -0.08648636038341219, "alpha_loss": -0.04844374928091254, "alpha_value": 0.09531785766535568, "duration": 34.49820351600647, "step": 8375}
{"episode_reward": 670.705322043896, "episode": 68.0, "critic_loss": 119.74989233398438, "critic_target_Q_variance_m=2": 2841.96809765625, "critic_Q1_variance_k=2": 3.968490809440613, "critic_Q2_variance_k=2": 3.945334461212158, "actor_loss": -102.6191669587166, "actor_mean_entropy": -0.10313270932003375, "alpha_loss": -0.05066211407463397, "alpha_value": 0.09610169638745879, "duration": 34.76369309425354, "step": 8500}
{"episode_reward": 649.929021608138, "episode": 69.0, "critic_loss": 131.55963439941405, "critic_target_Q_variance_m=2": 3031.511927734375, "critic_Q1_variance_k=2": 3.8799960594177247, "critic_Q2_variance_k=2": 3.8882849082946778, "actor_loss": -105.37886664980934, "actor_mean_entropy": -0.11642501243050137, "alpha_loss": -0.057987745319093974, "alpha_value": 0.09689810077641607, "duration": 34.670092821121216, "step": 8625}
{"episode_reward": 630.1487736304792, "episode": 70.0, "critic_loss": 127.74798046875, "critic_target_Q_variance_m=2": 3213.959068359375, "critic_Q1_variance_k=2": 3.996490682601929, "critic_Q2_variance_k=2": 3.9743226737976074, "actor_loss": -108.66339234382876, "actor_mean_entropy": -0.1813172136223124, "alpha_loss": -0.05124339449309533, "alpha_value": 0.09770345890749936, "duration": 34.783642053604126, "step": 8750}
{"episode_reward": 665.9777818929587, "episode": 71.0, "critic_loss": 124.68133367919921, "critic_target_Q_variance_m=2": 3363.599498046875, "critic_Q1_variance_k=2": 4.0210529289245605, "critic_Q2_variance_k=2": 4.007988670349121, "actor_loss": -110.9015604654948, "actor_mean_entropy": -0.10676269079484636, "alpha_loss": -0.050941589288413525, "alpha_value": 0.09843920613915497, "duration": 34.715364933013916, "step": 8875}
{"episode_reward": 774.1449013619477, "episode": 72.0, "critic_loss": 139.41762322998048, "critic_target_Q_variance_m=2": 3564.527212890625, "critic_Q1_variance_k=2": 4.164533006668091, "critic_Q2_variance_k=2": 4.154093790054321, "actor_loss": -114.39284466158959, "actor_mean_entropy": -0.11224531484467368, "alpha_loss": -0.055073734252683575, "alpha_value": 0.09921598354262998, "duration": 34.48430395126343, "step": 9000}
{"episode_reward": 665.7983704609779, "episode": 73.0, "critic_loss": 147.15825811767579, "critic_target_Q_variance_m=2": 3772.43384765625, "critic_Q1_variance_k=2": 4.4485210609436034, "critic_Q2_variance_k=2": 4.482697055816651, "actor_loss": -117.28116474454364, "actor_mean_entropy": -0.09016900278982662, "alpha_loss": -0.05611727272884713, "alpha_value": 0.0999969645044385, "duration": 34.572707653045654, "step": 9125}
{"episode_reward": 655.0769852107195, "episode": 74.0, "critic_loss": 150.07317510986329, "critic_target_Q_variance_m=2": 3991.11978515625, "critic_Q1_variance_k=2": 4.722671356201172, "critic_Q2_variance_k=2": 4.70110615158081, "actor_loss": -120.77643363706527, "actor_mean_entropy": -0.11840490672376848, "alpha_loss": -0.06636952263333144, "alpha_value": 0.10083810854781039, "duration": 34.43672513961792, "step": 9250}
{"episode_reward": 704.2612346044069, "episode": 75.0, "critic_loss": 152.72519006347656, "critic_target_Q_variance_m=2": 4233.85873828125, "critic_Q1_variance_k=2": 4.912112911224365, "critic_Q2_variance_k=2": 4.913748825073243, "actor_loss": -124.7938984462193, "actor_mean_entropy": -0.13952253244462468, "alpha_loss": -0.06590616768078199, "alpha_value": 0.10172013719665875, "duration": 34.907389879226685, "step": 9375}
{"episode_reward": 800.3959777258573, "episode": 76.0, "critic_loss": 164.46264837646484, "critic_target_Q_variance_m=2": 4403.218408203125, "critic_Q1_variance_k=2": 4.755791507720947, "critic_Q2_variance_k=2": 4.762395462036133, "actor_loss": -127.50683212280273, "actor_mean_entropy": -0.12116001900886336, "alpha_loss": -0.06508784963478965, "alpha_value": 0.10261785520308793, "duration": 34.44834494590759, "step": 9500}
{"episode_reward": 548.6269312372054, "episode": 77.0, "critic_loss": 186.78360034179687, "critic_target_Q_variance_m=2": 4648.85955859375, "critic_Q1_variance_k=2": 5.159609029769897, "critic_Q2_variance_k=2": 5.123484712600708, "actor_loss": -130.55975923084077, "actor_mean_entropy": -0.0873554762866762, "alpha_loss": -0.06464429844229941, "alpha_value": 0.10346351985091526, "duration": 34.620532512664795, "step": 9625}
{"episode_reward": 740.5864876950582, "episode": 78.0, "critic_loss": 176.11249182128907, "critic_target_Q_variance_m=2": 4885.206828125, "critic_Q1_variance_k=2": 5.14572233581543, "critic_Q2_variance_k=2": 5.149187351226806, "actor_loss": -133.52062176119895, "actor_mean_entropy": -0.19761562341403577, "alpha_loss": -0.07668032953816076, "alpha_value": 0.10428391712242167, "duration": 34.68502926826477, "step": 9750}
{"episode_reward": 567.0939851027523, "episode": 79.0, "critic_loss": 163.53548065185547, "critic_target_Q_variance_m=2": 5161.27315625, "critic_Q1_variance_k=2": 5.12749515914917, "critic_Q2_variance_k=2": 5.132613967895508, "actor_loss": -137.21912517244854, "actor_mean_entropy": -0.1266343573492671, "alpha_loss": -0.06731613145934211, "alpha_value": 0.10524623394605537, "duration": 34.61532711982727, "step": 9875}
{"episode_reward": 527.8666485981403, "episode": 80.0, "critic_loss": 178.98890612792968, "critic_target_Q_variance_m=2": 5395.01944140625, "critic_Q1_variance_k=2": 5.5108900527954106, "critic_Q2_variance_k=2": 5.538376964569092, "actor_loss": -140.52776410502773, "actor_mean_entropy": -0.07949688754254772, "alpha_loss": -0.06703297787856671, "alpha_value": 0.10607591965083817, "duration": 34.61465644836426, "step": 10000}
{"episode_reward": 703.7462974416653, "episode": 81.0, "critic_loss": 179.41355883789063, "critic_target_Q_variance_m=2": 5631.8088203125, "critic_Q1_variance_k=2": 5.654815753936767, "critic_Q2_variance_k=2": 5.649884750366211, "actor_loss": -143.57552543519034, "actor_mean_entropy": -0.09727543444624023, "alpha_loss": -0.07372650078364781, "alpha_value": 0.10690333284082652, "duration": 36.50388479232788, "step": 10125}
{"episode_reward": 568.9483417625622, "episode": 82.0, "critic_loss": 197.44671472167968, "critic_target_Q_variance_m=2": 5936.4206328125, "critic_Q1_variance_k=2": 6.05604256439209, "critic_Q2_variance_k=2": 6.025629203796386, "actor_loss": -147.01715506276776, "actor_mean_entropy": -0.11395328909519219, "alpha_loss": -0.07504234829496953, "alpha_value": 0.10780959988509728, "duration": 32.45639657974243, "step": 10250}
{"episode_reward": 700.4983681206053, "episode": 83.0, "critic_loss": 204.36661053466796, "critic_target_Q_variance_m=2": 6160.6324921875, "critic_Q1_variance_k=2": 6.0155961799621585, "critic_Q2_variance_k=2": 5.996363477706909, "actor_loss": -149.8882560124473, "actor_mean_entropy": -0.10787990896238221, "alpha_loss": -0.0790489800865688, "alpha_value": 0.10869112854098706, "duration": 35.00818347930908, "step": 10375}
{"episode_reward": 698.1609271763425, "episode": 84.0, "critic_loss": 208.20070471191406, "critic_target_Q_variance_m=2": 6541.2167421875, "critic_Q1_variance_k=2": 6.075094552993774, "critic_Q2_variance_k=2": 6.107849296569825, "actor_loss": -154.8951396326865, "actor_mean_entropy": -0.07690878167387939, "alpha_loss": -0.07810681253190964, "alpha_value": 0.10959454993798055, "duration": 34.40646314620972, "step": 10500}
{"episode_reward": 670.1853181142366, "episode": 85.0, "critic_loss": 212.21605224609374, "critic_target_Q_variance_m=2": 6822.5804453125, "critic_Q1_variance_k=2": 6.560801383972168, "critic_Q2_variance_k=2": 6.551051355361938, "actor_loss": -159.24381486196367, "actor_mean_entropy": -0.15208619856645192, "alpha_loss": -0.07886836790139713, "alpha_value": 0.11048020107567082, "duration": 34.488237142562866, "step": 10625}
{"episode_reward": 723.1438261037739, "episode": 86.0, "critic_loss": 211.21184686279298, "critic_target_Q_variance_m=2": 7028.7253515625, "critic_Q1_variance_k=2": 6.416322479248047, "critic_Q2_variance_k=2": 6.3849103527069095, "actor_loss": -161.43594926403415, "actor_mean_entropy": -0.06851549542719318, "alpha_loss": -0.08045457555882392, "alpha_value": 0.1113814940584396, "duration": 34.35680961608887, "step": 10750}
{"episode_reward": 584.4073973123336, "episode": 87.0, "critic_loss": 222.0810069580078, "critic_target_Q_variance_m=2": 7356.9904921875, "critic_Q1_variance_k=2": 6.4106414451599125, "critic_Q2_variance_k=2": 6.425386510848999, "actor_loss": -164.9935605488126, "actor_mean_entropy": -0.11033245037117648, "alpha_loss": -0.08066351575747369, "alpha_value": 0.11225434206203913, "duration": 34.81264281272888, "step": 10875}
{"episode_reward": 736.1860124171006, "episode": 88.0, "critic_loss": 213.21171142578126, "critic_target_Q_variance_m=2": 7691.0901171875, "critic_Q1_variance_k=2": 6.571940275192261, "critic_Q2_variance_k=2": 6.504670106887818, "actor_loss": -168.07150170110887, "actor_mean_entropy": -0.022577213544038036, "alpha_loss": -0.08200951936023851, "alpha_value": 0.11312729905294985, "duration": 34.39802050590515, "step": 11000}
{"episode_reward": 707.1477819673914, "episode": 89.0, "critic_loss": 223.35646789550782, "critic_target_Q_variance_m=2": 7955.47175, "critic_Q1_variance_k=2": 6.4786130218505855, "critic_Q2_variance_k=2": 6.463857995986938, "actor_loss": -171.35941932314918, "actor_mean_entropy": -0.11193099292734313, "alpha_loss": -0.08439489418552035, "alpha_value": 0.11399579148280016, "duration": 34.77594518661499, "step": 11125}
{"episode_reward": 718.9090147119126, "episode": 90.0, "critic_loss": 231.19598907470703, "critic_target_Q_variance_m=2": 8272.338484375, "critic_Q1_variance_k=2": 6.804365037918091, "critic_Q2_variance_k=2": 6.847864582061767, "actor_loss": -175.69025051978326, "actor_mean_entropy": -0.07652520802953551, "alpha_loss": -0.07523435582557032, "alpha_value": 0.11486192127313838, "duration": 34.625962257385254, "step": 11250}
{"episode_reward": 673.7714155786492, "episode": 91.0, "critic_loss": 241.52376257324218, "critic_target_Q_variance_m=2": 8623.82202734375, "critic_Q1_variance_k=2": 6.985774768829346, "critic_Q2_variance_k=2": 6.998854951858521, "actor_loss": -178.83097088526165, "actor_mean_entropy": -0.12741811993339705, "alpha_loss": -0.08238952926227025, "alpha_value": 0.11569176579718095, "duration": 34.56102728843689, "step": 11375}
{"episode_reward": 681.4370430571498, "episode": 92.0, "critic_loss": 245.20429541015625, "critic_target_Q_variance_m=2": 9029.271796875, "critic_Q1_variance_k=2": 7.3304047012329105, "critic_Q2_variance_k=2": 7.316820837020874, "actor_loss": -182.9558073474515, "actor_mean_entropy": -0.01109188692944665, "alpha_loss": -0.08519975216157975, "alpha_value": 0.1165525635055364, "duration": 34.44318079948425, "step": 11500}
{"episode_reward": 734.2330802823666, "episode": 93.0, "critic_loss": 236.7801654663086, "critic_target_Q_variance_m=2": 9364.0020546875, "critic_Q1_variance_k=2": 7.20577359008789, "critic_Q2_variance_k=2": 7.189022584915161, "actor_loss": -186.98230513315352, "actor_mean_entropy": -0.11829785092009439, "alpha_loss": -0.08473817868128655, "alpha_value": 0.11742843067520062, "duration": 34.69038009643555, "step": 11625}
{"episode_reward": 721.9609766454167, "episode": 94.0, "critic_loss": 241.58111779785156, "critic_target_Q_variance_m=2": 9688.3179296875, "critic_Q1_variance_k=2": 6.867345575332641, "critic_Q2_variance_k=2": 6.826064350128174, "actor_loss": -189.61588582684917, "actor_mean_entropy": -0.0829305813437508, "alpha_loss": -0.09430315201320956, "alpha_value": 0.11835416949663329, "duration": 34.79127883911133, "step": 11750}
{"episode_reward": 730.2558970805769, "episode": 95.0, "critic_loss": 226.0404907836914, "critic_target_Q_variance_m=2": 10019.043671875, "critic_Q1_variance_k=2": 7.305695276260376, "critic_Q2_variance_k=2": 7.287552591323853, "actor_loss": -193.3776622953869, "actor_mean_entropy": -0.04303870557083024, "alpha_loss": -0.08703774438490944, "alpha_value": 0.1192731494297293, "duration": 34.70297026634216, "step": 11875}
{"episode_reward": 753.4328351954659, "episode": 96.0, "critic_loss": 227.86219384765624, "critic_target_Q_variance_m=2": 10438.3693671875, "critic_Q1_variance_k=2": 6.8117735404968265, "critic_Q2_variance_k=2": 6.766204957962036, "actor_loss": -198.14935770342427, "actor_mean_entropy": -0.08187499708465991, "alpha_loss": -0.08951803086505782, "alpha_value": 0.12013611323799375, "duration": 34.57616138458252, "step": 12000}
{"episode_reward": 715.0426081400758, "episode": 97.0, "critic_loss": 239.25648602294922, "critic_target_Q_variance_m=2": 10857.2958046875, "critic_Q1_variance_k=2": 7.054017841339111, "critic_Q2_variance_k=2": 7.007428218841553, "actor_loss": -201.74485754588292, "actor_mean_entropy": -0.08216829846302669, "alpha_loss": -0.08797476452494425, "alpha_value": 0.1210468826791168, "duration": 34.52610230445862, "step": 12125}
{"episode_reward": 686.1479890824758, "episode": 98.0, "critic_loss": 224.8530523071289, "critic_target_Q_variance_m=2": 11168.0680234375, "critic_Q1_variance_k=2": 7.107552358627319, "critic_Q2_variance_k=2": 7.0794885578155515, "actor_loss": -204.5778340985698, "actor_mean_entropy": -0.06412387538641211, "alpha_loss": -0.08193127540571074, "alpha_value": 0.12189459566565435, "duration": 34.38200855255127, "step": 12250}
{"episode_reward": 742.0093517167187, "episode": 99.0, "critic_loss": 224.7351513671875, "critic_target_Q_variance_m=2": 11525.44296875, "critic_Q1_variance_k=2": 6.863044162750244, "critic_Q2_variance_k=2": 6.8458775043487545, "actor_loss": -208.13012574210998, "actor_mean_entropy": -0.099495494472129, "alpha_loss": -0.08945971863373878, "alpha_value": 0.12274221655419948, "duration": 34.69837188720703, "step": 12375}
{"episode_reward": 742.4708361537643, "episode": 100.0, "critic_loss": 214.24876965332032, "critic_target_Q_variance_m=2": 11994.7068125, "critic_Q1_variance_k=2": 6.469259052276612, "critic_Q2_variance_k=2": 6.454714193344116, "actor_loss": -212.1310095017956, "actor_mean_entropy": -0.13262264400480256, "alpha_loss": -0.09000690762073763, "alpha_value": 0.12364302523114368, "duration": 34.24239444732666, "step": 12500}
{"episode_reward": 813.5564463922763, "episode": 101.0, "critic_loss": 229.76514721679686, "critic_target_Q_variance_m=2": 12361.154671875, "critic_Q1_variance_k=2": 7.115896947860718, "critic_Q2_variance_k=2": 7.105514125823975, "actor_loss": -216.0359857952784, "actor_mean_entropy": -0.15462250942512165, "alpha_loss": -0.08532451252852168, "alpha_value": 0.12447836608732803, "duration": 34.88172268867493, "step": 12625}
{"episode_reward": 749.9709774646913, "episode": 102.0, "critic_loss": 223.20893994140624, "critic_target_Q_variance_m=2": 12725.09653125, "critic_Q1_variance_k=2": 7.0727228279113765, "critic_Q2_variance_k=2": 7.105345924377441, "actor_loss": -219.57642561389554, "actor_mean_entropy": -0.0794432265383582, "alpha_loss": -0.08374093040343254, "alpha_value": 0.12531283416096278, "duration": 34.53503489494324, "step": 12750}
{"episode_reward": 751.2034471479151, "episode": 103.0, "critic_loss": 227.40437255859376, "critic_target_Q_variance_m=2": 13100.9153515625, "critic_Q1_variance_k=2": 6.898544368743896, "critic_Q2_variance_k=2": 6.823807033538818, "actor_loss": -221.97513301788814, "actor_mean_entropy": -0.09285733494020644, "alpha_loss": -0.09006422622099755, "alpha_value": 0.12614735105215888, "duration": 34.73351001739502, "step": 12875}
{"episode_reward": 757.1157016204681, "episode": 104.0, "critic_loss": 243.2672196044922, "critic_target_Q_variance_m=2": 13585.4870390625, "critic_Q1_variance_k=2": 7.215157320022583, "critic_Q2_variance_k=2": 7.174974027633667, "actor_loss": -226.53058378158076, "actor_mean_entropy": -0.12290550275675712, "alpha_loss": -0.09672150574624538, "alpha_value": 0.12704952301397474, "duration": 34.31841588020325, "step": 13000}
{"episode_reward": 761.5552688683779, "episode": 105.0, "critic_loss": 221.22637084960937, "critic_target_Q_variance_m=2": 14004.4231953125, "critic_Q1_variance_k=2": 6.829339399337768, "critic_Q2_variance_k=2": 6.752605670928955, "actor_loss": -231.3851294139075, "actor_mean_entropy": -0.1743578001975067, "alpha_loss": -0.07892795882764317, "alpha_value": 0.12792773559307366, "duration": 34.50942063331604, "step": 13125}
{"episode_reward": 802.0000040813683, "episode": 106.0, "critic_loss": 229.94262341308593, "critic_target_Q_variance_m=2": 14493.4331015625, "critic_Q1_variance_k=2": 6.8063161277771, "critic_Q2_variance_k=2": 6.786611267089844, "actor_loss": -234.33660593340474, "actor_mean_entropy": -0.13060241607168027, "alpha_loss": -0.09223278263403524, "alpha_value": 0.128768392209307, "duration": 34.4887957572937, "step": 13250}
{"episode_reward": 748.953395679522, "episode": 107.0, "critic_loss": 229.85488098144532, "critic_target_Q_variance_m=2": 14945.004875, "critic_Q1_variance_k=2": 6.9330957355499265, "critic_Q2_variance_k=2": 6.935603551864624, "actor_loss": -238.9315454392206, "actor_mean_entropy": -0.13818386711535, "alpha_loss": -0.0922757549773133, "alpha_value": 0.12964710924313272, "duration": 34.66753911972046, "step": 13375}
{"episode_reward": 760.0513748653007, "episode": 108.0, "critic_loss": 237.01761303710938, "critic_target_Q_variance_m=2": 15281.2490078125, "critic_Q1_variance_k=2": 7.030797933578492, "critic_Q2_variance_k=2": 6.956225660324097, "actor_loss": -241.45240586803806, "actor_mean_entropy": -0.12027428515495793, "alpha_loss": -0.08461088278601246, "alpha_value": 0.13052661149891237, "duration": 34.74665927886963, "step": 13500}
{"episode_reward": 764.2470465604478, "episode": 109.0, "critic_loss": 233.00217169189452, "critic_target_Q_variance_m=2": 15817.604375, "critic_Q1_variance_k=2": 7.066736549377441, "critic_Q2_variance_k=2": 7.088579702377319, "actor_loss": -245.87500169542102, "actor_mean_entropy": -0.21362809079980094, "alpha_loss": -0.08595203791582395, "alpha_value": 0.13136543489148214, "duration": 34.737252950668335, "step": 13625}
{"episode_reward": 671.7205415219755, "episode": 110.0, "critic_loss": 227.6386905517578, "critic_target_Q_variance_m=2": 16254.5559375, "critic_Q1_variance_k=2": 7.215692363739014, "critic_Q2_variance_k=2": 7.207922540664673, "actor_loss": -249.3272175942698, "actor_mean_entropy": -0.21016876237286675, "alpha_loss": -0.0887283252612237, "alpha_value": 0.13222927355966604, "duration": 35.033629417419434, "step": 13750}
{"episode_reward": 759.1365329044677, "episode": 111.0, "critic_loss": 221.99307049560548, "critic_target_Q_variance_m=2": 16673.5801796875, "critic_Q1_variance_k=2": 7.118696075439453, "critic_Q2_variance_k=2": 7.075873317718506, "actor_loss": -251.96104649135046, "actor_mean_entropy": -0.13523820013044371, "alpha_loss": -0.0865502774360634, "alpha_value": 0.13309618162496112, "duration": 34.61037254333496, "step": 13875}
{"episode_reward": 743.651344758527, "episode": 112.0, "critic_loss": 228.75428393554688, "critic_target_Q_variance_m=2": 17135.146890625, "critic_Q1_variance_k=2": 6.903708236694336, "critic_Q2_variance_k=2": 6.805805953979492, "actor_loss": -256.0209490868353, "actor_mean_entropy": -0.18280748001510097, "alpha_loss": -0.08718821796919068, "alpha_value": 0.13395173592305418, "duration": 34.36035394668579, "step": 14000}
{"episode_reward": 755.8600026366764, "episode": 113.0, "critic_loss": 206.9915135498047, "critic_target_Q_variance_m=2": 17558.7586953125, "critic_Q1_variance_k=2": 6.664015256881714, "critic_Q2_variance_k=2": 6.549971754074097, "actor_loss": -259.9967985607329, "actor_mean_entropy": -0.19236585486029822, "alpha_loss": -0.08603976980324775, "alpha_value": 0.13477910110926958, "duration": 34.754536628723145, "step": 14125}
{"episode_reward": 729.7014080697581, "episode": 114.0, "critic_loss": 239.70647094726561, "critic_target_Q_variance_m=2": 17892.4794453125, "critic_Q1_variance_k=2": 7.231600149154663, "critic_Q2_variance_k=2": 7.1772553310394285, "actor_loss": -261.27237775248864, "actor_mean_entropy": -0.15993139418142457, "alpha_loss": -0.08509386979764508, "alpha_value": 0.13563736063471668, "duration": 34.497249364852905, "step": 14250}
{"episode_reward": 766.7723062651471, "episode": 115.0, "critic_loss": 237.72289178466798, "critic_target_Q_variance_m=2": 18576.60378125, "critic_Q1_variance_k=2": 6.95047671508789, "critic_Q2_variance_k=2": 6.94884259223938, "actor_loss": -267.8928014361669, "actor_mean_entropy": -0.14825213121043312, "alpha_loss": -0.09952393907403188, "alpha_value": 0.13656238729025497, "duration": 34.51870679855347, "step": 14375}
{"episode_reward": 731.2380781296647, "episode": 116.0, "critic_loss": 221.90361993408203, "critic_target_Q_variance_m=2": 19002.029046875, "critic_Q1_variance_k=2": 6.961904224395752, "critic_Q2_variance_k=2": 7.001676614761353, "actor_loss": -270.2545904344128, "actor_mean_entropy": -0.08899952759665827, "alpha_loss": -0.08303518449106524, "alpha_value": 0.13747183334294835, "duration": 34.333348989486694, "step": 14500}
{"episode_reward": 750.5043899572927, "episode": 117.0, "critic_loss": 229.16266009521485, "critic_target_Q_variance_m=2": 19546.61734375, "critic_Q1_variance_k=2": 6.6001469440460205, "critic_Q2_variance_k=2": 6.64373903465271, "actor_loss": -273.3141881549169, "actor_mean_entropy": -0.09261257934664922, "alpha_loss": -0.08712233319169, "alpha_value": 0.13833701228821732, "duration": 34.66056299209595, "step": 14625}
{"episode_reward": 762.0247351293718, "episode": 118.0, "critic_loss": 209.71747387695314, "critic_target_Q_variance_m=2": 19971.8636875, "critic_Q1_variance_k=2": 6.419796152114868, "critic_Q2_variance_k=2": 6.4257404994964595, "actor_loss": -277.94749253795993, "actor_mean_entropy": -0.14096725978437932, "alpha_loss": -0.09043984625849032, "alpha_value": 0.13920230958682742, "duration": 34.62697076797485, "step": 14750}
{"episode_reward": 771.14402187876, "episode": 119.0, "critic_loss": 216.1121898803711, "critic_target_Q_variance_m=2": 20388.59846875, "critic_Q1_variance_k=2": 6.5808378562927246, "critic_Q2_variance_k=2": 6.648686414718628, "actor_loss": -280.8422275119358, "actor_mean_entropy": -0.17323380265207516, "alpha_loss": -0.09566854472671237, "alpha_value": 0.14014589905257147, "duration": 34.71012759208679, "step": 14875}
{"episode_reward": 679.978248928384, "episode": 120.0, "critic_loss": 235.28489392089844, "critic_target_Q_variance_m=2": 20899.726828125, "critic_Q1_variance_k=2": 6.79332381439209, "critic_Q2_variance_k=2": 6.7778151416778565, "actor_loss": -284.45830658943424, "actor_mean_entropy": -0.1052281045685372, "alpha_loss": -0.09622090249772995, "alpha_value": 0.14110967141130082, "duration": 34.51248526573181, "step": 15000}
{"episode_reward": 826.3020549833271, "episode": 121.0, "critic_loss": 213.46783380126953, "critic_target_Q_variance_m=2": 21472.400515625, "critic_Q1_variance_k=2": 6.786305131912232, "critic_Q2_variance_k=2": 6.749231592178345, "actor_loss": -288.2382560608879, "actor_mean_entropy": -0.16074909642338753, "alpha_loss": -0.09846638722552194, "alpha_value": 0.14211162896299193, "duration": 34.88912630081177, "step": 15125}
{"episode_reward": 783.4531109446873, "episode": 122.0, "critic_loss": 209.07978149414063, "critic_target_Q_variance_m=2": 21877.871921875, "critic_Q1_variance_k=2": 6.402416711807251, "critic_Q2_variance_k=2": 6.4770303840637204, "actor_loss": -291.28077746975805, "actor_mean_entropy": -0.13504404358325467, "alpha_loss": -0.08442226442838868, "alpha_value": 0.1430135816729175, "duration": 34.57053875923157, "step": 15250}
{"episode_reward": 787.0929630063947, "episode": 123.0, "critic_loss": 216.70424768066405, "critic_target_Q_variance_m=2": 22337.58075, "critic_Q1_variance_k=2": 6.737739711761475, "critic_Q2_variance_k=2": 6.767461069107056, "actor_loss": -294.5312005905878, "actor_mean_entropy": -0.12213952183013871, "alpha_loss": -0.08476918341503256, "alpha_value": 0.14385334365841856, "duration": 34.5287721157074, "step": 15375}
{"episode_reward": 743.2190832978463, "episode": 124.0, "critic_loss": 186.85286413574218, "critic_target_Q_variance_m=2": 22998.258875, "critic_Q1_variance_k=2": 5.899930875778198, "critic_Q2_variance_k=2": 5.827983213424683, "actor_loss": -298.1814206031061, "actor_mean_entropy": -0.13437739173851668, "alpha_loss": -0.07622966071170184, "alpha_value": 0.14466398094290595, "duration": 34.46678948402405, "step": 15500}
{"episode_reward": 750.6620122453232, "episode": 125.0, "critic_loss": 207.3782682495117, "critic_target_Q_variance_m=2": 23348.288703125, "critic_Q1_variance_k=2": 5.86983024597168, "critic_Q2_variance_k=2": 5.847898851394653, "actor_loss": -301.16317361498636, "actor_mean_entropy": -0.12192386273472082, "alpha_loss": -0.07908670586489495, "alpha_value": 0.14550698010784355, "duration": 34.65198612213135, "step": 15625}
{"episode_reward": 754.790876215292, "episode": 126.0, "critic_loss": 203.8998758544922, "critic_target_Q_variance_m=2": 23741.834, "critic_Q1_variance_k=2": 5.875016658782959, "critic_Q2_variance_k=2": 5.825907510757446, "actor_loss": -302.78131349625124, "actor_mean_entropy": -0.11343671624819117, "alpha_loss": -0.07759532891213894, "alpha_value": 0.14632031148189287, "duration": 34.48452830314636, "step": 15750}
{"episode_reward": 741.321006855887, "episode": 127.0, "critic_loss": 175.4894546508789, "critic_target_Q_variance_m=2": 24437.740109375, "critic_Q1_variance_k=2": 5.601916296005249, "critic_Q2_variance_k=2": 5.591840551376343, "actor_loss": -307.531255812872, "actor_mean_entropy": -0.1086293500922029, "alpha_loss": -0.071932691814644, "alpha_value": 0.14706714441532162, "duration": 35.18095064163208, "step": 15875}
{"episode_reward": 762.6428451496545, "episode": 128.0, "critic_loss": 188.16009716796876, "critic_target_Q_variance_m=2": 24806.857234375, "critic_Q1_variance_k=2": 5.689276647567749, "critic_Q2_variance_k=2": 5.630020999908448, "actor_loss": -310.947517641129, "actor_mean_entropy": -0.1612189407310178, "alpha_loss": -0.0840130262677708, "alpha_value": 0.1479155673883143, "duration": 34.478076457977295, "step": 16000}
{"episode_reward": 825.783338787942, "episode": 129.0, "critic_loss": 185.02896697998048, "critic_target_Q_variance_m=2": 25195.22515625, "critic_Q1_variance_k=2": 5.575513460159302, "critic_Q2_variance_k=2": 5.576665842056275, "actor_loss": -313.8503132169209, "actor_mean_entropy": -0.0938851090059394, "alpha_loss": -0.07694734916800544, "alpha_value": 0.14878096095613522, "duration": 34.66068434715271, "step": 16125}
{"episode_reward": 756.1749232542358, "episode": 130.0, "critic_loss": 186.88336749267577, "critic_target_Q_variance_m=2": 25771.842546875, "critic_Q1_variance_k=2": 5.39131137084961, "critic_Q2_variance_k=2": 5.402719717025757, "actor_loss": -316.5889395436933, "actor_mean_entropy": -0.15213674715449732, "alpha_loss": -0.07786742414558126, "alpha_value": 0.14961786220747553, "duration": 34.450591802597046, "step": 16250}
{"episode_reward": 734.6196773274509, "episode": 131.0, "critic_loss": 188.01060247802735, "critic_target_Q_variance_m=2": 26307.831, "critic_Q1_variance_k=2": 5.556176795959472, "critic_Q2_variance_k=2": 5.5980619487762455, "actor_loss": -320.5199182903956, "actor_mean_entropy": -0.14872754595818974, "alpha_loss": -0.06987120039642804, "alpha_value": 0.15042474269811743, "duration": 34.479400634765625, "step": 16375}
{"episode_reward": 807.9839382840902, "episode": 132.0, "critic_loss": 158.53620086669923, "critic_target_Q_variance_m=2": 26735.696328125, "critic_Q1_variance_k=2": 5.070586812973023, "critic_Q2_variance_k=2": 5.138809602737426, "actor_loss": -323.7736097766507, "actor_mean_entropy": -0.1527735598745846, "alpha_loss": -0.0694882205176738, "alpha_value": 0.1512015101572162, "duration": 34.44587540626526, "step": 16500}
{"episode_reward": 751.0665961539476, "episode": 133.0, "critic_loss": 152.9636982421875, "critic_target_Q_variance_m=2": 27408.011890625, "critic_Q1_variance_k=2": 4.7667168674469, "critic_Q2_variance_k=2": 4.7605946788787845, "actor_loss": -327.0256735181052, "actor_mean_entropy": -0.136545045035226, "alpha_loss": -0.06829967828733581, "alpha_value": 0.1519609375567796, "duration": 33.50281047821045, "step": 16625}
{"episode_reward": 764.2502762611668, "episode": 134.0, "critic_loss": 163.94902764892578, "critic_target_Q_variance_m=2": 27763.61903125, "critic_Q1_variance_k=2": 5.089738967895507, "critic_Q2_variance_k=2": 5.059434204101563, "actor_loss": -328.7005201770413, "actor_mean_entropy": -0.11656649428750238, "alpha_loss": -0.07431004845326947, "alpha_value": 0.15275354940194072, "duration": 34.7717719078064, "step": 16750}
{"episode_reward": 745.9475713826663, "episode": 135.0, "critic_loss": 163.8066596069336, "critic_target_Q_variance_m=2": 28197.654640625, "critic_Q1_variance_k=2": 4.786189315795898, "critic_Q2_variance_k=2": 4.7080062370300295, "actor_loss": -332.0629194955977, "actor_mean_entropy": -0.15107347647703828, "alpha_loss": -0.07277398946739379, "alpha_value": 0.15360922478389386, "duration": 34.862191915512085, "step": 16875}
{"episode_reward": 750.8122024571029, "episode": 136.0, "critic_loss": 151.6298491821289, "critic_target_Q_variance_m=2": 28778.093984375, "critic_Q1_variance_k=2": 4.614658329963684, "critic_Q2_variance_k=2": 4.657949228286743, "actor_loss": -335.38081458307084, "actor_mean_entropy": -0.13588995696796524, "alpha_loss": -0.06928661395044576, "alpha_value": 0.154426749029316, "duration": 34.47961711883545, "step": 17000}
{"episode_reward": 734.977250197903, "episode": 137.0, "critic_loss": 160.2529663696289, "critic_target_Q_variance_m=2": 29216.01553125, "critic_Q1_variance_k=2": 5.071430212020874, "critic_Q2_variance_k=2": 4.979762033462524, "actor_loss": -338.0122327047681, "actor_mean_entropy": -0.1157990170140115, "alpha_loss": -0.0717265826487352, "alpha_value": 0.15528115788109367, "duration": 34.98117661476135, "step": 17125}
{"episode_reward": 745.7204778958907, "episode": 138.0, "critic_loss": 170.31433563232423, "critic_target_Q_variance_m=2": 29686.5185625, "critic_Q1_variance_k=2": 5.3149007396698, "critic_Q2_variance_k=2": 5.310457576751709, "actor_loss": -340.9998843285345, "actor_mean_entropy": -0.2019161130151441, "alpha_loss": -0.07095501806226469, "alpha_value": 0.15611921832629364, "duration": 34.629995346069336, "step": 17250}
{"episode_reward": 825.3090814664752, "episode": 139.0, "critic_loss": 158.8450264892578, "critic_target_Q_variance_m=2": 30153.095859375, "critic_Q1_variance_k=2": 4.971680187225342, "critic_Q2_variance_k=2": 4.897341424942017, "actor_loss": -344.2157360258557, "actor_mean_entropy": -0.1444616201555445, "alpha_loss": -0.06760102093574547, "alpha_value": 0.15693986178866864, "duration": 34.863201379776, "step": 17375}
{"episode_reward": 762.6847494453009, "episode": 140.0, "critic_loss": 164.29187713623048, "critic_target_Q_variance_m=2": 30654.422828125, "critic_Q1_variance_k=2": 4.744672256469727, "critic_Q2_variance_k=2": 4.766913751602173, "actor_loss": -346.7783404934791, "actor_mean_entropy": -0.1336575229201586, "alpha_loss": -0.05852203978405845, "alpha_value": 0.1577133290784165, "duration": 34.365981340408325, "step": 17500}
{"episode_reward": 759.5672207843235, "episode": 141.0, "critic_loss": 156.85064654541014, "critic_target_Q_variance_m=2": 31255.04353125, "critic_Q1_variance_k=2": 4.584610821723938, "critic_Q2_variance_k=2": 4.561146996498108, "actor_loss": -350.0601312546503, "actor_mean_entropy": -0.13014152084314634, "alpha_loss": -0.0667011710475125, "alpha_value": 0.15846066192677732, "duration": 34.608275175094604, "step": 17625}
{"episode_reward": 745.5817282175974, "episode": 142.0, "critic_loss": 152.38239385986327, "critic_target_Q_variance_m=2": 31553.0191875, "critic_Q1_variance_k=2": 4.766687377929688, "critic_Q2_variance_k=2": 4.7316434965133665, "actor_loss": -351.62726666850426, "actor_mean_entropy": -0.18163361346289034, "alpha_loss": -0.06998359219681832, "alpha_value": 0.15933309967362724, "duration": 34.270989656448364, "step": 17750}
{"episode_reward": 740.3364090310031, "episode": 143.0, "critic_loss": 137.62312719726563, "critic_target_Q_variance_m=2": 32138.29653125, "critic_Q1_variance_k=2": 4.3960838108062745, "critic_Q2_variance_k=2": 4.401061260223389, "actor_loss": -354.6791774204799, "actor_mean_entropy": -0.1119237911724855, "alpha_loss": -0.060180475077931846, "alpha_value": 0.1601711894357816, "duration": 34.64816665649414, "step": 17875}
{"episode_reward": 731.0035356704986, "episode": 144.0, "critic_loss": 144.55429998779297, "critic_target_Q_variance_m=2": 32600.154265625, "critic_Q1_variance_k=2": 4.138245232582093, "critic_Q2_variance_k=2": 4.131495301246643, "actor_loss": -358.1509714434224, "actor_mean_entropy": -0.1986919807931108, "alpha_loss": -0.06975751033713741, "alpha_value": 0.16101365941844908, "duration": 34.40190553665161, "step": 18000}
{"episode_reward": 835.8398851500857, "episode": 145.0, "critic_loss": 132.82299627685546, "critic_target_Q_variance_m=2": 33085.989015625, "critic_Q1_variance_k=2": 4.2039034385681155, "critic_Q2_variance_k=2": 4.131615827560425, "actor_loss": -360.786614312066, "actor_mean_entropy": -0.1352354237248027, "alpha_loss": -0.06232864483599625, "alpha_value": 0.16186155128199095, "duration": 34.775519609451294, "step": 18125}
{"episode_reward": 759.1622567923527, "episode": 146.0, "critic_loss": 163.06658813476562, "critic_target_Q_variance_m=2": 33518.472390625, "critic_Q1_variance_k=2": 4.692024723052978, "critic_Q2_variance_k=2": 4.643674877166748, "actor_loss": -363.08460407872354, "actor_mean_entropy": -0.14004067181339186, "alpha_loss": -0.06643609846791913, "alpha_value": 0.1627574179886288, "duration": 34.61137628555298, "step": 18250}
{"episode_reward": 765.1898503444996, "episode": 147.0, "critic_loss": 174.06956829833985, "critic_target_Q_variance_m=2": 33979.353203125, "critic_Q1_variance_k=2": 5.0699898109436035, "critic_Q2_variance_k=2": 5.111345083236694, "actor_loss": -365.08471534365697, "actor_mean_entropy": -0.1622178852262478, "alpha_loss": -0.06366691336272255, "alpha_value": 0.16355722611205892, "duration": 34.64920902252197, "step": 18375}
{"episode_reward": 837.1834953924522, "episode": 148.0, "critic_loss": 143.09794909667968, "critic_target_Q_variance_m=2": 34494.8336875, "critic_Q1_variance_k=2": 4.110317184448242, "critic_Q2_variance_k=2": 4.131850531578064, "actor_loss": -368.56082251764116, "actor_mean_entropy": -0.05532803822068438, "alpha_loss": -0.05775547062888021, "alpha_value": 0.16441165302526625, "duration": 34.54026699066162, "step": 18500}
{"episode_reward": 704.31979214492, "episode": 149.0, "critic_loss": 156.01412438964843, "critic_target_Q_variance_m=2": 34943.48415625, "critic_Q1_variance_k=2": 4.752845579147339, "critic_Q2_variance_k=2": 4.775005506515503, "actor_loss": -370.7367631215898, "actor_mean_entropy": -0.22192890072862306, "alpha_loss": -0.07805704692053417, "alpha_value": 0.16529989816687599, "duration": 35.12983727455139, "step": 18625}
{"episode_reward": 818.9032401014543, "episode": 150.0, "critic_loss": 139.43290893554686, "critic_target_Q_variance_m=2": 35473.93625, "critic_Q1_variance_k=2": 4.375171261787415, "critic_Q2_variance_k=2": 4.3098175916671755, "actor_loss": -372.7156632946384, "actor_mean_entropy": -0.13671268633897266, "alpha_loss": -0.06374565163447012, "alpha_value": 0.16629588458493186, "duration": 34.35869574546814, "step": 18750}
{"episode_reward": 755.7734728230223, "episode": 151.0, "critic_loss": 144.0067216796875, "critic_target_Q_variance_m=2": 35893.3400625, "critic_Q1_variance_k=2": 4.451623058319091, "critic_Q2_variance_k=2": 4.383319620132446, "actor_loss": -375.827151343936, "actor_mean_entropy": -0.16130585885710186, "alpha_loss": -0.07149232102055399, "alpha_value": 0.16719402457005167, "duration": 34.62194752693176, "step": 18875}
{"episode_reward": 730.2192033087969, "episode": 152.0, "critic_loss": 141.35151388549804, "critic_target_Q_variance_m=2": 36435.748875, "critic_Q1_variance_k=2": 4.024236457824707, "critic_Q2_variance_k=2": 3.9165087633132933, "actor_loss": -378.4185579361454, "actor_mean_entropy": -0.1254625883434088, "alpha_loss": -0.06508873490196082, "alpha_value": 0.16816840711355216, "duration": 34.318989276885986, "step": 19000}
{"episode_reward": 731.2181899076082, "episode": 153.0, "critic_loss": 148.51216693115234, "critic_target_Q_variance_m=2": 36824.72490625, "critic_Q1_variance_k=2": 4.199852097511291, "critic_Q2_variance_k=2": 4.247052491188049, "actor_loss": -381.01507471478175, "actor_mean_entropy": -0.07405257189557665, "alpha_loss": -0.06157167521970613, "alpha_value": 0.16905155098905714, "duration": 34.49929332733154, "step": 19125}
{"episode_reward": 755.8698730567621, "episode": 154.0, "critic_loss": 142.09247900390625, "critic_target_Q_variance_m=2": 37390.76728125, "critic_Q1_variance_k=2": 4.336454248428344, "critic_Q2_variance_k=2": 4.301268313407898, "actor_loss": -384.16076118715347, "actor_mean_entropy": -0.12127611563811379, "alpha_loss": -0.05704856304932506, "alpha_value": 0.16990749098566335, "duration": 34.313498735427856, "step": 19250}
{"episode_reward": 756.0304986547516, "episode": 155.0, "critic_loss": 149.96723272705077, "critic_target_Q_variance_m=2": 37837.31446875, "critic_Q1_variance_k=2": 4.308535967826844, "critic_Q2_variance_k=2": 4.243500973701477, "actor_loss": -385.6156848725818, "actor_mean_entropy": -0.13555795557442166, "alpha_loss": -0.05646371220548948, "alpha_value": 0.17072526931757454, "duration": 34.821340560913086, "step": 19375}
{"episode_reward": 827.8504693689468, "episode": 156.0, "critic_loss": 148.61601623535157, "critic_target_Q_variance_m=2": 38194.17184375, "critic_Q1_variance_k=2": 4.5802042169570925, "critic_Q2_variance_k=2": 4.650568880081177, "actor_loss": -388.23270686980214, "actor_mean_entropy": -0.10383713587878211, "alpha_loss": -0.06272179381020608, "alpha_value": 0.17157637633833034, "duration": 34.3293035030365, "step": 19500}
{"episode_reward": 750.2074573405364, "episode": 157.0, "critic_loss": 152.17542395019532, "critic_target_Q_variance_m=2": 38589.1935, "critic_Q1_variance_k=2": 4.4394779901504515, "critic_Q2_variance_k=2": 4.3968708648681645, "actor_loss": -390.3290279327877, "actor_mean_entropy": -0.11537405966766297, "alpha_loss": -0.053048122615095165, "alpha_value": 0.17247041310640487, "duration": 34.62010216712952, "step": 19625}
{"episode_reward": 804.4703683271224, "episode": 158.0, "critic_loss": 154.78709130859374, "critic_target_Q_variance_m=2": 39282.27871875, "critic_Q1_variance_k=2": 4.523631081581116, "critic_Q2_variance_k=2": 4.484248184204102, "actor_loss": -393.46331836331274, "actor_mean_entropy": -0.15236636791979113, "alpha_loss": -0.04821785929943285, "alpha_value": 0.17325617891125208, "duration": 34.82304906845093, "step": 19750}
{"episode_reward": 794.7776285640149, "episode": 159.0, "critic_loss": 157.88343963623046, "critic_target_Q_variance_m=2": 39628.972625, "critic_Q1_variance_k=2": 4.4085818271636965, "critic_Q2_variance_k=2": 4.337293704032898, "actor_loss": -395.2921622140067, "actor_mean_entropy": -0.12627616563131885, "alpha_loss": -0.0554606540660773, "alpha_value": 0.17398721780747492, "duration": 34.94807505607605, "step": 19875}
{"episode_reward": 823.3461131033176, "episode": 160.0, "critic_loss": 138.1838920288086, "critic_target_Q_variance_m=2": 40284.83371875, "critic_Q1_variance_k=2": 4.137704030990601, "critic_Q2_variance_k=2": 4.1041170663833615, "actor_loss": -398.9646783644153, "actor_mean_entropy": -0.09005329427459548, "alpha_loss": -0.05145190043314811, "alpha_value": 0.17485352386659458, "duration": 34.426032304763794, "step": 20000}
{"episode_reward": 743.5532382332791, "episode": 161.0, "critic_loss": 153.5343074951172, "critic_target_Q_variance_m=2": 40523.3889375, "critic_Q1_variance_k=2": 4.3349293575286865, "critic_Q2_variance_k=2": 4.417703640937805, "actor_loss": -399.70421442909844, "actor_mean_entropy": -0.19834525646671416, "alpha_loss": -0.05680867160360018, "alpha_value": 0.17568940289835597, "duration": 36.799869775772095, "step": 20125}
{"episode_reward": 681.0221664870068, "episode": 162.0, "critic_loss": 135.2392249145508, "critic_target_Q_variance_m=2": 40969.595375, "critic_Q1_variance_k=2": 4.005287034988403, "critic_Q2_variance_k=2": 4.008001796722412, "actor_loss": -402.47460445280996, "actor_mean_entropy": -0.14647864940906724, "alpha_loss": -0.053450943391409614, "alpha_value": 0.176579618774286, "duration": 32.754992961883545, "step": 20250}
{"episode_reward": 837.1254026453981, "episode": 163.0, "critic_loss": 137.90071365356445, "critic_target_Q_variance_m=2": 41535.16346875, "critic_Q1_variance_k=2": 3.8486577749252318, "critic_Q2_variance_k=2": 3.8258621644973756, "actor_loss": -405.4267820328001, "actor_mean_entropy": -0.13924956845030897, "alpha_loss": -0.05784244570762865, "alpha_value": 0.17752483577999761, "duration": 34.65436577796936, "step": 20375}
{"episode_reward": 806.4237390333853, "episode": 164.0, "critic_loss": 154.7477553100586, "critic_target_Q_variance_m=2": 41791.33571875, "critic_Q1_variance_k=2": 4.63261954498291, "critic_Q2_variance_k=2": 4.612015087127686, "actor_loss": -405.5120455834173, "actor_mean_entropy": -0.13764601170776353, "alpha_loss": -0.04900521587490315, "alpha_value": 0.17839603673752735, "duration": 34.59864544868469, "step": 20500}
{"episode_reward": 820.5560947165184, "episode": 165.0, "critic_loss": 159.87711083984374, "critic_target_Q_variance_m=2": 42385.86365625, "critic_Q1_variance_k=2": 4.602696473121643, "critic_Q2_variance_k=2": 4.513914283752442, "actor_loss": -408.7964007665241, "actor_mean_entropy": -0.017401670445761984, "alpha_loss": -0.04369143404746576, "alpha_value": 0.17919029524218702, "duration": 34.63881850242615, "step": 20625}
{"episode_reward": 774.6213181507105, "episode": 166.0, "critic_loss": 127.59730279541016, "critic_target_Q_variance_m=2": 42853.85178125, "critic_Q1_variance_k=2": 3.804386301994324, "critic_Q2_variance_k=2": 3.807655159950256, "actor_loss": -410.94000441028226, "actor_mean_entropy": -0.159455411346449, "alpha_loss": -0.046078486307974786, "alpha_value": 0.17984033788574144, "duration": 34.57604694366455, "step": 20750}
{"episode_reward": 766.1089638465786, "episode": 167.0, "critic_loss": 137.9290464477539, "critic_target_Q_variance_m=2": 43309.3104375, "critic_Q1_variance_k=2": 4.313253558158874, "critic_Q2_variance_k=2": 4.343315380096436, "actor_loss": -412.7288411458333, "actor_mean_entropy": -0.10092933138921148, "alpha_loss": -0.052197175418278056, "alpha_value": 0.18074634428269704, "duration": 34.888927698135376, "step": 20875}
{"episode_reward": 832.6206539885886, "episode": 168.0, "critic_loss": 147.70512255859376, "critic_target_Q_variance_m=2": 43709.2266875, "critic_Q1_variance_k=2": 4.306087655067444, "critic_Q2_variance_k=2": 4.370827387809753, "actor_loss": -415.3870332779423, "actor_mean_entropy": -0.16170574400213458, "alpha_loss": -0.05403193651187804, "alpha_value": 0.18167726490025668, "duration": 34.32044982910156, "step": 21000}
{"episode_reward": 824.1167190867448, "episode": 169.0, "critic_loss": 153.70263037109376, "critic_target_Q_variance_m=2": 44244.74640625, "critic_Q1_variance_k=2": 4.523236752510071, "critic_Q2_variance_k=2": 4.542720350265503, "actor_loss": -417.9916730608259, "actor_mean_entropy": -0.22054583292513613, "alpha_loss": -0.05383560405896297, "alpha_value": 0.1826129443552344, "duration": 34.47577738761902, "step": 21125}
{"episode_reward": 756.2396237337842, "episode": 170.0, "critic_loss": 141.40040420532227, "critic_target_Q_variance_m=2": 44831.702625, "critic_Q1_variance_k=2": 3.8938322744369507, "critic_Q2_variance_k=2": 3.8497000064849853, "actor_loss": -419.4776645783455, "actor_mean_entropy": -0.013338572495887357, "alpha_loss": -0.049018477893344334, "alpha_value": 0.1835135796009412, "duration": 34.48647618293762, "step": 21250}
{"episode_reward": 744.4980455574596, "episode": 171.0, "critic_loss": 132.56422302246094, "critic_target_Q_variance_m=2": 45273.8406875, "critic_Q1_variance_k=2": 3.9697655210494993, "critic_Q2_variance_k=2": 3.9238224258422854, "actor_loss": -422.257072327629, "actor_mean_entropy": -0.11455887848777431, "alpha_loss": -0.0450453290656682, "alpha_value": 0.1843852863405543, "duration": 34.618539810180664, "step": 21375}
{"episode_reward": 746.3937733080571, "episode": 172.0, "critic_loss": 139.06645141601564, "critic_target_Q_variance_m=2": 45482.55925, "critic_Q1_variance_k=2": 4.085503454208374, "critic_Q2_variance_k=2": 4.063179798126221, "actor_loss": -422.9449994487147, "actor_mean_entropy": -0.10337495942029261, "alpha_loss": -0.04541639289668491, "alpha_value": 0.18519697089579337, "duration": 34.45080518722534, "step": 21500}
{"episode_reward": 807.7905173631374, "episode": 173.0, "critic_loss": 145.5435881958008, "critic_target_Q_variance_m=2": 46114.50284375, "critic_Q1_variance_k=2": 4.134670571327209, "critic_Q2_variance_k=2": 4.066853692054749, "actor_loss": -426.57375081380206, "actor_mean_entropy": -0.09138587232501734, "alpha_loss": -0.04281902167620876, "alpha_value": 0.18603066704354881, "duration": 34.78288245201111, "step": 21625}
{"episode_reward": 836.2593686605044, "episode": 174.0, "critic_loss": 135.54350732421875, "critic_target_Q_variance_m=2": 46603.090125, "critic_Q1_variance_k=2": 4.2371910238265995, "critic_Q2_variance_k=2": 4.212064016342163, "actor_loss": -429.6034737863848, "actor_mean_entropy": -0.12341171863578981, "alpha_loss": -0.03397179606010116, "alpha_value": 0.18673251636197813, "duration": 34.57346868515015, "step": 21750}
{"episode_reward": 813.6905991247116, "episode": 175.0, "critic_loss": 152.85142114257812, "critic_target_Q_variance_m=2": 47147.94525, "critic_Q1_variance_k=2": 4.229272261619568, "critic_Q2_variance_k=2": 4.128745933532715, "actor_loss": -431.1531255812872, "actor_mean_entropy": -0.0812951076539263, "alpha_loss": -0.0384578035390448, "alpha_value": 0.18744414704355505, "duration": 34.631006956100464, "step": 21875}
{"episode_reward": 748.8729179518365, "episode": 176.0, "critic_loss": 148.8575089111328, "critic_target_Q_variance_m=2": 47376.15778125, "critic_Q1_variance_k=2": 4.084988610267639, "critic_Q2_variance_k=2": 4.086516084671021, "actor_loss": -432.2761722687752, "actor_mean_entropy": -0.03323902931785391, "alpha_loss": -0.0450623024014696, "alpha_value": 0.1882733026041208, "duration": 34.360950231552124, "step": 22000}
{"episode_reward": 727.6238012977218, "episode": 177.0, "critic_loss": 140.62768353271485, "critic_target_Q_variance_m=2": 47935.24671875, "critic_Q1_variance_k=2": 4.096035536766053, "critic_Q2_variance_k=2": 4.090267333984375, "actor_loss": -434.66882857065355, "actor_mean_entropy": -0.11389197382543768, "alpha_loss": -0.04815066622067538, "alpha_value": 0.18922985026520153, "duration": 34.56870913505554, "step": 22125}
{"episode_reward": 755.248883244349, "episode": 178.0, "critic_loss": 133.8295655517578, "critic_target_Q_variance_m=2": 48361.73009375, "critic_Q1_variance_k=2": 4.001431941986084, "critic_Q2_variance_k=2": 4.013377885818482, "actor_loss": -437.15600093718496, "actor_mean_entropy": -0.14653872914852634, "alpha_loss": -0.03929626780201591, "alpha_value": 0.19008074794384713, "duration": 34.358248472213745, "step": 22250}
{"episode_reward": 753.0761304252904, "episode": 179.0, "critic_loss": 137.0246076660156, "critic_target_Q_variance_m=2": 48910.11115625, "critic_Q1_variance_k=2": 3.8568437757492067, "critic_Q2_variance_k=2": 3.8687931060791017, "actor_loss": -439.76644752139134, "actor_mean_entropy": -0.10136530997734221, "alpha_loss": -0.03907054304958336, "alpha_value": 0.1908502861774615, "duration": 34.75016450881958, "step": 22375}
{"episode_reward": 809.3314720695479, "episode": 180.0, "critic_loss": 145.19094485473633, "critic_target_Q_variance_m=2": 49187.95959375, "critic_Q1_variance_k=2": 4.22111025428772, "critic_Q2_variance_k=2": 4.164074337005615, "actor_loss": -441.57623044906126, "actor_mean_entropy": -0.10941830043110155, "alpha_loss": -0.031878945537872856, "alpha_value": 0.19154811068301744, "duration": 34.47448945045471, "step": 22500}
{"episode_reward": 684.6456016593372, "episode": 181.0, "critic_loss": 131.31804388427733, "critic_target_Q_variance_m=2": 49478.80865625, "critic_Q1_variance_k=2": 3.9580696392059327, "critic_Q2_variance_k=2": 3.972078553199768, "actor_loss": -441.49902973477805, "actor_mean_entropy": -0.065927963526476, "alpha_loss": -0.04403055945618285, "alpha_value": 0.1923722659372977, "duration": 34.57075572013855, "step": 22625}
{"episode_reward": 753.6484908874266, "episode": 182.0, "critic_loss": 138.95447924804688, "critic_target_Q_variance_m=2": 50038.02925, "critic_Q1_variance_k=2": 3.8762537851333616, "critic_Q2_variance_k=2": 3.7828486814498903, "actor_loss": -443.93291645665323, "actor_mean_entropy": -0.07980841488367127, "alpha_loss": -0.029878086027418895, "alpha_value": 0.19318604379558443, "duration": 34.628857135772705, "step": 22750}
{"episode_reward": 769.7016503782916, "episode": 183.0, "critic_loss": 136.34377407836914, "critic_target_Q_variance_m=2": 50639.32153125, "critic_Q1_variance_k=2": 3.6984095249176026, "critic_Q2_variance_k=2": 3.7175707397460935, "actor_loss": -447.64659433516243, "actor_mean_entropy": -0.07434042034641145, "alpha_loss": -0.039691370793633045, "alpha_value": 0.1939490178008474, "duration": 34.65105891227722, "step": 22875}
{"episode_reward": 810.1466629523128, "episode": 184.0, "critic_loss": 127.04872842407227, "critic_target_Q_variance_m=2": 50895.4914375, "critic_Q1_variance_k=2": 3.6829486541748047, "critic_Q2_variance_k=2": 3.7158054618835448, "actor_loss": -448.67298544606854, "actor_mean_entropy": -0.07291388794058754, "alpha_loss": -0.041304330476709915, "alpha_value": 0.1948720360656871, "duration": 34.384761571884155, "step": 23000}
{"episode_reward": 814.0358134763638, "episode": 185.0, "critic_loss": 128.29170397949218, "critic_target_Q_variance_m=2": 51334.68978125, "critic_Q1_variance_k=2": 3.6128501329422, "critic_Q2_variance_k=2": 3.5870035219192506, "actor_loss": -451.0721735878596, "actor_mean_entropy": -0.12131370799172492, "alpha_loss": -0.03531856218441611, "alpha_value": 0.1957119504286403, "duration": 34.91651129722595, "step": 23125}
{"episode_reward": 837.5980314234706, "episode": 186.0, "critic_loss": 126.6340055847168, "critic_target_Q_variance_m=2": 51964.57553125, "critic_Q1_variance_k=2": 3.705423377990723, "critic_Q2_variance_k=2": 3.7217086629867553, "actor_loss": -453.98259858162174, "actor_mean_entropy": -0.11994564705978959, "alpha_loss": -0.02912373354868783, "alpha_value": 0.1964280790949931, "duration": 34.398852586746216, "step": 23250}
{"episode_reward": 726.513718402095, "episode": 187.0, "critic_loss": 144.43107537841797, "critic_target_Q_variance_m=2": 52371.2096875, "critic_Q1_variance_k=2": 3.8252154483795167, "critic_Q2_variance_k=2": 3.886957155227661, "actor_loss": -455.344236343626, "actor_mean_entropy": -0.06572971853708463, "alpha_loss": -0.03449523978910986, "alpha_value": 0.19714776537442089, "duration": 34.67624521255493, "step": 23375}
{"episode_reward": 770.9717173552594, "episode": 188.0, "critic_loss": 127.00854138183594, "critic_target_Q_variance_m=2": 52575.737625, "critic_Q1_variance_k=2": 3.7023015298843385, "critic_Q2_variance_k=2": 3.723463785171509, "actor_loss": -455.48758229901716, "actor_mean_entropy": -0.023254860733305256, "alpha_loss": -0.046093534099899476, "alpha_value": 0.198058677691486, "duration": 34.41949534416199, "step": 23500}
{"episode_reward": 811.2105647708704, "episode": 189.0, "critic_loss": 159.46714407348634, "critic_target_Q_variance_m=2": 53083.6281875, "critic_Q1_variance_k=2": 4.15064797782898, "critic_Q2_variance_k=2": 4.120926113128662, "actor_loss": -458.56072707403274, "actor_mean_entropy": -0.01510087311977432, "alpha_loss": -0.030092944856733084, "alpha_value": 0.1989544341772, "duration": 34.78829550743103, "step": 23625}
{"episode_reward": 706.5905571961584, "episode": 190.0, "critic_loss": 130.77358868408203, "critic_target_Q_variance_m=2": 53737.42809375, "critic_Q1_variance_k=2": 3.558293797492981, "critic_Q2_variance_k=2": 3.5144693460464476, "actor_loss": -461.54542590725805, "actor_mean_entropy": 0.029602530322247935, "alpha_loss": -0.020695790096426442, "alpha_value": 0.19965040264338518, "duration": 34.365097761154175, "step": 23750}
{"episode_reward": 814.1644350423577, "episode": 191.0, "critic_loss": 116.86367837524413, "critic_target_Q_variance_m=2": 53838.74540625, "critic_Q1_variance_k=2": 3.4761497621536255, "critic_Q2_variance_k=2": 3.4155001916885377, "actor_loss": -461.50038364955356, "actor_mean_entropy": 0.01304509857344249, "alpha_loss": -0.013429810219104327, "alpha_value": 0.20005994864171353, "duration": 34.980682611465454, "step": 23875}
{"episode_reward": 642.7019115368329, "episode": 192.0, "critic_loss": 122.46598385620118, "critic_target_Q_variance_m=2": 54584.055, "critic_Q1_variance_k=2": 3.578623818397522, "critic_Q2_variance_k=2": 3.566159331321716, "actor_loss": -464.67076652280747, "actor_mean_entropy": -0.1223707879863439, "alpha_loss": -0.020715414561451442, "alpha_value": 0.20038027080555137, "duration": 34.54413151741028, "step": 24000}
{"episode_reward": 790.4863940048282, "episode": 193.0, "critic_loss": 124.92151077270508, "critic_target_Q_variance_m=2": 54782.0985, "critic_Q1_variance_k=2": 3.776820990562439, "critic_Q2_variance_k=2": 3.756867241859436, "actor_loss": -465.7791462247334, "actor_mean_entropy": -0.013153841216412802, "alpha_loss": -0.03129179183659809, "alpha_value": 0.20112426840964856, "duration": 34.77208399772644, "step": 24125}
{"episode_reward": 779.3352757353563, "episode": 194.0, "critic_loss": 130.36489193725586, "critic_target_Q_variance_m=2": 55157.3698125, "critic_Q1_variance_k=2": 3.565573709487915, "critic_Q2_variance_k=2": 3.581608221054077, "actor_loss": -467.2188641948085, "actor_mean_entropy": -0.08802899904549122, "alpha_loss": -0.027108331627753234, "alpha_value": 0.20187381299393098, "duration": 34.34757208824158, "step": 24250}
{"episode_reward": 799.8706266576625, "episode": 195.0, "critic_loss": 124.66269012451171, "critic_target_Q_variance_m=2": 55610.79978125, "critic_Q1_variance_k=2": 3.4750063867568968, "critic_Q2_variance_k=2": 3.5140808191299437, "actor_loss": -469.4891318669395, "actor_mean_entropy": -0.029062610622199756, "alpha_loss": -0.01670172880034125, "alpha_value": 0.2024677871174809, "duration": 34.6737699508667, "step": 24375}
{"episode_reward": 777.6211868329874, "episode": 196.0, "critic_loss": 110.69050814819336, "critic_target_Q_variance_m=2": 55965.60121875, "critic_Q1_variance_k=2": 3.4231983385086058, "critic_Q2_variance_k=2": 3.456504720687866, "actor_loss": -470.6781793409778, "actor_mean_entropy": 0.009735775811056937, "alpha_loss": -0.015581554560471446, "alpha_value": 0.2028641999381467, "duration": 34.36834979057312, "step": 24500}
{"episode_reward": 727.1159971967396, "episode": 197.0, "critic_loss": 131.95497500610352, "critic_target_Q_variance_m=2": 56452.80296875, "critic_Q1_variance_k=2": 3.549203712463379, "critic_Q2_variance_k=2": 3.5980660724639892, "actor_loss": -472.71495758541045, "actor_mean_entropy": -0.010906011191388917, "alpha_loss": -0.03177940416046315, "alpha_value": 0.2035426133555405, "duration": 34.69126343727112, "step": 24625}
{"episode_reward": 745.3181199328338, "episode": 198.0, "critic_loss": 130.33557415771483, "critic_target_Q_variance_m=2": 57075.7603125, "critic_Q1_variance_k=2": 3.6523143787384034, "critic_Q2_variance_k=2": 3.6696407098770143, "actor_loss": -476.1894969324912, "actor_mean_entropy": -0.09623140228852149, "alpha_loss": -0.02661321029036997, "alpha_value": 0.2042509986398047, "duration": 34.31927943229675, "step": 24750}
{"episode_reward": 821.5484994859513, "episode": 199.0, "critic_loss": 124.36366387939454, "critic_target_Q_variance_m=2": 57131.280375, "critic_Q1_variance_k=2": 3.5589361333847047, "critic_Q2_variance_k=2": 3.534867594718933, "actor_loss": -475.0682101779514, "actor_mean_entropy": -0.050066025306781135, "alpha_loss": -0.025380560706946113, "alpha_value": 0.20509001490294693, "duration": 34.660228967666626, "step": 24875}
{"episode_reward": 802.9093963824258, "episode": 200.0, "critic_loss": 120.1271212463379, "critic_target_Q_variance_m=2": 57724.9993125, "critic_Q1_variance_k=2": 3.4626135835647585, "critic_Q2_variance_k=2": 3.4570434198379516, "actor_loss": -479.19701902328, "actor_mean_entropy": -0.08866050839424133, "alpha_loss": -0.02013686317349634, "alpha_value": 0.2057483949433522, "duration": 34.400962591171265, "step": 25000}
{"episode_reward": 829.9210006716912, "episode": 201.0, "critic_loss": 125.86015957641601, "critic_target_Q_variance_m=2": 58143.64171875, "critic_Q1_variance_k=2": 3.490164298057556, "critic_Q2_variance_k=2": 3.395895320892334, "actor_loss": -479.6375872899616, "actor_mean_entropy": -0.029912059683175313, "alpha_loss": -0.019056492448148745, "alpha_value": 0.2062369498468715, "duration": 34.615718603134155, "step": 25125}
{"episode_reward": 742.9084817018752, "episode": 202.0, "critic_loss": 119.19891394042969, "critic_target_Q_variance_m=2": 58586.28828125, "critic_Q1_variance_k=2": 3.467004294395447, "critic_Q2_variance_k=2": 3.523348104476929, "actor_loss": -481.4938211748677, "actor_mean_entropy": -0.050768771779633334, "alpha_loss": -0.02583693936392064, "alpha_value": 0.20693541312344896, "duration": 34.34303855895996, "step": 25250}
{"episode_reward": 764.439301346295, "episode": 203.0, "critic_loss": 121.85990353393555, "critic_target_Q_variance_m=2": 59092.20971875, "critic_Q1_variance_k=2": 3.4134134407043457, "critic_Q2_variance_k=2": 3.3518703346252443, "actor_loss": -483.96163262261285, "actor_mean_entropy": -0.08268516936472484, "alpha_loss": -0.01866706428561537, "alpha_value": 0.20759762514374175, "duration": 34.74035143852234, "step": 25375}
{"episode_reward": 758.0375930329762, "episode": 204.0, "critic_loss": 125.77107897949219, "critic_target_Q_variance_m=2": 59320.4940625, "critic_Q1_variance_k=2": 3.286294722557068, "critic_Q2_variance_k=2": 3.2628290615081785, "actor_loss": -484.8645964591734, "actor_mean_entropy": -0.059872702304874695, "alpha_loss": -0.022428603621289855, "alpha_value": 0.20821062046297448, "duration": 35.10425162315369, "step": 25500}
{"episode_reward": 802.5171625766465, "episode": 205.0, "critic_loss": 115.28686001586914, "critic_target_Q_variance_m=2": 59970.067125, "critic_Q1_variance_k=2": 3.2349421586990355, "critic_Q2_variance_k=2": 3.1326654348373415, "actor_loss": -488.1725841703869, "actor_mean_entropy": 0.007135554704637755, "alpha_loss": -0.011468473378391493, "alpha_value": 0.2087830818848678, "duration": 34.853506565093994, "step": 25625}
{"episode_reward": 764.739726106233, "episode": 206.0, "critic_loss": 126.36288729858398, "critic_target_Q_variance_m=2": 60338.1414375, "critic_Q1_variance_k=2": 3.567316514015198, "critic_Q2_variance_k=2": 3.4139031772613526, "actor_loss": -489.236824281754, "actor_mean_entropy": -0.03498571501263688, "alpha_loss": -0.009985322925081898, "alpha_value": 0.2090687950123408, "duration": 34.36670279502869, "step": 25750}
{"episode_reward": 812.4120782296976, "episode": 207.0, "critic_loss": 118.6239150390625, "critic_target_Q_variance_m=2": 60684.34234375, "critic_Q1_variance_k=2": 3.37027249622345, "critic_Q2_variance_k=2": 3.338480975151062, "actor_loss": -490.9866783505394, "actor_mean_entropy": -0.06083506124005431, "alpha_loss": -0.012912109287248718, "alpha_value": 0.2095257301408691, "duration": 34.538769483566284, "step": 25875}
{"episode_reward": 722.0288490848488, "episode": 208.0, "critic_loss": 113.85021621704101, "critic_target_Q_variance_m=2": 61098.84459375, "critic_Q1_variance_k=2": 3.0528157501220705, "critic_Q2_variance_k=2": 2.926013963699341, "actor_loss": -492.14766077841483, "actor_mean_entropy": -0.06544213519702034, "alpha_loss": -0.019851179973733042, "alpha_value": 0.21002019299697913, "duration": 34.45133972167969, "step": 26000}
{"episode_reward": 767.0670545660907, "episode": 209.0, "critic_loss": 107.31365463256836, "critic_target_Q_variance_m=2": 61604.75303125, "critic_Q1_variance_k=2": 3.040112913131714, "critic_Q2_variance_k=2": 3.0703652219772337, "actor_loss": -494.38499717106896, "actor_mean_entropy": -0.00479646630230404, "alpha_loss": -0.019398457777228147, "alpha_value": 0.2107251466908096, "duration": 34.64019060134888, "step": 26125}
{"episode_reward": 818.739288327081, "episode": 210.0, "critic_loss": 113.79126461791992, "critic_target_Q_variance_m=2": 61905.49, "critic_Q1_variance_k=2": 3.1969041175842285, "critic_Q2_variance_k=2": 3.191275185585022, "actor_loss": -495.4697930120653, "actor_mean_entropy": -0.047213232324969386, "alpha_loss": -0.025972758990622336, "alpha_value": 0.21134957566620324, "duration": 34.48175024986267, "step": 26250}
{"episode_reward": 756.7701700277854, "episode": 211.0, "critic_loss": 121.15733972167969, "critic_target_Q_variance_m=2": 62091.386, "critic_Q1_variance_k=2": 3.3552935791015623, "critic_Q2_variance_k=2": 3.320398832321167, "actor_loss": -496.50377303834944, "actor_mean_entropy": -0.060056970587798526, "alpha_loss": -0.019726974213318454, "alpha_value": 0.2121621815310756, "duration": 34.53136444091797, "step": 26375}
{"episode_reward": 661.7940736713465, "episode": 212.0, "critic_loss": 109.89801013183593, "critic_target_Q_variance_m=2": 62572.87921875, "critic_Q1_variance_k=2": 3.1638823347091676, "critic_Q2_variance_k=2": 3.160628225326538, "actor_loss": -498.583987820533, "actor_mean_entropy": -0.046134605192609375, "alpha_loss": -0.017191548437450924, "alpha_value": 0.21278219887056818, "duration": 34.511080265045166, "step": 26500}
{"episode_reward": 772.8591649033464, "episode": 213.0, "critic_loss": 128.33462860107423, "critic_target_Q_variance_m=2": 62927.01321875, "critic_Q1_variance_k=2": 3.011481972694397, "critic_Q2_variance_k=2": 2.988094920158386, "actor_loss": -499.12155102926585, "actor_mean_entropy": -0.03708676656796819, "alpha_loss": -0.012963266012125782, "alpha_value": 0.21330350871465065, "duration": 33.906556129455566, "step": 26625}
{"episode_reward": 811.8342895974724, "episode": 214.0, "critic_loss": 121.76197442626953, "critic_target_Q_variance_m=2": 63458.85365625, "critic_Q1_variance_k=2": 3.152226470947266, "critic_Q2_variance_k=2": 3.09041641998291, "actor_loss": -501.67293966970135, "actor_mean_entropy": 0.02840590531066541, "alpha_loss": -0.008466567889216446, "alpha_value": 0.2136378768343747, "duration": 34.77537226676941, "step": 26750}
{"episode_reward": 753.0283227274136, "episode": 215.0, "critic_loss": 122.55451635742187, "critic_target_Q_variance_m=2": 63639.53975, "critic_Q1_variance_k=2": 3.144068365097046, "critic_Q2_variance_k=2": 3.120325489997864, "actor_loss": -502.83360799153644, "actor_mean_entropy": 0.017273848610264913, "alpha_loss": -0.010158506606424611, "alpha_value": 0.21399019283708381, "duration": 34.787474632263184, "step": 26875}
{"episode_reward": 742.1196831014247, "episode": 216.0, "critic_loss": 131.52294671630858, "critic_target_Q_variance_m=2": 64090.9508125, "critic_Q1_variance_k=2": 3.5390669193267823, "critic_Q2_variance_k=2": 3.5279210834503174, "actor_loss": -504.4634748889554, "actor_mean_entropy": 0.0043611180998625295, "alpha_loss": -0.014360641046697575, "alpha_value": 0.21447220077372958, "duration": 34.795668601989746, "step": 27000}
{"episode_reward": 755.8373864269043, "episode": 217.0, "critic_loss": 108.36142309570313, "critic_target_Q_variance_m=2": 64497.61815625, "critic_Q1_variance_k=2": 3.1401270513534545, "critic_Q2_variance_k=2": 3.064360447883606, "actor_loss": -506.6161610436818, "actor_mean_entropy": -0.04697761888660136, "alpha_loss": -0.014129464174546892, "alpha_value": 0.21498924452464357, "duration": 35.014119386672974, "step": 27125}
{"episode_reward": 741.716133615507, "episode": 218.0, "critic_loss": 104.9326487121582, "critic_target_Q_variance_m=2": 64898.9555625, "critic_Q1_variance_k=2": 3.0513243188858032, "critic_Q2_variance_k=2": 3.0824010171890257, "actor_loss": -507.1554909982989, "actor_mean_entropy": -0.04737046078568505, "alpha_loss": -0.017919629500547964, "alpha_value": 0.2155878222704545, "duration": 34.642249584198, "step": 27250}
{"episode_reward": 789.5307219078309, "episode": 219.0, "critic_loss": 107.7185636291504, "critic_target_Q_variance_m=2": 65218.008375, "critic_Q1_variance_k=2": 2.923053451538086, "critic_Q2_variance_k=2": 2.859648449897766, "actor_loss": -508.4689335898748, "actor_mean_entropy": -0.07772493457037305, "alpha_loss": -0.012882486599246188, "alpha_value": 0.21607878733509156, "duration": 35.20404243469238, "step": 27375}
{"episode_reward": 794.4574442790595, "episode": 220.0, "critic_loss": 117.94639666748047, "critic_target_Q_variance_m=2": 65532.59909375, "critic_Q1_variance_k=2": 3.4655975999832154, "critic_Q2_variance_k=2": 3.490158452987671, "actor_loss": -509.65464930380546, "actor_mean_entropy": -0.01958692248069471, "alpha_loss": -0.014795933151617646, "alpha_value": 0.21672370056191612, "duration": 34.351097106933594, "step": 27500}
{"episode_reward": 768.9470841522946, "episode": 221.0, "critic_loss": 115.34851364135743, "critic_target_Q_variance_m=2": 65976.7965625, "critic_Q1_variance_k=2": 3.0995941047668456, "critic_Q2_variance_k=2": 3.060161485671997, "actor_loss": -511.7553182934958, "actor_mean_entropy": -0.0416485747056348, "alpha_loss": -0.009569554852085218, "alpha_value": 0.21721130533469532, "duration": 34.53202152252197, "step": 27625}
{"episode_reward": 827.5236301372735, "episode": 222.0, "critic_loss": 112.34434091186523, "critic_target_Q_variance_m=2": 66144.22759375, "critic_Q1_variance_k=2": 3.1916633377075194, "critic_Q2_variance_k=2": 3.1757550706863404, "actor_loss": -512.447014593309, "actor_mean_entropy": -0.03313141093859749, "alpha_loss": -0.013869085882399832, "alpha_value": 0.2175710922259287, "duration": 34.25206971168518, "step": 27750}
{"episode_reward": 819.9912533634907, "episode": 223.0, "critic_loss": 109.67725265502929, "critic_target_Q_variance_m=2": 66736.2783125, "critic_Q1_variance_k=2": 3.013652015686035, "critic_Q2_variance_k=2": 3.032654359817505, "actor_loss": -514.5436386835007, "actor_mean_entropy": -0.020746151665373455, "alpha_loss": -0.0008349423961980003, "alpha_value": 0.21788478289152047, "duration": 34.82843565940857, "step": 27875}
{"episode_reward": 741.7185083842722, "episode": 224.0, "critic_loss": 111.10033551025391, "critic_target_Q_variance_m=2": 67185.58296875, "critic_Q1_variance_k=2": 3.1512428350448607, "critic_Q2_variance_k=2": 3.139781265258789, "actor_loss": -516.0140956755607, "actor_mean_entropy": -0.022830342513418967, "alpha_loss": -0.011261896365472385, "alpha_value": 0.218149104993488, "duration": 34.32184052467346, "step": 28000}
{"episode_reward": 816.024137643345, "episode": 225.0, "critic_loss": 113.85821911621093, "critic_target_Q_variance_m=2": 67471.97990625, "critic_Q1_variance_k=2": 2.9628511762619016, "critic_Q2_variance_k=2": 2.924189791202545, "actor_loss": -516.9029778374565, "actor_mean_entropy": -0.07505710792565157, "alpha_loss": -0.021532113715592358, "alpha_value": 0.21874480700668286, "duration": 34.69220781326294, "step": 28125}
{"episode_reward": 822.943552021042, "episode": 226.0, "critic_loss": 107.48181176757812, "critic_target_Q_variance_m=2": 67918.57528125, "critic_Q1_variance_k=2": 2.9221892080307006, "critic_Q2_variance_k=2": 2.871027523994446, "actor_loss": -520.0672297323904, "actor_mean_entropy": 0.005607811193312368, "alpha_loss": -0.0016529497975904133, "alpha_value": 0.21911145851147396, "duration": 34.54641771316528, "step": 28250}
{"episode_reward": 814.2867791283782, "episode": 227.0, "critic_loss": 116.24283026123047, "critic_target_Q_variance_m=2": 68059.297, "critic_Q1_variance_k=2": 3.0022128591537474, "critic_Q2_variance_k=2": 2.969949472427368, "actor_loss": -519.9081740606399, "actor_mean_entropy": -0.02657152174247636, "alpha_loss": 0.0020446208239133868, "alpha_value": 0.21921898438592938, "duration": 34.55765962600708, "step": 28375}
{"episode_reward": 813.4666306940666, "episode": 228.0, "critic_loss": 115.04883596801758, "critic_target_Q_variance_m=2": 68660.446, "critic_Q1_variance_k=2": 2.984635234832764, "critic_Q2_variance_k=2": 2.9970003976821897, "actor_loss": -521.4518398161857, "actor_mean_entropy": -0.01788123597901675, "alpha_loss": -0.0010299211660880715, "alpha_value": 0.21919729007565839, "duration": 34.69754672050476, "step": 28500}
{"episode_reward": 824.5416092417762, "episode": 229.0, "critic_loss": 114.81542971801758, "critic_target_Q_variance_m=2": 68820.5749375, "critic_Q1_variance_k=2": 3.036524923324585, "critic_Q2_variance_k=2": 3.060968777656555, "actor_loss": -523.5970856197297, "actor_mean_entropy": 0.0007544837832923919, "alpha_loss": -0.0031800538390165285, "alpha_value": 0.21933040342571966, "duration": 34.64227890968323, "step": 28625}
{"episode_reward": 816.9975424028828, "episode": 230.0, "critic_loss": 117.7203108215332, "critic_target_Q_variance_m=2": 69161.5696875, "critic_Q1_variance_k=2": 3.0368899421691893, "critic_Q2_variance_k=2": 3.062337766647339, "actor_loss": -523.8639851231729, "actor_mean_entropy": -0.021997179054925518, "alpha_loss": -0.008219527448677728, "alpha_value": 0.21952358871191635, "duration": 34.470388889312744, "step": 28750}
{"episode_reward": 840.1046424021525, "episode": 231.0, "critic_loss": 110.95510021972656, "critic_target_Q_variance_m=2": 69673.3595625, "critic_Q1_variance_k=2": 3.0135598039627074, "critic_Q2_variance_k=2": 3.0193915195465086, "actor_loss": -525.8343157087054, "actor_mean_entropy": -0.05442543239110992, "alpha_loss": 0.0003357817056692309, "alpha_value": 0.2197042086785367, "duration": 34.72676658630371, "step": 28875}
{"episode_reward": 825.1580516309607, "episode": 232.0, "critic_loss": 104.8886689453125, "critic_target_Q_variance_m=2": 70132.563, "critic_Q1_variance_k=2": 2.8301548109054564, "critic_Q2_variance_k=2": 2.8425468215942384, "actor_loss": -527.2770464497228, "actor_mean_entropy": -0.04451641446400073, "alpha_loss": -0.0024522016981556533, "alpha_value": 0.21967338113854099, "duration": 34.451823472976685, "step": 29000}
{"episode_reward": 809.8070691327708, "episode": 233.0, "critic_loss": 110.66807592773438, "critic_target_Q_variance_m=2": 70412.022125, "critic_Q1_variance_k=2": 2.828805576324463, "critic_Q2_variance_k=2": 2.777813259124756, "actor_loss": -528.9647139291915, "actor_mean_entropy": -0.07171380921961769, "alpha_loss": -0.012420363369442168, "alpha_value": 0.21992243053408198, "duration": 34.65541195869446, "step": 29125}
{"episode_reward": 836.0394609142313, "episode": 234.0, "critic_loss": 129.49417639160157, "critic_target_Q_variance_m=2": 70809.221, "critic_Q1_variance_k=2": 3.442452300071716, "critic_Q2_variance_k=2": 3.473032380104065, "actor_loss": -530.9854047221522, "actor_mean_entropy": -0.0031640532937261367, "alpha_loss": 0.007482839924764008, "alpha_value": 0.22023613387414123, "duration": 34.56122398376465, "step": 29250}
{"episode_reward": 836.1333450963698, "episode": 235.0, "critic_loss": 120.47155477905274, "critic_target_Q_variance_m=2": 71018.261375, "critic_Q1_variance_k=2": 3.0383891277313233, "critic_Q2_variance_k=2": 3.079308857917786, "actor_loss": -530.6709275018601, "actor_mean_entropy": -0.006542357364817271, "alpha_loss": -0.007511441669766865, "alpha_value": 0.2201418556297328, "duration": 34.65183687210083, "step": 29375}
{"episode_reward": 812.5514608515883, "episode": 236.0, "critic_loss": 102.92288128662109, "critic_target_Q_variance_m=2": 71409.5161875, "critic_Q1_variance_k=2": 3.0736571321487425, "critic_Q2_variance_k=2": 3.0601448011398316, "actor_loss": -532.5701254567792, "actor_mean_entropy": -0.048042405486827894, "alpha_loss": -0.0010980416254530992, "alpha_value": 0.2204113941231732, "duration": 34.40343880653381, "step": 29500}
{"episode_reward": 734.7589033323017, "episode": 237.0, "critic_loss": 121.08674667358399, "critic_target_Q_variance_m=2": 71974.8979375, "critic_Q1_variance_k=2": 3.355375192642212, "critic_Q2_variance_k=2": 3.3295736179351807, "actor_loss": -535.2506365094866, "actor_mean_entropy": -0.028551500113237472, "alpha_loss": 0.0024969659760476107, "alpha_value": 0.22047823748772286, "duration": 34.69075798988342, "step": 29625}
{"episode_reward": 757.684753831755, "episode": 238.0, "critic_loss": 111.07617260742188, "critic_target_Q_variance_m=2": 72519.5761875, "critic_Q1_variance_k=2": 2.761964831352234, "critic_Q2_variance_k=2": 2.7812314825057984, "actor_loss": -537.0798064201109, "actor_mean_entropy": -0.022889571564812815, "alpha_loss": 0.007918642563444952, "alpha_value": 0.22006099985804156, "duration": 34.69303345680237, "step": 29750}
{"episode_reward": 825.3723186881615, "episode": 239.0, "critic_loss": 109.999359375, "critic_target_Q_variance_m=2": 72674.1980625, "critic_Q1_variance_k=2": 2.7892786588668823, "critic_Q2_variance_k=2": 2.8351093282699584, "actor_loss": -537.6544237893726, "actor_mean_entropy": -0.019766923468855637, "alpha_loss": 0.006342024668045934, "alpha_value": 0.21975094665634684, "duration": 34.61367106437683, "step": 29875}
{"episode_reward": 770.0270858394612, "episode": 240.0, "critic_loss": 105.41993395996094, "critic_target_Q_variance_m=2": 73171.6885, "critic_Q1_variance_k=2": 2.7613746795654297, "critic_Q2_variance_k=2": 2.795582839012146, "actor_loss": -539.3856949344759, "actor_mean_entropy": -0.01008082439582194, "alpha_loss": 0.001480521645487076, "alpha_value": 0.21959320230049842, "duration": 34.416152000427246, "step": 30000}
{"episode_reward": 820.1693544708379, "episode": 241.0, "critic_loss": 105.93893334960937, "critic_target_Q_variance_m=2": 73481.5970625, "critic_Q1_variance_k=2": 2.9397275171279906, "critic_Q2_variance_k=2": 2.8780675897598265, "actor_loss": -539.8095431857639, "actor_mean_entropy": 0.0017269840907482873, "alpha_loss": 0.008467089118702071, "alpha_value": 0.21949901102459818, "duration": 36.68716478347778, "step": 30125}
{"episode_reward": 824.7102789970068, "episode": 242.0, "critic_loss": 100.60801541137695, "critic_target_Q_variance_m=2": 73595.3330625, "critic_Q1_variance_k=2": 2.863832684993744, "critic_Q2_variance_k=2": 2.8750812792778015, "actor_loss": -540.6092647429435, "actor_mean_entropy": 0.011236448381696977, "alpha_loss": 0.001745756565322799, "alpha_value": 0.21910464368197716, "duration": 32.55136060714722, "step": 30250}
{"episode_reward": 727.9944218217672, "episode": 243.0, "critic_loss": 97.95709698486328, "critic_target_Q_variance_m=2": 74213.530875, "critic_Q1_variance_k=2": 2.682027129173279, "critic_Q2_variance_k=2": 2.698682864189148, "actor_loss": -543.03759765625, "actor_mean_entropy": 0.005843177467348084, "alpha_loss": -0.013090486556942027, "alpha_value": 0.21937219349980294, "duration": 34.57635831832886, "step": 30375}
{"episode_reward": 824.095202788865, "episode": 244.0, "critic_loss": 108.5382387084961, "critic_target_Q_variance_m=2": 74634.3119375, "critic_Q1_variance_k=2": 2.9883297872543335, "critic_Q2_variance_k=2": 2.987041874885559, "actor_loss": -544.4296294181578, "actor_mean_entropy": -0.04125584848225117, "alpha_loss": -0.01192453961759325, "alpha_value": 0.2198803894184533, "duration": 34.50961136817932, "step": 30500}
{"episode_reward": 726.7569387722157, "episode": 245.0, "critic_loss": 110.0868042602539, "critic_target_Q_variance_m=2": 74943.6805, "critic_Q1_variance_k=2": 2.9533049116134644, "critic_Q2_variance_k=2": 2.95300680065155, "actor_loss": -545.9185471307663, "actor_mean_entropy": 0.0006800351280068594, "alpha_loss": -0.0032169543602134265, "alpha_value": 0.22038767030254672, "duration": 34.64337086677551, "step": 30625}
{"episode_reward": 833.7947868962452, "episode": 246.0, "critic_loss": 108.64178973388672, "critic_target_Q_variance_m=2": 75197.6281875, "critic_Q1_variance_k=2": 3.015547878742218, "critic_Q2_variance_k=2": 2.9608260746002197, "actor_loss": -547.1328981461063, "actor_mean_entropy": -0.09593303790015559, "alpha_loss": -0.0010258648957636569, "alpha_value": 0.22036159977492803, "duration": 34.46196627616882, "step": 30750}
{"episode_reward": 819.9037566713433, "episode": 247.0, "critic_loss": 108.04220968627929, "critic_target_Q_variance_m=2": 75644.630375, "critic_Q1_variance_k=2": 2.982385600090027, "critic_Q2_variance_k=2": 2.9120535669326784, "actor_loss": -548.1486244807168, "actor_mean_entropy": -0.0318139861559584, "alpha_loss": -0.007266494829858106, "alpha_value": 0.22067740881991119, "duration": 34.59926104545593, "step": 30875}
{"episode_reward": 737.7511424478237, "episode": 248.0, "critic_loss": 109.76377075195313, "critic_target_Q_variance_m=2": 75903.6970625, "critic_Q1_variance_k=2": 2.911203089237213, "critic_Q2_variance_k=2": 2.981335652351379, "actor_loss": -549.9161751039567, "actor_mean_entropy": -0.016706112231458386, "alpha_loss": -0.003421554567232247, "alpha_value": 0.22085623724310985, "duration": 34.54065752029419, "step": 31000}
{"episode_reward": 811.9578415455924, "episode": 249.0, "critic_loss": 111.32415869140625, "critic_target_Q_variance_m=2": 76247.5484375, "critic_Q1_variance_k=2": 2.962941038131714, "critic_Q2_variance_k=2": 3.0148964710235595, "actor_loss": -550.0779854910714, "actor_mean_entropy": -0.002529044472982013, "alpha_loss": -7.794716853707556e-05, "alpha_value": 0.2210544019965063, "duration": 35.265708684921265, "step": 31125}
{"episode_reward": 746.6340649322965, "episode": 250.0, "critic_loss": 108.86866665649414, "critic_target_Q_variance_m=2": 76559.172375, "critic_Q1_variance_k=2": 2.777340845108032, "critic_Q2_variance_k=2": 2.756372194290161, "actor_loss": -550.8825151997228, "actor_mean_entropy": 0.04000065070126326, "alpha_loss": -0.00042018441543463736, "alpha_value": 0.2209554480335474, "duration": 34.431984663009644, "step": 31250}
{"episode_reward": 824.0895490162432, "episode": 251.0, "critic_loss": 111.95904623413085, "critic_target_Q_variance_m=2": 77207.521625, "critic_Q1_variance_k=2": 2.97321301984787, "critic_Q2_variance_k=2": 2.981938102722168, "actor_loss": -553.5533166310144, "actor_mean_entropy": -0.03990977414188877, "alpha_loss": 0.009493479682576089, "alpha_value": 0.22083783233120213, "duration": 34.64459490776062, "step": 31375}
{"episode_reward": 821.5193694451609, "episode": 252.0, "critic_loss": 111.55443063354492, "critic_target_Q_variance_m=2": 76983.8734375, "critic_Q1_variance_k=2": 2.9738412880897522, "critic_Q2_variance_k=2": 3.0215400190353394, "actor_loss": -553.2782671528478, "actor_mean_entropy": 0.0674424871441818, "alpha_loss": 0.007348613175112874, "alpha_value": 0.2204498167762023, "duration": 34.46633815765381, "step": 31500}
{"episode_reward": 765.5841628826058, "episode": 253.0, "critic_loss": 115.78256735229492, "critic_target_Q_variance_m=2": 77620.1854375, "critic_Q1_variance_k=2": 2.805798982620239, "critic_Q2_variance_k=2": 2.831767382621765, "actor_loss": -554.8571360754588, "actor_mean_entropy": 0.04879624801613982, "alpha_loss": 0.006247085918273244, "alpha_value": 0.21986630217941533, "duration": 34.87949895858765, "step": 31625}
{"episode_reward": 818.0398855797415, "episode": 254.0, "critic_loss": 97.88638415527343, "critic_target_Q_variance_m=2": 78171.086, "critic_Q1_variance_k=2": 2.759394226074219, "critic_Q2_variance_k=2": 2.7030364623069763, "actor_loss": -556.878915109942, "actor_mean_entropy": -0.047214233346523776, "alpha_loss": -0.0060617182696718844, "alpha_value": 0.21989103334409973, "duration": 34.52672815322876, "step": 31750}
{"episode_reward": 830.0905401989218, "episode": 255.0, "critic_loss": 112.36542575073243, "critic_target_Q_variance_m=2": 78320.418625, "critic_Q1_variance_k=2": 2.8952355279922486, "critic_Q2_variance_k=2": 2.8513029651641846, "actor_loss": -558.4052036830357, "actor_mean_entropy": -0.08324189478206256, "alpha_loss": -0.008158140483179263, "alpha_value": 0.22027608041396002, "duration": 34.552998542785645, "step": 31875}
{"episode_reward": 800.0922947951586, "episode": 256.0, "critic_loss": 108.24681069946288, "critic_target_Q_variance_m=2": 78633.9278125, "critic_Q1_variance_k=2": 3.0229411182403565, "critic_Q2_variance_k=2": 2.995048493385315, "actor_loss": -559.4064714985509, "actor_mean_entropy": -0.027303199433991985, "alpha_loss": -0.00028658829509250577, "alpha_value": 0.22046991452092862, "duration": 34.5105082988739, "step": 32000}
{"episode_reward": 831.4398306181101, "episode": 257.0, "critic_loss": 119.73923828125, "critic_target_Q_variance_m=2": 79083.6139375, "critic_Q1_variance_k=2": 2.7864000577926635, "critic_Q2_variance_k=2": 2.819810212135315, "actor_loss": -561.1733291868179, "actor_mean_entropy": -0.03286431540572454, "alpha_loss": 0.004863244688345326, "alpha_value": 0.2204646217717659, "duration": 34.57376194000244, "step": 32125}
{"episode_reward": 825.2255404565038, "episode": 258.0, "critic_loss": 98.90825820922852, "critic_target_Q_variance_m=2": 79405.7918125, "critic_Q1_variance_k=2": 2.637270941734314, "critic_Q2_variance_k=2": 2.602893333911896, "actor_loss": -561.5013791976437, "actor_mean_entropy": 0.08632466839926858, "alpha_loss": 0.008793957501409514, "alpha_value": 0.22029594414416293, "duration": 34.372783184051514, "step": 32250}
{"episode_reward": 803.7177984453663, "episode": 259.0, "critic_loss": 96.74651162719726, "critic_target_Q_variance_m=2": 80022.908625, "critic_Q1_variance_k=2": 2.7983131432533264, "critic_Q2_variance_k=2": 2.772362458229065, "actor_loss": -563.8203347826761, "actor_mean_entropy": 0.018362612714843143, "alpha_loss": 0.010336928465034045, "alpha_value": 0.21960092879749243, "duration": 34.99110007286072, "step": 32375}
{"episode_reward": 723.4730040527274, "episode": 260.0, "critic_loss": 115.34601110839844, "critic_target_Q_variance_m=2": 80179.475375, "critic_Q1_variance_k=2": 2.6939446144104005, "critic_Q2_variance_k=2": 2.629789776802063, "actor_loss": -564.2091655115927, "actor_mean_entropy": -0.049544687533090194, "alpha_loss": -0.006583689877222623, "alpha_value": 0.21956192088356674, "duration": 34.56589388847351, "step": 32500}
{"episode_reward": 831.9405110117832, "episode": 261.0, "critic_loss": 115.2464231262207, "critic_target_Q_variance_m=2": 80509.3580625, "critic_Q1_variance_k=2": 2.7379462728500368, "critic_Q2_variance_k=2": 2.7446497259140012, "actor_loss": -564.8665742420014, "actor_mean_entropy": -0.014980107900642213, "alpha_loss": -0.000688030691226087, "alpha_value": 0.2197709102764653, "duration": 34.72398066520691, "step": 32625}
{"episode_reward": 824.8562851719134, "episode": 262.0, "critic_loss": 97.80010972595215, "critic_target_Q_variance_m=2": 80696.3699375, "critic_Q1_variance_k=2": 2.5942032384872435, "critic_Q2_variance_k=2": 2.6174495134353637, "actor_loss": -566.3837093230217, "actor_mean_entropy": 0.030171486789420728, "alpha_loss": 0.004463535312923693, "alpha_value": 0.2197981117034723, "duration": 34.69820857048035, "step": 32750}
{"episode_reward": 828.7215795836667, "episode": 263.0, "critic_loss": 101.82867346191406, "critic_target_Q_variance_m=2": 80879.886875, "critic_Q1_variance_k=2": 2.8709170303344727, "critic_Q2_variance_k=2": 2.910647357940674, "actor_loss": -567.5916292705233, "actor_mean_entropy": 0.007519489242917015, "alpha_loss": 0.00415741829645066, "alpha_value": 0.21941534328008805, "duration": 34.552831411361694, "step": 32875}
{"episode_reward": 836.8887700554172, "episode": 264.0, "critic_loss": 119.12359826660156, "critic_target_Q_variance_m=2": 81646.6356875, "critic_Q1_variance_k=2": 2.629344934463501, "critic_Q2_variance_k=2": 2.636389934062958, "actor_loss": -569.8646949029738, "actor_mean_entropy": -0.024005643182223844, "alpha_loss": 0.01587631382919367, "alpha_value": 0.2191001989677288, "duration": 34.494298458099365, "step": 33000}
{"episode_reward": 817.7250313684445, "episode": 265.0, "critic_loss": 96.83044049072265, "critic_target_Q_variance_m=2": 81513.3674375, "critic_Q1_variance_k=2": 2.5115940866470337, "critic_Q2_variance_k=2": 2.526440149307251, "actor_loss": -568.9668152824281, "actor_mean_entropy": -0.015108057342114904, "alpha_loss": 0.010514538565147964, "alpha_value": 0.218307956006021, "duration": 34.4703733921051, "step": 33125}
{"episode_reward": 821.8402952783207, "episode": 266.0, "critic_loss": 100.63055319213868, "critic_target_Q_variance_m=2": 81830.5385, "critic_Q1_variance_k=2": 2.630827874183655, "critic_Q2_variance_k=2": 2.590826675415039, "actor_loss": -570.5105443154612, "actor_mean_entropy": 0.004858087147435834, "alpha_loss": 0.004891766956256282, "alpha_value": 0.2179439982884643, "duration": 34.56705093383789, "step": 33250}
{"episode_reward": 734.4302832387554, "episode": 267.0, "critic_loss": 106.43356710815429, "critic_target_Q_variance_m=2": 82271.9394375, "critic_Q1_variance_k=2": 2.5556424713134764, "critic_Q2_variance_k=2": 2.5610643186569213, "actor_loss": -572.4716535295759, "actor_mean_entropy": -0.060159112371149515, "alpha_loss": 0.0003938895709339588, "alpha_value": 0.21784895074894414, "duration": 34.809032678604126, "step": 33375}
{"episode_reward": 826.6359729528549, "episode": 268.0, "critic_loss": 101.5152174987793, "critic_target_Q_variance_m=2": 82749.8058125, "critic_Q1_variance_k=2": 2.7104492363929746, "critic_Q2_variance_k=2": 2.682574305534363, "actor_loss": -574.1536707724295, "actor_mean_entropy": -0.011055695974538404, "alpha_loss": 0.007101254965809565, "alpha_value": 0.2176090196131523, "duration": 34.628084897994995, "step": 33500}
{"episode_reward": 820.1675696327915, "episode": 269.0, "critic_loss": 105.21741268920898, "critic_target_Q_variance_m=2": 83148.2233125, "critic_Q1_variance_k=2": 2.7626460361480714, "critic_Q2_variance_k=2": 2.748354696273804, "actor_loss": -575.1722935267857, "actor_mean_entropy": -0.008451591526705122, "alpha_loss": 0.0014183701326449711, "alpha_value": 0.21751599429163224, "duration": 34.625924587249756, "step": 33625}
{"episode_reward": 749.9048811684565, "episode": 270.0, "critic_loss": 107.35734313964844, "critic_target_Q_variance_m=2": 83160.1270625, "critic_Q1_variance_k=2": 2.778741008758545, "critic_Q2_variance_k=2": 2.759397334098816, "actor_loss": -574.9824671591482, "actor_mean_entropy": 0.01647110304404651, "alpha_loss": 0.008324155328615059, "alpha_value": 0.2172846814462189, "duration": 34.38877892494202, "step": 33750}
{"episode_reward": 822.8613173261529, "episode": 271.0, "critic_loss": 97.01058850097657, "critic_target_Q_variance_m=2": 83739.2825625, "critic_Q1_variance_k=2": 2.313924957752228, "critic_Q2_variance_k=2": 2.328729148864746, "actor_loss": -577.1905381944445, "actor_mean_entropy": -0.02737021842409694, "alpha_loss": -0.0026022676629797806, "alpha_value": 0.21721291753471286, "duration": 34.665382385253906, "step": 33875}
{"episode_reward": 814.5378741331014, "episode": 272.0, "critic_loss": 104.08412399291993, "critic_target_Q_variance_m=2": 83864.78575, "critic_Q1_variance_k=2": 2.6476133279800416, "critic_Q2_variance_k=2": 2.62634886264801, "actor_loss": -577.5423160676033, "actor_mean_entropy": 0.02061748669873322, "alpha_loss": 0.006104489067389119, "alpha_value": 0.21703198114762398, "duration": 34.50783729553223, "step": 34000}
{"episode_reward": 825.6339284987919, "episode": 273.0, "critic_loss": 96.75828857421875, "critic_target_Q_variance_m=2": 84241.501125, "critic_Q1_variance_k=2": 2.4354024276733397, "critic_Q2_variance_k=2": 2.372484302520752, "actor_loss": -578.4058770073784, "actor_mean_entropy": 0.05735869631762543, "alpha_loss": 6.573023422369881e-05, "alpha_value": 0.21695775430374722, "duration": 34.811991691589355, "step": 34125}
{"episode_reward": 751.3015175978524, "episode": 274.0, "critic_loss": 91.5079021911621, "critic_target_Q_variance_m=2": 84673.265125, "critic_Q1_variance_k=2": 2.517462019920349, "critic_Q2_variance_k=2": 2.4978137760162356, "actor_loss": -581.1150601294732, "actor_mean_entropy": -0.0012970742499155382, "alpha_loss": 0.012683010810325223, "alpha_value": 0.21649762098069314, "duration": 34.39345407485962, "step": 34250}
{"episode_reward": 832.5456739536718, "episode": 275.0, "critic_loss": 93.26158447265625, "critic_target_Q_variance_m=2": 85036.2640625, "critic_Q1_variance_k=2": 2.357504468917847, "critic_Q2_variance_k=2": 2.359651237487793, "actor_loss": -581.09375, "actor_mean_entropy": 0.0033643153451737903, "alpha_loss": 0.00688681047823694, "alpha_value": 0.21606763027461673, "duration": 34.5625319480896, "step": 34375}
{"episode_reward": 832.2719424147033, "episode": 276.0, "critic_loss": 112.62937942504882, "critic_target_Q_variance_m=2": 85059.317125, "critic_Q1_variance_k=2": 2.7495221672058103, "critic_Q2_variance_k=2": 2.7369943890571595, "actor_loss": -581.8302336662047, "actor_mean_entropy": -0.0056671318297664966, "alpha_loss": -0.005462607162283553, "alpha_value": 0.2160657872957589, "duration": 34.46205115318298, "step": 34500}
{"episode_reward": 816.4099903790209, "episode": 277.0, "critic_loss": 92.79885717773438, "critic_target_Q_variance_m=2": 85684.0710625, "critic_Q1_variance_k=2": 2.4924941158294676, "critic_Q2_variance_k=2": 2.4605739603042602, "actor_loss": -583.4103858584449, "actor_mean_entropy": -0.06986817575636364, "alpha_loss": -0.002444735462112086, "alpha_value": 0.21627599381632853, "duration": 34.58968639373779, "step": 34625}
{"episode_reward": 755.1219537211337, "episode": 278.0, "critic_loss": 93.52876303100587, "critic_target_Q_variance_m=2": 85689.10925, "critic_Q1_variance_k=2": 2.668787546634674, "critic_Q2_variance_k=2": 2.6407964553833008, "actor_loss": -583.8379624889743, "actor_mean_entropy": 0.004876562153860446, "alpha_loss": 0.0028430532641528596, "alpha_value": 0.21631547613015267, "duration": 34.55374598503113, "step": 34750}
{"episode_reward": 759.8710180797924, "episode": 279.0, "critic_loss": 100.86413160705567, "critic_target_Q_variance_m=2": 85917.487, "critic_Q1_variance_k=2": 2.7624608068466188, "critic_Q2_variance_k=2": 2.700073464870453, "actor_loss": -584.3919929625496, "actor_mean_entropy": -0.0352208355944308, "alpha_loss": -0.001683436141955474, "alpha_value": 0.21624626525606583, "duration": 34.56416988372803, "step": 34875}
{"episode_reward": 830.3004145398559, "episode": 280.0, "critic_loss": 104.24554446411133, "critic_target_Q_variance_m=2": 86583.9295625, "critic_Q1_variance_k=2": 2.693130404472351, "critic_Q2_variance_k=2": 2.6872845344543457, "actor_loss": -586.852786156439, "actor_mean_entropy": 0.040225331641493306, "alpha_loss": 0.004960037756621117, "alpha_value": 0.2163092527673686, "duration": 34.41994762420654, "step": 35000}
{"episode_reward": 824.7808994620485, "episode": 281.0, "critic_loss": 106.7377511291504, "critic_target_Q_variance_m=2": 86775.0615, "critic_Q1_variance_k=2": 2.7246831722259524, "critic_Q2_variance_k=2": 2.6896957206726073, "actor_loss": -588.1130797371031, "actor_mean_entropy": 0.012080327533776797, "alpha_loss": 0.015147782932405197, "alpha_value": 0.21564326774240897, "duration": 34.720338582992554, "step": 35125}
{"episode_reward": 821.581470934206, "episode": 282.0, "critic_loss": 106.72539358520508, "critic_target_Q_variance_m=2": 86847.302, "critic_Q1_variance_k=2": 2.775607804775238, "critic_Q2_variance_k=2": 2.7765093421936036, "actor_loss": -587.7491966985887, "actor_mean_entropy": -0.013157127244818595, "alpha_loss": 0.011246091273102549, "alpha_value": 0.21504858601037652, "duration": 34.46071910858154, "step": 35250}
{"episode_reward": 831.6591192185374, "episode": 283.0, "critic_loss": 92.57911508178711, "critic_target_Q_variance_m=2": 87330.5645, "critic_Q1_variance_k=2": 2.7038107423782347, "critic_Q2_variance_k=2": 2.6894674377441405, "actor_loss": -589.8183835953001, "actor_mean_entropy": 0.03182520167458625, "alpha_loss": 0.0012007682872492644, "alpha_value": 0.21479131900290332, "duration": 34.817758321762085, "step": 35375}
{"episode_reward": 817.682827885044, "episode": 284.0, "critic_loss": 97.55094589233398, "critic_target_Q_variance_m=2": 87548.74, "critic_Q1_variance_k=2": 2.585420521736145, "critic_Q2_variance_k=2": 2.638183614730835, "actor_loss": -590.6122210102696, "actor_mean_entropy": -0.028518822464731433, "alpha_loss": -0.0076027985572093915, "alpha_value": 0.21482822249409658, "duration": 34.29915428161621, "step": 35500}
{"episode_reward": 813.6128830410446, "episode": 285.0, "critic_loss": 97.84501498413086, "critic_target_Q_variance_m=2": 88005.992625, "critic_Q1_variance_k=2": 2.508599437713623, "critic_Q2_variance_k=2": 2.421703489780426, "actor_loss": -591.7534644717261, "actor_mean_entropy": 0.005652117794231763, "alpha_loss": 0.008916982767423467, "alpha_value": 0.21502697744132138, "duration": 34.506404399871826, "step": 35625}
{"episode_reward": 826.14438933878, "episode": 286.0, "critic_loss": 100.13932284545898, "critic_target_Q_variance_m=2": 88170.890625, "critic_Q1_variance_k=2": 2.5795886611938474, "critic_Q2_variance_k=2": 2.560100914955139, "actor_loss": -592.082019436744, "actor_mean_entropy": 0.002430449960933578, "alpha_loss": 0.0006139399333586616, "alpha_value": 0.21466283917483917, "duration": 34.43616795539856, "step": 35750}
{"episode_reward": 835.6073143464869, "episode": 287.0, "critic_loss": 93.16558746337891, "critic_target_Q_variance_m=2": 88744.619875, "critic_Q1_variance_k=2": 2.4059357509613037, "critic_Q2_variance_k=2": 2.440995433330536, "actor_loss": -593.8932514493428, "actor_mean_entropy": 0.004090176510905463, "alpha_loss": 0.01129712124118611, "alpha_value": 0.21433645002367296, "duration": 34.610353231430054, "step": 35875}
{"episode_reward": 814.1032035399052, "episode": 288.0, "critic_loss": 101.21508181762695, "critic_target_Q_variance_m=2": 89180.6341875, "critic_Q1_variance_k=2": 2.2084665884971617, "critic_Q2_variance_k=2": 2.2334721660614014, "actor_loss": -595.5835896153604, "actor_mean_entropy": 0.07834210736496795, "alpha_loss": 0.012526085739204239, "alpha_value": 0.21384526266296913, "duration": 34.59755349159241, "step": 36000}
{"episode_reward": 826.7410490154016, "episode": 289.0, "critic_loss": 92.75446054077149, "critic_target_Q_variance_m=2": 89197.3529375, "critic_Q1_variance_k=2": 2.3051990699768066, "critic_Q2_variance_k=2": 2.3427274370193483, "actor_loss": -595.703855484251, "actor_mean_entropy": 0.005631533022674304, "alpha_loss": -0.0019141868170764712, "alpha_value": 0.21363961452624178, "duration": 34.71629047393799, "step": 36125}
{"episode_reward": 823.2685998026378, "episode": 290.0, "critic_loss": 90.38465838623047, "critic_target_Q_variance_m=2": 89572.5956875, "critic_Q1_variance_k=2": 2.4306194458007813, "critic_Q2_variance_k=2": 2.3849859957695005, "actor_loss": -597.3947232154107, "actor_mean_entropy": -0.031067788210367004, "alpha_loss": 0.005705322927585052, "alpha_value": 0.21343212207433543, "duration": 34.82937526702881, "step": 36250}
{"episode_reward": 749.6283693662198, "episode": 291.0, "critic_loss": 90.11897177124024, "critic_target_Q_variance_m=2": 89678.4586875, "critic_Q1_variance_k=2": 2.2319458947181703, "critic_Q2_variance_k=2": 2.182319890499115, "actor_loss": -597.0192648266989, "actor_mean_entropy": -0.03018245485330385, "alpha_loss": 0.0006763554466444822, "alpha_value": 0.21332829742443443, "duration": 34.5628867149353, "step": 36375}
{"episode_reward": 820.0069503478744, "episode": 292.0, "critic_loss": 87.865123046875, "critic_target_Q_variance_m=2": 90222.309, "critic_Q1_variance_k=2": 2.427926257133484, "critic_Q2_variance_k=2": 2.3707295875549317, "actor_loss": -599.4778658959174, "actor_mean_entropy": -0.004462338232946011, "alpha_loss": 0.011475886901720397, "alpha_value": 0.21315417408091222, "duration": 34.391841411590576, "step": 36500}
{"episode_reward": 818.2039115864527, "episode": 293.0, "critic_loss": 89.99429943847656, "critic_target_Q_variance_m=2": 90278.41875, "critic_Q1_variance_k=2": 2.2651377449035643, "critic_Q2_variance_k=2": 2.2695088572502136, "actor_loss": -599.9943586077009, "actor_mean_entropy": 0.0038542631008322277, "alpha_loss": 0.004436000309411495, "alpha_value": 0.2126608028034928, "duration": 34.99779772758484, "step": 36625}
{"episode_reward": 823.9038469936172, "episode": 294.0, "critic_loss": 92.18104125976562, "critic_target_Q_variance_m=2": 90734.10175, "critic_Q1_variance_k=2": 2.2641858162879944, "critic_Q2_variance_k=2": 2.2539711837768555, "actor_loss": -600.8760671307964, "actor_mean_entropy": 0.0071520373345382755, "alpha_loss": 0.009454992766897645, "alpha_value": 0.21229090402993153, "duration": 33.50105571746826, "step": 36750}
{"episode_reward": 807.357107960595, "episode": 295.0, "critic_loss": 88.91390737915039, "critic_target_Q_variance_m=2": 90702.555125, "critic_Q1_variance_k=2": 2.1906171083450316, "critic_Q2_variance_k=2": 2.1853034868240355, "actor_loss": -600.3539874364459, "actor_mean_entropy": -0.06631869059943017, "alpha_loss": -0.009818956307652924, "alpha_value": 0.21227130874669187, "duration": 34.58015537261963, "step": 36875}
{"episode_reward": 830.9978369087568, "episode": 296.0, "critic_loss": 92.47581805419922, "critic_target_Q_variance_m=2": 91155.7643125, "critic_Q1_variance_k=2": 2.2633416776657103, "critic_Q2_variance_k=2": 2.2388286066055296, "actor_loss": -602.0067552135837, "actor_mean_entropy": 0.017607304387755932, "alpha_loss": 0.00652675113205107, "alpha_value": 0.21247685529723875, "duration": 34.564260482788086, "step": 37000}
{"episode_reward": 830.8475310743295, "episode": 297.0, "critic_loss": 94.0294243774414, "critic_target_Q_variance_m=2": 91228.596125, "critic_Q1_variance_k=2": 2.4386697130203245, "critic_Q2_variance_k=2": 2.4472289242744445, "actor_loss": -602.2539527529761, "actor_mean_entropy": -0.0061699071573832675, "alpha_loss": 0.00216614112760576, "alpha_value": 0.21227241632480748, "duration": 34.6820924282074, "step": 37125}
{"episode_reward": 775.2557979702646, "episode": 298.0, "critic_loss": 93.48688546752929, "critic_target_Q_variance_m=2": 91546.60075, "critic_Q1_variance_k=2": 2.458426343917847, "critic_Q2_variance_k=2": 2.4542766313552855, "actor_loss": -603.393294795867, "actor_mean_entropy": -0.00028860388744261957, "alpha_loss": 0.005595303591220609, "alpha_value": 0.21217777854299133, "duration": 34.758604288101196, "step": 37250}
{"episode_reward": 826.3818679726311, "episode": 299.0, "critic_loss": 106.98766870117187, "critic_target_Q_variance_m=2": 91856.8078125, "critic_Q1_variance_k=2": 2.500769874572754, "critic_Q2_variance_k=2": 2.502497808456421, "actor_loss": -605.1592707558284, "actor_mean_entropy": 0.023143431674393398, "alpha_loss": 0.00800133696461599, "alpha_value": 0.21178276796711507, "duration": 34.7336540222168, "step": 37375}
{"episode_reward": 803.6318832536087, "episode": 300.0, "critic_loss": 108.70364822387695, "critic_target_Q_variance_m=2": 92293.907875, "critic_Q1_variance_k=2": 2.5754391469955444, "critic_Q2_variance_k=2": 2.5720868835449218, "actor_loss": -606.4146246141003, "actor_mean_entropy": -0.007754462801160351, "alpha_loss": 0.002619893462847798, "alpha_value": 0.21148758716748903, "duration": 34.43650412559509, "step": 37500}
{"episode_reward": 733.1845257085793, "episode": 301.0, "critic_loss": 90.83343054199219, "critic_target_Q_variance_m=2": 92664.988875, "critic_Q1_variance_k=2": 2.1500588064193726, "critic_Q2_variance_k=2": 2.1867349166870116, "actor_loss": -607.8634798564608, "actor_mean_entropy": -0.008008538139244866, "alpha_loss": 0.010926237736370355, "alpha_value": 0.21129549638271855, "duration": 34.887502908706665, "step": 37625}
{"episode_reward": 827.6781689638101, "episode": 302.0, "critic_loss": 95.4030426940918, "critic_target_Q_variance_m=2": 92684.5069375, "critic_Q1_variance_k=2": 2.2721935358047487, "critic_Q2_variance_k=2": 2.286501747131348, "actor_loss": -607.5757731776083, "actor_mean_entropy": -0.045775123931948214, "alpha_loss": 0.006732663935831477, "alpha_value": 0.21090891427610553, "duration": 34.70397925376892, "step": 37750}
{"episode_reward": 840.2028494600835, "episode": 303.0, "critic_loss": 91.09774282836914, "critic_target_Q_variance_m=2": 93118.1915, "critic_Q1_variance_k=2": 2.313619941711426, "critic_Q2_variance_k=2": 2.301560085296631, "actor_loss": -609.3764076838418, "actor_mean_entropy": -0.02244879858243087, "alpha_loss": 0.014927936185683523, "alpha_value": 0.21026513211627906, "duration": 34.688236713409424, "step": 37875}
{"episode_reward": 735.9505104163434, "episode": 304.0, "critic_loss": 98.21617111206055, "critic_target_Q_variance_m=2": 93228.227125, "critic_Q1_variance_k=2": 2.3844882278442383, "critic_Q2_variance_k=2": 2.4041938333511355, "actor_loss": -609.4098865139869, "actor_mean_entropy": 0.07212498982346827, "alpha_loss": 0.01395261939239478, "alpha_value": 0.20957873199959448, "duration": 34.82056713104248, "step": 38000}
{"episode_reward": 810.9681452362514, "episode": 305.0, "critic_loss": 102.1585590209961, "critic_target_Q_variance_m=2": 93363.11225, "critic_Q1_variance_k=2": 2.4276356363296507, "critic_Q2_variance_k=2": 2.3591218395233153, "actor_loss": -609.8878609793527, "actor_mean_entropy": 0.005878322949958226, "alpha_loss": 0.012803947346078025, "alpha_value": 0.2091072433136913, "duration": 35.19969081878662, "step": 38125}
{"episode_reward": 811.7592435761646, "episode": 306.0, "critic_loss": 86.63279815673827, "critic_target_Q_variance_m=2": 93801.48975, "critic_Q1_variance_k=2": 2.1979360036849975, "critic_Q2_variance_k=2": 2.1488649320602415, "actor_loss": -610.3332814862652, "actor_mean_entropy": 0.00011847968844156111, "alpha_loss": -0.003346617540134297, "alpha_value": 0.20879816787274336, "duration": 34.4762978553772, "step": 38250}
{"episode_reward": 822.703145815601, "episode": 307.0, "critic_loss": 99.06379776000976, "critic_target_Q_variance_m=2": 94223.0369375, "critic_Q1_variance_k=2": 2.272640759944916, "critic_Q2_variance_k=2": 2.2516907291412354, "actor_loss": -612.6460455031622, "actor_mean_entropy": -0.03914201768144729, "alpha_loss": 0.007276835843979839, "alpha_value": 0.20874859070756888, "duration": 34.60124230384827, "step": 38375}
{"episode_reward": 748.1384424286599, "episode": 308.0, "critic_loss": 96.66629415893554, "critic_target_Q_variance_m=2": 94285.3145625, "critic_Q1_variance_k=2": 2.39778994512558, "critic_Q2_variance_k=2": 2.3844653215408327, "actor_loss": -613.1131188177293, "actor_mean_entropy": 0.017882182473136533, "alpha_loss": 0.00801024199914067, "alpha_value": 0.2084936921412947, "duration": 34.6635057926178, "step": 38500}
{"episode_reward": 801.7087808250554, "episode": 309.0, "critic_loss": 89.61502958679199, "critic_target_Q_variance_m=2": 94599.5451875, "critic_Q1_variance_k=2": 2.242450517177582, "critic_Q2_variance_k=2": 2.279400327205658, "actor_loss": -614.1015847826761, "actor_mean_entropy": -0.032738452304213767, "alpha_loss": 0.011647111211445123, "alpha_value": 0.20800772761874978, "duration": 34.886632204055786, "step": 38625}
{"episode_reward": 827.6806003442839, "episode": 310.0, "critic_loss": 84.19972521972656, "critic_target_Q_variance_m=2": 95147.2459375, "critic_Q1_variance_k=2": 2.147405779838562, "critic_Q2_variance_k=2": 2.119719382762909, "actor_loss": -615.8527349656628, "actor_mean_entropy": 0.036532430549062064, "alpha_loss": 0.010576564300384733, "alpha_value": 0.2074996221315314, "duration": 34.57099628448486, "step": 38750}
{"episode_reward": 825.1395541158647, "episode": 311.0, "critic_loss": 87.28492178344726, "critic_target_Q_variance_m=2": 95219.686125, "critic_Q1_variance_k=2": 2.191503336906433, "critic_Q2_variance_k=2": 2.1549232287406923, "actor_loss": -615.9146079411582, "actor_mean_entropy": 0.013202590779179619, "alpha_loss": 0.013910527873252119, "alpha_value": 0.20678008078119367, "duration": 34.955456018447876, "step": 38875}
{"episode_reward": 829.5422102003829, "episode": 312.0, "critic_loss": 104.1756121673584, "critic_target_Q_variance_m=2": 95512.2388125, "critic_Q1_variance_k=2": 2.16491383600235, "critic_Q2_variance_k=2": 2.1163481011390686, "actor_loss": -616.5046987225933, "actor_mean_entropy": -0.06624624944261966, "alpha_loss": -0.0038417058155661627, "alpha_value": 0.20665353801865824, "duration": 34.651363134384155, "step": 39000}
{"episode_reward": 835.2494163238872, "episode": 313.0, "critic_loss": 100.19613543701172, "critic_target_Q_variance_m=2": 95559.2425, "critic_Q1_variance_k=2": 2.4383425817489623, "critic_Q2_variance_k=2": 2.373846981048584, "actor_loss": -616.2387346540179, "actor_mean_entropy": 0.02639238369311132, "alpha_loss": -0.0026708923812423435, "alpha_value": 0.20690397726537008, "duration": 34.60283422470093, "step": 39125}
{"episode_reward": 830.6807046583209, "episode": 314.0, "critic_loss": 106.7126671447754, "critic_target_Q_variance_m=2": 96020.1979375, "critic_Q1_variance_k=2": 2.3509836196899414, "critic_Q2_variance_k=2": 2.3591182050704957, "actor_loss": -618.6022043535786, "actor_mean_entropy": 0.006556967814122477, "alpha_loss": -0.001281574436072861, "alpha_value": 0.207006068411929, "duration": 34.862119913101196, "step": 39250}
{"episode_reward": 834.9937209903591, "episode": 315.0, "critic_loss": 88.04852307128907, "critic_target_Q_variance_m=2": 96196.2515, "critic_Q1_variance_k=2": 2.241419184207916, "critic_Q2_variance_k=2": 2.2310249004364016, "actor_loss": -619.7901514446925, "actor_mean_entropy": -0.000731733405873889, "alpha_loss": 0.005166518586939053, "alpha_value": 0.2067171124109056, "duration": 34.55577778816223, "step": 39375}
{"episode_reward": 815.4941695412319, "episode": 316.0, "critic_loss": 98.56520101928712, "critic_target_Q_variance_m=2": 96520.1275625, "critic_Q1_variance_k=2": 2.2480391297340394, "critic_Q2_variance_k=2": 2.270419888496399, "actor_loss": -620.6082990092616, "actor_mean_entropy": -0.08877711689039584, "alpha_loss": 0.0002780139235959899, "alpha_value": 0.2067813867573083, "duration": 34.625911474227905, "step": 39500}
{"episode_reward": 829.7918275372554, "episode": 317.0, "critic_loss": 97.1476526184082, "critic_target_Q_variance_m=2": 97100.784125, "critic_Q1_variance_k=2": 2.328733362197876, "critic_Q2_variance_k=2": 2.362012689590454, "actor_loss": -621.5254119388641, "actor_mean_entropy": -0.04619180044484517, "alpha_loss": -0.0028143453722198806, "alpha_value": 0.20684089267082068, "duration": 34.563244104385376, "step": 39625}
{"episode_reward": 823.6396669969466, "episode": 318.0, "critic_loss": 74.39544046020508, "critic_target_Q_variance_m=2": 97245.2058125, "critic_Q1_variance_k=2": 1.9888702445030213, "critic_Q2_variance_k=2": 2.0167996163368227, "actor_loss": -622.3121200069304, "actor_mean_entropy": 0.00322168692946434, "alpha_loss": -0.0041458259727205, "alpha_value": 0.2069561662447079, "duration": 34.451597929000854, "step": 39750}
{"episode_reward": 831.4969372627065, "episode": 319.0, "critic_loss": 87.50111892700195, "critic_target_Q_variance_m=2": 97395.3176875, "critic_Q1_variance_k=2": 2.200035871505737, "critic_Q2_variance_k=2": 2.207913186073303, "actor_loss": -623.2082054501489, "actor_mean_entropy": 0.026846703023664535, "alpha_loss": 0.010134459340146609, "alpha_value": 0.20693911886953026, "duration": 34.68126177787781, "step": 39875}
{"episode_reward": 825.4812380428211, "episode": 320.0, "critic_loss": 86.01922151184083, "critic_target_Q_variance_m=2": 97616.746, "critic_Q1_variance_k=2": 2.3165398111343385, "critic_Q2_variance_k=2": 2.2907034039497374, "actor_loss": -623.9911252913937, "actor_mean_entropy": -0.05532894776232781, "alpha_loss": -0.004164630637293862, "alpha_value": 0.2067181813745259, "duration": 34.857502698898315, "step": 40000}
{"episode_reward": 833.5317872664698, "episode": 321.0, "critic_loss": 94.61313150024414, "critic_target_Q_variance_m=2": 97907.051125, "critic_Q1_variance_k=2": 2.189715552806854, "critic_Q2_variance_k=2": 2.2057249450683596, "actor_loss": -624.7912801106771, "actor_mean_entropy": -0.04202123054318012, "alpha_loss": 0.005874255435570838, "alpha_value": 0.2065038685500233, "duration": 36.73947477340698, "step": 40125}
{"episode_reward": 835.6595948728097, "episode": 322.0, "critic_loss": 92.2817774963379, "critic_target_Q_variance_m=2": 98197.196875, "critic_Q1_variance_k=2": 2.3217141761779785, "critic_Q2_variance_k=2": 2.3155933580398558, "actor_loss": -625.0429579211819, "actor_mean_entropy": -0.06383036083031085, "alpha_loss": -0.005718026009778823, "alpha_value": 0.20663408075999434, "duration": 32.383705377578735, "step": 40250}
{"episode_reward": 829.3489340992027, "episode": 323.0, "critic_loss": 86.73085292053223, "critic_target_Q_variance_m=2": 98589.0228125, "critic_Q1_variance_k=2": 2.154413813114166, "critic_Q2_variance_k=2": 2.1170710577964784, "actor_loss": -626.6481177920386, "actor_mean_entropy": -0.06294828691771107, "alpha_loss": 0.002244318011290734, "alpha_value": 0.20664051000743264, "duration": 34.74324321746826, "step": 40375}
{"episode_reward": 825.2644955480059, "episode": 324.0, "critic_loss": 92.50929751586914, "critic_target_Q_variance_m=2": 99019.3645625, "critic_Q1_variance_k=2": 2.0837746024131776, "critic_Q2_variance_k=2": 2.0861671948432923, "actor_loss": -628.036364155431, "actor_mean_entropy": -0.004980041495253963, "alpha_loss": 0.002059106369532885, "alpha_value": 0.20668791480236823, "duration": 34.3221070766449, "step": 40500}
{"episode_reward": 825.2871902597384, "episode": 325.0, "critic_loss": 98.07997515869141, "critic_target_Q_variance_m=2": 99060.986, "critic_Q1_variance_k=2": 2.2554124488830567, "critic_Q2_variance_k=2": 2.2070204248428347, "actor_loss": -627.9564499627976, "actor_mean_entropy": 0.00018291352760224115, "alpha_loss": 0.008685049482636036, "alpha_value": 0.20616003838104868, "duration": 34.58589220046997, "step": 40625}
{"episode_reward": 835.7012823975296, "episode": 326.0, "critic_loss": 89.49768640136719, "critic_target_Q_variance_m=2": 99285.38175, "critic_Q1_variance_k=2": 2.1257779779434203, "critic_Q2_variance_k=2": 2.1677974505424498, "actor_loss": -629.3498131536668, "actor_mean_entropy": -0.080194822963207, "alpha_loss": -0.0003856563595153632, "alpha_value": 0.20617929830978923, "duration": 34.466984033584595, "step": 40750}
{"episode_reward": 837.7775423950037, "episode": 327.0, "critic_loss": 83.97364622497558, "critic_target_Q_variance_m=2": 99230.885375, "critic_Q1_variance_k=2": 1.952000131368637, "critic_Q2_variance_k=2": 1.9610792303085327, "actor_loss": -628.1080448211186, "actor_mean_entropy": -0.0426730534860066, "alpha_loss": -0.00369940338552826, "alpha_value": 0.2062730193205705, "duration": 34.56724715232849, "step": 40875}
{"episode_reward": 833.9052351179649, "episode": 328.0, "critic_loss": 75.48594338989258, "critic_target_Q_variance_m=2": 99680.921, "critic_Q1_variance_k=2": 1.9262207193374634, "critic_Q2_variance_k=2": 1.9735608081817626, "actor_loss": -629.8795126638105, "actor_mean_entropy": -0.05946542675636949, "alpha_loss": -0.007744825246082919, "alpha_value": 0.20638967971290476, "duration": 34.40907096862793, "step": 41000}
{"episode_reward": 841.9137315772692, "episode": 329.0, "critic_loss": 69.55034791564941, "critic_target_Q_variance_m=2": 100089.1215, "critic_Q1_variance_k=2": 1.9105175819396973, "critic_Q2_variance_k=2": 1.9234136171340943, "actor_loss": -631.8163277762277, "actor_mean_entropy": -0.028689971223237024, "alpha_loss": -0.003410823465812774, "alpha_value": 0.20679972088410578, "duration": 35.06928038597107, "step": 41125}
{"episode_reward": 837.625854517589, "episode": 330.0, "critic_loss": 78.10129475402832, "critic_target_Q_variance_m=2": 100313.710625, "critic_Q1_variance_k=2": 2.071928431034088, "critic_Q2_variance_k=2": 2.1028365812301635, "actor_loss": -631.9107606949344, "actor_mean_entropy": -0.02437407898926927, "alpha_loss": -0.004041316652400119, "alpha_value": 0.20690821130218304, "duration": 34.63661456108093, "step": 41250}
{"episode_reward": 826.5192888647105, "episode": 331.0, "critic_loss": 84.49539878845215, "critic_target_Q_variance_m=2": 100605.598, "critic_Q1_variance_k=2": 2.1287743272781374, "critic_Q2_variance_k=2": 2.084753845214844, "actor_loss": -632.7997271825396, "actor_mean_entropy": -0.012230122476697915, "alpha_loss": 0.007202464968912185, "alpha_value": 0.20687096408869163, "duration": 34.7498505115509, "step": 41375}
{"episode_reward": 832.725608049074, "episode": 332.0, "critic_loss": 95.5954100341797, "critic_target_Q_variance_m=2": 100727.8640625, "critic_Q1_variance_k=2": 2.0432286920547487, "critic_Q2_variance_k=2": 2.0124845032691954, "actor_loss": -633.752448297316, "actor_mean_entropy": -0.03317234629104214, "alpha_loss": 0.007334440800120994, "alpha_value": 0.20663735670080333, "duration": 34.3800151348114, "step": 41500}
{"episode_reward": 820.63858932056, "episode": 333.0, "critic_loss": 82.82789886474609, "critic_target_Q_variance_m=2": 100934.60225, "critic_Q1_variance_k=2": 2.070957173347473, "critic_Q2_variance_k=2": 2.0960933637619017, "actor_loss": -634.444587828621, "actor_mean_entropy": -0.10711938994271415, "alpha_loss": -0.012271209623635052, "alpha_value": 0.20675391884416297, "duration": 34.586554527282715, "step": 41625}
{"episode_reward": 842.0145470933354, "episode": 334.0, "critic_loss": 81.58356118774414, "critic_target_Q_variance_m=2": 100962.5911875, "critic_Q1_variance_k=2": 1.9830668659210204, "critic_Q2_variance_k=2": 1.9614202766418456, "actor_loss": -634.0985894972279, "actor_mean_entropy": -0.06934189706319763, "alpha_loss": -0.003158567570931008, "alpha_value": 0.20699713193060876, "duration": 34.69172692298889, "step": 41750}
{"episode_reward": 826.8741116298677, "episode": 335.0, "critic_loss": 91.88586965942383, "critic_target_Q_variance_m=2": 101410.453, "critic_Q1_variance_k=2": 2.14900918006897, "critic_Q2_variance_k=2": 2.173949456691742, "actor_loss": -635.7659592401413, "actor_mean_entropy": -0.0013926125294159329, "alpha_loss": 0.001993700610621581, "alpha_value": 0.20705790067740135, "duration": 34.721439838409424, "step": 41875}
{"episode_reward": 822.8276936404911, "episode": 336.0, "critic_loss": 86.64993179321289, "critic_target_Q_variance_m=2": 101622.791, "critic_Q1_variance_k=2": 2.233151361942291, "critic_Q2_variance_k=2": 2.274953577041626, "actor_loss": -635.9308176348286, "actor_mean_entropy": 0.011618802203766761, "alpha_loss": 0.0021170835205984694, "alpha_value": 0.20699367685158943, "duration": 34.536373138427734, "step": 42000}
{"episode_reward": 825.1198438451412, "episode": 337.0, "critic_loss": 86.00466525268554, "critic_target_Q_variance_m=2": 101908.6455625, "critic_Q1_variance_k=2": 2.2288262152671816, "critic_Q2_variance_k=2": 2.229012118816376, "actor_loss": -636.8142496744791, "actor_mean_entropy": 0.00964952606175627, "alpha_loss": 0.007584404832284365, "alpha_value": 0.20668808631539118, "duration": 34.806538820266724, "step": 42125}
{"episode_reward": 824.2271917232249, "episode": 338.0, "critic_loss": 95.40122921752929, "critic_target_Q_variance_m=2": 102406.3866875, "critic_Q1_variance_k=2": 2.4144910411834717, "critic_Q2_variance_k=2": 2.4855614461898803, "actor_loss": -638.8230521909652, "actor_mean_entropy": -0.037540640621896715, "alpha_loss": 0.008208106035336612, "alpha_value": 0.20619915287808963, "duration": 34.40341401100159, "step": 42250}
{"episode_reward": 838.2818019341728, "episode": 339.0, "critic_loss": 86.77297412109375, "critic_target_Q_variance_m=2": 102580.4269375, "critic_Q1_variance_k=2": 2.141176456928253, "critic_Q2_variance_k=2": 2.0750148997306823, "actor_loss": -639.4855133541047, "actor_mean_entropy": 0.013849312646521462, "alpha_loss": 0.0028587315704614396, "alpha_value": 0.20599887088048807, "duration": 34.786360025405884, "step": 42375}
{"episode_reward": 736.6870989499753, "episode": 340.0, "critic_loss": 86.64027955627441, "critic_target_Q_variance_m=2": 102838.494125, "critic_Q1_variance_k=2": 2.1915073256492614, "critic_Q2_variance_k=2": 2.212963631153107, "actor_loss": -639.8492195375504, "actor_mean_entropy": 0.0334308638928398, "alpha_loss": 0.002991821541781387, "alpha_value": 0.20583826649954243, "duration": 34.878878116607666, "step": 42500}
{"episode_reward": 818.8238644632306, "episode": 341.0, "critic_loss": 93.80156646728516, "critic_target_Q_variance_m=2": 103133.6908125, "critic_Q1_variance_k=2": 2.135979745388031, "critic_Q2_variance_k=2": 2.1344776067733764, "actor_loss": -641.3412717788939, "actor_mean_entropy": -0.012380230462267286, "alpha_loss": 0.006609405346569561, "alpha_value": 0.20577459768001333, "duration": 34.5645112991333, "step": 42625}
{"episode_reward": 828.0984741194391, "episode": 342.0, "critic_loss": 86.03284088134765, "critic_target_Q_variance_m=2": 103338.996, "critic_Q1_variance_k=2": 2.095237093448639, "critic_Q2_variance_k=2": 2.0585305314064026, "actor_loss": -641.9557593560988, "actor_mean_entropy": -0.04528371124498306, "alpha_loss": -0.0003442468024009178, "alpha_value": 0.20553540783646293, "duration": 34.63179898262024, "step": 42750}
{"episode_reward": 815.9564940655997, "episode": 343.0, "critic_loss": 83.16625318908692, "critic_target_Q_variance_m=2": 103408.271875, "critic_Q1_variance_k=2": 2.126978735923767, "critic_Q2_variance_k=2": 2.1174408679008483, "actor_loss": -642.3836853996156, "actor_mean_entropy": 0.055916791456559346, "alpha_loss": 0.009806322820839427, "alpha_value": 0.20551595720509303, "duration": 34.90625309944153, "step": 42875}
{"episode_reward": 826.7511116087277, "episode": 344.0, "critic_loss": 89.23443295288087, "critic_target_Q_variance_m=2": 103476.1434375, "critic_Q1_variance_k=2": 1.974465774536133, "critic_Q2_variance_k=2": 1.9777895917892456, "actor_loss": -641.739013671875, "actor_mean_entropy": 0.11576868569658648, "alpha_loss": 0.014284642732461853, "alpha_value": 0.2048499844060461, "duration": 34.479241609573364, "step": 43000}
{"episode_reward": 819.8603798459209, "episode": 345.0, "critic_loss": 81.63248362731933, "critic_target_Q_variance_m=2": 103698.0220625, "critic_Q1_variance_k=2": 1.9084739203453065, "critic_Q2_variance_k=2": 1.8895673203468322, "actor_loss": -642.8848780071925, "actor_mean_entropy": 0.022929029332266912, "alpha_loss": 0.013729411406472089, "alpha_value": 0.20411068607039523, "duration": 34.608598947525024, "step": 43125}
{"episode_reward": 842.0053325164158, "episode": 346.0, "critic_loss": 76.1518094177246, "critic_target_Q_variance_m=2": 104041.849875, "critic_Q1_variance_k=2": 1.9550227184295654, "critic_Q2_variance_k=2": 1.9555762887001038, "actor_loss": -644.1374777517011, "actor_mean_entropy": -0.04930439507288317, "alpha_loss": -0.0014069898790048977, "alpha_value": 0.2038076030092701, "duration": 34.536576986312866, "step": 43250}
{"episode_reward": 829.1084777023431, "episode": 347.0, "critic_loss": 84.86200001525879, "critic_target_Q_variance_m=2": 104329.513125, "critic_Q1_variance_k=2": 2.044781237602234, "critic_Q2_variance_k=2": 2.0041607723236083, "actor_loss": -645.2691214425223, "actor_mean_entropy": -0.0019234738770931485, "alpha_loss": 0.014812499292135711, "alpha_value": 0.20361332482417252, "duration": 35.192856311798096, "step": 43375}
{"episode_reward": 818.1859342837689, "episode": 348.0, "critic_loss": 78.01126084899903, "critic_target_Q_variance_m=2": 104522.5553125, "critic_Q1_variance_k=2": 2.05585843706131, "critic_Q2_variance_k=2": 2.0472577295303345, "actor_loss": -644.7371373330393, "actor_mean_entropy": -0.014819197837383516, "alpha_loss": 0.0013676329418235728, "alpha_value": 0.20333572474845132, "duration": 34.772998332977295, "step": 43500}
{"episode_reward": 832.8927353414224, "episode": 349.0, "critic_loss": 75.83383406066895, "critic_target_Q_variance_m=2": 104580.1109375, "critic_Q1_variance_k=2": 1.9295032377243042, "critic_Q2_variance_k=2": 1.9379936318397522, "actor_loss": -645.1693502759176, "actor_mean_entropy": -0.00270326914531844, "alpha_loss": 0.011224673092660923, "alpha_value": 0.202896767377307, "duration": 34.67783188819885, "step": 43625}
{"episode_reward": 821.4890979281265, "episode": 350.0, "critic_loss": 78.71908721923828, "critic_target_Q_variance_m=2": 105053.27075, "critic_Q1_variance_k=2": 2.0437741899490356, "critic_Q2_variance_k=2": 2.058182098388672, "actor_loss": -647.5264548024824, "actor_mean_entropy": -0.023806402504804633, "alpha_loss": 0.0033126641477968905, "alpha_value": 0.20251793941370522, "duration": 34.40295338630676, "step": 43750}
{"episode_reward": 840.049473551146, "episode": 351.0, "critic_loss": 81.3583521118164, "critic_target_Q_variance_m=2": 104994.6745625, "critic_Q1_variance_k=2": 2.0927631797790527, "critic_Q2_variance_k=2": 2.1055390129089355, "actor_loss": -647.3183138408358, "actor_mean_entropy": 0.004239834549408111, "alpha_loss": 0.004054424825996634, "alpha_value": 0.20249098042567995, "duration": 35.031327962875366, "step": 43875}
{"episode_reward": 830.7921447782329, "episode": 352.0, "critic_loss": 90.57987741088867, "critic_target_Q_variance_m=2": 105178.5565625, "critic_Q1_variance_k=2": 2.2116094484329225, "critic_Q2_variance_k=2": 2.2219317564964296, "actor_loss": -647.5574124243951, "actor_mean_entropy": 0.010578751113385923, "alpha_loss": 0.0029087708812327155, "alpha_value": 0.2022033217897163, "duration": 34.54313683509827, "step": 44000}
{"episode_reward": 827.3113987544499, "episode": 353.0, "critic_loss": 90.97485800170898, "critic_target_Q_variance_m=2": 105777.3451875, "critic_Q1_variance_k=2": 2.1601983819007873, "critic_Q2_variance_k=2": 2.212628490924835, "actor_loss": -649.4710199265253, "actor_mean_entropy": -0.037429092185837884, "alpha_loss": 0.007763302478466242, "alpha_value": 0.20210384017854355, "duration": 35.38171029090881, "step": 44125}
{"episode_reward": 821.0206707263158, "episode": 354.0, "critic_loss": 81.0767830505371, "critic_target_Q_variance_m=2": 105637.5050625, "critic_Q1_variance_k=2": 1.946234959602356, "critic_Q2_variance_k=2": 1.9682364377975463, "actor_loss": -649.0566081385458, "actor_mean_entropy": 0.016153621277020823, "alpha_loss": 0.009046912347266992, "alpha_value": 0.20160567390792639, "duration": 34.28323674201965, "step": 44250}
{"episode_reward": 801.5449596756125, "episode": 355.0, "critic_loss": 90.4607844543457, "critic_target_Q_variance_m=2": 106140.4570625, "critic_Q1_variance_k=2": 1.8924812355041505, "critic_Q2_variance_k=2": 1.8861264309883117, "actor_loss": -650.0949929858011, "actor_mean_entropy": 0.008103451795048185, "alpha_loss": 0.0065899548372105946, "alpha_value": 0.2011650008685019, "duration": 34.63250923156738, "step": 44375}
{"episode_reward": 834.6800476221053, "episode": 356.0, "critic_loss": 88.22469134521485, "critic_target_Q_variance_m=2": 105975.6101875, "critic_Q1_variance_k=2": 2.169234260082245, "critic_Q2_variance_k=2": 2.1624236755371093, "actor_loss": -649.7129506757183, "actor_mean_entropy": -0.0670589022638817, "alpha_loss": -0.0008805872752301154, "alpha_value": 0.20119175764852454, "duration": 34.59810400009155, "step": 44500}
{"episode_reward": 826.066270090449, "episode": 357.0, "critic_loss": 91.18719499206543, "critic_target_Q_variance_m=2": 106533.0046875, "critic_Q1_variance_k=2": 1.9850018916130066, "critic_Q2_variance_k=2": 2.014231586933136, "actor_loss": -651.1192578512524, "actor_mean_entropy": 0.006511651363874238, "alpha_loss": 0.0034653700052923154, "alpha_value": 0.20112127224189733, "duration": 34.55105948448181, "step": 44625}
{"episode_reward": 833.2537034249881, "episode": 358.0, "critic_loss": 76.5353673248291, "critic_target_Q_variance_m=2": 106822.2124375, "critic_Q1_variance_k=2": 1.9034827094078064, "critic_Q2_variance_k=2": 1.8855810656547547, "actor_loss": -652.4824740502143, "actor_mean_entropy": -0.0434465168584739, "alpha_loss": 0.002996186763348599, "alpha_value": 0.20088185442736212, "duration": 34.870325803756714, "step": 44750}
{"episode_reward": 840.4573702578184, "episode": 359.0, "critic_loss": 82.22422976684571, "critic_target_Q_variance_m=2": 107020.1528125, "critic_Q1_variance_k=2": 1.9806185402870178, "critic_Q2_variance_k=2": 1.9945716562271119, "actor_loss": -653.3253842308408, "actor_mean_entropy": -0.035767713088601355, "alpha_loss": 0.010635769519481867, "alpha_value": 0.20071969982512303, "duration": 34.66681885719299, "step": 44875}
{"episode_reward": 826.4862130679105, "episode": 360.0, "critic_loss": 90.26053424072266, "critic_target_Q_variance_m=2": 106696.9455, "critic_Q1_variance_k=2": 2.0884103817939756, "critic_Q2_variance_k=2": 2.1444506497383116, "actor_loss": -652.6410758726058, "actor_mean_entropy": -0.000718424637471476, "alpha_loss": 0.014318061481800771, "alpha_value": 0.19997092067427447, "duration": 34.702751874923706, "step": 45000}
{"episode_reward": 828.3928825536962, "episode": 361.0, "critic_loss": 81.83431793212891, "critic_target_Q_variance_m=2": 107137.2065, "critic_Q1_variance_k=2": 1.9458551440238954, "critic_Q2_variance_k=2": 1.9410640063285827, "actor_loss": -653.1755971757192, "actor_mean_entropy": -0.013202619487567553, "alpha_loss": 0.009241897464981155, "alpha_value": 0.19949062449618304, "duration": 34.770880460739136, "step": 45125}
{"episode_reward": 830.1268854574118, "episode": 362.0, "critic_loss": 81.08208267211914, "critic_target_Q_variance_m=2": 107653.7210625, "critic_Q1_variance_k=2": 1.8935251741409302, "critic_Q2_variance_k=2": 1.9253200097084044, "actor_loss": -655.4712416125882, "actor_mean_entropy": -0.07180124431127502, "alpha_loss": 0.003505947714250895, "alpha_value": 0.1991298811080346, "duration": 34.60079312324524, "step": 45250}
{"episode_reward": 831.0637761188376, "episode": 363.0, "critic_loss": 77.3442853088379, "critic_target_Q_variance_m=2": 107892.7274375, "critic_Q1_variance_k=2": 1.8684457657337188, "critic_Q2_variance_k=2": 1.8702520191669465, "actor_loss": -655.4190886966766, "actor_mean_entropy": -0.08870816538258204, "alpha_loss": 0.002452853900779571, "alpha_value": 0.19900197995943972, "duration": 34.676265716552734, "step": 45375}
{"episode_reward": 841.4377214689039, "episode": 364.0, "critic_loss": 79.37975843811036, "critic_target_Q_variance_m=2": 108117.64625, "critic_Q1_variance_k=2": 1.8313909459114075, "critic_Q2_variance_k=2": 1.788699203968048, "actor_loss": -657.0240143806703, "actor_mean_entropy": -0.0010365266052465285, "alpha_loss": 0.014818472675077857, "alpha_value": 0.1986832617058194, "duration": 34.543217182159424, "step": 45500}
{"episode_reward": 830.3035051062261, "episode": 365.0, "critic_loss": 71.90468966674804, "critic_target_Q_variance_m=2": 108050.229375, "critic_Q1_variance_k=2": 1.9189885067939758, "critic_Q2_variance_k=2": 1.9578976969718933, "actor_loss": -656.4854465060764, "actor_mean_entropy": -0.038415945534195216, "alpha_loss": 0.0021667429818845695, "alpha_value": 0.1983178881114952, "duration": 34.59743118286133, "step": 45625}
{"episode_reward": 831.5592762281877, "episode": 366.0, "critic_loss": 90.5465923461914, "critic_target_Q_variance_m=2": 108361.0015625, "critic_Q1_variance_k=2": 2.011432760000229, "critic_Q2_variance_k=2": 2.011664719581604, "actor_loss": -657.3907903855846, "actor_mean_entropy": -0.04701377884034188, "alpha_loss": 0.01498978325886832, "alpha_value": 0.19787641670215586, "duration": 34.61304998397827, "step": 45750}
{"episode_reward": 828.5621651114723, "episode": 367.0, "critic_loss": 84.9325336151123, "critic_target_Q_variance_m=2": 108620.911375, "critic_Q1_variance_k=2": 2.0997569441795347, "critic_Q2_variance_k=2": 2.0509079842567446, "actor_loss": -657.7133837503101, "actor_mean_entropy": -0.005954114838488518, "alpha_loss": 0.007588168879645685, "alpha_value": 0.19740493596750872, "duration": 34.59967494010925, "step": 45875}
{"episode_reward": 833.973648042606, "episode": 368.0, "critic_loss": 80.49042593383788, "critic_target_Q_variance_m=2": 108812.8403125, "critic_Q1_variance_k=2": 1.9851962676048278, "critic_Q2_variance_k=2": 1.9845443983078004, "actor_loss": -658.5394651351437, "actor_mean_entropy": 0.05487307885120953, "alpha_loss": 0.01233936323889441, "alpha_value": 0.19695734063257375, "duration": 34.53072500228882, "step": 46000}
{"episode_reward": 820.2810185838716, "episode": 369.0, "critic_loss": 86.63959292602539, "critic_target_Q_variance_m=2": 108987.7079375, "critic_Q1_variance_k=2": 1.9008745841979982, "critic_Q2_variance_k=2": 1.8948222408294677, "actor_loss": -659.3227074032739, "actor_mean_entropy": 0.011516429720416901, "alpha_loss": 0.011747335904233512, "alpha_value": 0.19642504885596068, "duration": 34.78423523902893, "step": 46125}
{"episode_reward": 816.6597276539469, "episode": 370.0, "critic_loss": 85.48112426757812, "critic_target_Q_variance_m=2": 109342.9925625, "critic_Q1_variance_k=2": 1.905762137413025, "critic_Q2_variance_k=2": 1.8891694073677063, "actor_loss": -660.1056164157006, "actor_mean_entropy": -0.005048091478285289, "alpha_loss": 0.011091245034138763, "alpha_value": 0.19586773052590534, "duration": 34.759748220443726, "step": 46250}
{"episode_reward": 821.458041515595, "episode": 371.0, "critic_loss": 80.11932899475097, "critic_target_Q_variance_m=2": 109622.73425, "critic_Q1_variance_k=2": 2.1171390833854677, "critic_Q2_variance_k=2": 2.1480552124977113, "actor_loss": -660.5677034892733, "actor_mean_entropy": -0.08132470505578178, "alpha_loss": 0.007582101261331921, "alpha_value": 0.19550119562635954, "duration": 34.62942171096802, "step": 46375}
{"episode_reward": 825.7111913966507, "episode": 372.0, "critic_loss": 67.16603247070313, "critic_target_Q_variance_m=2": 109607.1734375, "critic_Q1_variance_k=2": 1.8515571160316466, "critic_Q2_variance_k=2": 1.8453454852104187, "actor_loss": -660.8129735146799, "actor_mean_entropy": -0.02986655252114419, "alpha_loss": -0.005161255673174897, "alpha_value": 0.1954297800521802, "duration": 34.584442377090454, "step": 46500}
{"episode_reward": 828.2220684898128, "episode": 373.0, "critic_loss": 84.24275698852539, "critic_target_Q_variance_m=2": 109891.25725, "critic_Q1_variance_k=2": 1.925353394985199, "critic_Q2_variance_k=2": 1.9462693147659302, "actor_loss": -661.3675062391493, "actor_mean_entropy": -0.08614036216149254, "alpha_loss": -0.0037480354131687256, "alpha_value": 0.19568297169460275, "duration": 34.49479699134827, "step": 46625}
{"episode_reward": 835.0686494722063, "episode": 374.0, "critic_loss": 77.4041732788086, "critic_target_Q_variance_m=2": 110173.4245, "critic_Q1_variance_k=2": 1.8954236674308778, "critic_Q2_variance_k=2": 1.9013284239768982, "actor_loss": -662.8566097136467, "actor_mean_entropy": -0.08991465224854407, "alpha_loss": 0.0024327085007943452, "alpha_value": 0.19572308775151553, "duration": 26.63730812072754, "step": 46750}
{"episode_reward": 835.6214174847313, "episode": 375.0, "critic_loss": 81.72386549377441, "critic_target_Q_variance_m=2": 110067.951125, "critic_Q1_variance_k=2": 1.8715043573379517, "critic_Q2_variance_k=2": 1.869522822380066, "actor_loss": -662.0971999395462, "actor_mean_entropy": -0.1469146085991746, "alpha_loss": -0.010956933252542975, "alpha_value": 0.19579495653292683, "duration": 27.101869821548462, "step": 46875}
{"episode_reward": 839.0296341821246, "episode": 376.0, "critic_loss": 82.83074391174317, "critic_target_Q_variance_m=2": 110154.0734375, "critic_Q1_variance_k=2": 2.053876790046692, "critic_Q2_variance_k=2": 2.040101017951965, "actor_loss": -662.7775603263609, "actor_mean_entropy": -0.06296742232816835, "alpha_loss": -0.003858070099546063, "alpha_value": 0.1961379536813051, "duration": 27.023337364196777, "step": 47000}
{"episode_reward": 831.7308232900666, "episode": 377.0, "critic_loss": 76.14432019042968, "critic_target_Q_variance_m=2": 110535.0843125, "critic_Q1_variance_k=2": 1.820301387310028, "critic_Q2_variance_k=2": 1.8174577651023864, "actor_loss": -664.4783238002232, "actor_mean_entropy": -0.04754376417351148, "alpha_loss": 0.008927977703038662, "alpha_value": 0.1960972926939945, "duration": 26.72618842124939, "step": 47125}
{"episode_reward": 826.5155911543575, "episode": 378.0, "critic_loss": 74.85325132751464, "critic_target_Q_variance_m=2": 110809.01275, "critic_Q1_variance_k=2": 1.8392480049133302, "critic_Q2_variance_k=2": 1.8763488178253174, "actor_loss": -664.7858305900328, "actor_mean_entropy": -0.07762250262162378, "alpha_loss": 0.0012006270624096355, "alpha_value": 0.1957854499377427, "duration": 23.773109674453735, "step": 47250}
{"episode_reward": 834.1160898010645, "episode": 379.0, "critic_loss": 78.89850344848632, "critic_target_Q_variance_m=2": 110800.792875, "critic_Q1_variance_k=2": 1.7234153580665588, "critic_Q2_variance_k=2": 1.7262765653133392, "actor_loss": -664.5806119404142, "actor_mean_entropy": -0.020199710089299414, "alpha_loss": 0.0060134693492381345, "alpha_value": 0.19570083313007042, "duration": 23.470340251922607, "step": 47375}
{"episode_reward": 825.9620178108123, "episode": 380.0, "critic_loss": 78.96278735351562, "critic_target_Q_variance_m=2": 111160.6245625, "critic_Q1_variance_k=2": 2.0670969362258913, "critic_Q2_variance_k=2": 2.067562828540802, "actor_loss": -665.6383932790449, "actor_mean_entropy": -0.11786588942331652, "alpha_loss": -0.00512507748639872, "alpha_value": 0.19565103534882075, "duration": 23.336973905563354, "step": 47500}
{"episode_reward": 837.1315690763394, "episode": 381.0, "critic_loss": 68.31661976623535, "critic_target_Q_variance_m=2": 111574.1165, "critic_Q1_variance_k=2": 1.812093629360199, "critic_Q2_variance_k=2": 1.798545536518097, "actor_loss": -667.0780387757317, "actor_mean_entropy": -0.09517313746942414, "alpha_loss": 0.0002140760835674074, "alpha_value": 0.19575759939093265, "duration": 23.43085503578186, "step": 47625}
{"episode_reward": 822.0889053462183, "episode": 382.0, "critic_loss": 71.29253964233398, "critic_target_Q_variance_m=2": 111716.3425625, "critic_Q1_variance_k=2": 1.8279705958366395, "critic_Q2_variance_k=2": 1.8234244413375855, "actor_loss": -667.4722929923765, "actor_mean_entropy": -0.10311207079118298, "alpha_loss": 0.004186781615229143, "alpha_value": 0.19567350292485872, "duration": 25.01164221763611, "step": 47750}
{"episode_reward": 823.1800879479546, "episode": 383.0, "critic_loss": 77.2770743560791, "critic_target_Q_variance_m=2": 111747.457, "critic_Q1_variance_k=2": 1.9227502484321595, "critic_Q2_variance_k=2": 1.9605716767311097, "actor_loss": -667.8354879712301, "actor_mean_entropy": -0.16336714133383737, "alpha_loss": -0.007243593925580619, "alpha_value": 0.19573163312461989, "duration": 24.92732071876526, "step": 47875}
{"episode_reward": 843.2165327468047, "episode": 384.0, "critic_loss": 73.16761706542968, "critic_target_Q_variance_m=2": 112156.9515, "critic_Q1_variance_k=2": 2.0039196109771726, "critic_Q2_variance_k=2": 1.93844615983963, "actor_loss": -668.8140810074344, "actor_mean_entropy": -0.15021001307233686, "alpha_loss": -0.008953933806849583, "alpha_value": 0.19615962377277119, "duration": 23.389872312545776, "step": 48000}
{"episode_reward": 828.3622652935672, "episode": 385.0, "critic_loss": 84.91511337280274, "critic_target_Q_variance_m=2": 111967.430375, "critic_Q1_variance_k=2": 2.210219814300537, "critic_Q2_variance_k=2": 2.1486486639976503, "actor_loss": -668.2943124922496, "actor_mean_entropy": -0.11422833936318519, "alpha_loss": -0.0036288222024542472, "alpha_value": 0.1964687887521344, "duration": 23.734150171279907, "step": 48125}
{"episode_reward": 833.9298323083367, "episode": 386.0, "critic_loss": 75.80324293518066, "critic_target_Q_variance_m=2": 112273.6771875, "critic_Q1_variance_k=2": 1.8257356009483336, "critic_Q2_variance_k=2": 1.842019567489624, "actor_loss": -669.958000921434, "actor_mean_entropy": -0.08333944168783003, "alpha_loss": 0.012117502046748996, "alpha_value": 0.19615847282271132, "duration": 23.648443698883057, "step": 48250}
{"episode_reward": 814.0284130952906, "episode": 387.0, "critic_loss": 88.33624716186523, "critic_target_Q_variance_m=2": 112608.373375, "critic_Q1_variance_k=2": 2.052155306816101, "critic_Q2_variance_k=2": 2.075955406665802, "actor_loss": -669.7292412651909, "actor_mean_entropy": -0.03490103065731034, "alpha_loss": 0.008285351651942446, "alpha_value": 0.1956963304261485, "duration": 24.43047332763672, "step": 48375}
{"episode_reward": 821.9418029484708, "episode": 388.0, "critic_loss": 73.85937739562988, "critic_target_Q_variance_m=2": 112735.495125, "critic_Q1_variance_k=2": 1.7999471483230591, "critic_Q2_variance_k=2": 1.815985370159149, "actor_loss": -670.2997603877898, "actor_mean_entropy": -0.0764432905782615, "alpha_loss": -0.0009226682070162028, "alpha_value": 0.19548912588022319, "duration": 23.74522352218628, "step": 48500}
{"episode_reward": 827.6542765012163, "episode": 389.0, "critic_loss": 82.42190942382813, "critic_target_Q_variance_m=2": 113038.316625, "critic_Q1_variance_k=2": 1.9730515093803407, "critic_Q2_variance_k=2": 1.9649153575897216, "actor_loss": -671.9916701543899, "actor_mean_entropy": 0.012706842746526475, "alpha_loss": 0.01126460266846513, "alpha_value": 0.19545279744053592, "duration": 23.649386405944824, "step": 48625}
{"episode_reward": 823.6699442703775, "episode": 390.0, "critic_loss": 81.58575053405762, "critic_target_Q_variance_m=2": 112952.9021875, "critic_Q1_variance_k=2": 1.8927525444030762, "critic_Q2_variance_k=2": 1.9027706117630006, "actor_loss": -671.2511340725806, "actor_mean_entropy": -0.04579272603375777, "alpha_loss": 0.006308563752099872, "alpha_value": 0.1949019649713632, "duration": 24.28496217727661, "step": 48750}
{"episode_reward": 797.0021278152849, "episode": 391.0, "critic_loss": 76.57400387573242, "critic_target_Q_variance_m=2": 113433.5946875, "critic_Q1_variance_k=2": 1.8952354989051818, "critic_Q2_variance_k=2": 1.9125734605789184, "actor_loss": -672.8827156187996, "actor_mean_entropy": -0.06157919705387146, "alpha_loss": 0.0038797480039416796, "alpha_value": 0.19462178704853222, "duration": 24.157700777053833, "step": 48875}
{"episode_reward": 834.8834907943757, "episode": 392.0, "critic_loss": 69.71743984985352, "critic_target_Q_variance_m=2": 113630.7528125, "critic_Q1_variance_k=2": 1.9055689282417296, "critic_Q2_variance_k=2": 1.875482560634613, "actor_loss": -672.7845429451235, "actor_mean_entropy": -0.0884199320909477, "alpha_loss": 0.0063916162076976995, "alpha_value": 0.19450256624203638, "duration": 23.97537612915039, "step": 49000}
{"episode_reward": 833.8248692491934, "episode": 393.0, "critic_loss": 63.86594613647461, "critic_target_Q_variance_m=2": 113607.6190625, "critic_Q1_variance_k=2": 1.6755282702445984, "critic_Q2_variance_k=2": 1.6732051382064819, "actor_loss": -672.7635565863716, "actor_mean_entropy": -0.05985012384397643, "alpha_loss": 0.009933427220121735, "alpha_value": 0.19412939032880122, "duration": 23.33946704864502, "step": 49125}
{"episode_reward": 820.2129259387219, "episode": 394.0, "critic_loss": 69.61050283813476, "critic_target_Q_variance_m=2": 113826.480125, "critic_Q1_variance_k=2": 1.7480641446113587, "critic_Q2_variance_k=2": 1.7516225531101226, "actor_loss": -673.239269625756, "actor_mean_entropy": -0.010647934200542589, "alpha_loss": 0.011432409128775039, "alpha_value": 0.19358611645123483, "duration": 23.233821392059326, "step": 49250}
{"episode_reward": 825.7061218995001, "episode": 395.0, "critic_loss": 64.64804486083985, "critic_target_Q_variance_m=2": 113861.3549375, "critic_Q1_variance_k=2": 1.763965967655182, "critic_Q2_variance_k=2": 1.736627278327942, "actor_loss": -673.7112746465774, "actor_mean_entropy": 0.017073659669785274, "alpha_loss": 0.017084028220750273, "alpha_value": 0.19304338916148597, "duration": 23.366541385650635, "step": 49375}
{"episode_reward": 826.2608574217288, "episode": 396.0, "critic_loss": 79.72108532714844, "critic_target_Q_variance_m=2": 113999.6269375, "critic_Q1_variance_k=2": 1.8359299178123474, "critic_Q2_variance_k=2": 1.8279989681243896, "actor_loss": -673.7237381473665, "actor_mean_entropy": 0.04083945283726338, "alpha_loss": 0.014875897341558048, "alpha_value": 0.1921913405689687, "duration": 23.969974517822266, "step": 49500}
{"episode_reward": 837.6654881088554, "episode": 397.0, "critic_loss": 80.24736390686036, "critic_target_Q_variance_m=2": 114167.2564375, "critic_Q1_variance_k=2": 1.9117183594703675, "critic_Q2_variance_k=2": 1.9880828399658204, "actor_loss": -674.6083441840278, "actor_mean_entropy": -0.07171950075361463, "alpha_loss": 0.004837675408149759, "alpha_value": 0.19168591748356698, "duration": 24.480751752853394, "step": 49625}
{"episode_reward": 839.4323734920293, "episode": 398.0, "critic_loss": 74.30423706054688, "critic_target_Q_variance_m=2": 114620.305875, "critic_Q1_variance_k=2": 1.8609271492958068, "critic_Q2_variance_k=2": 1.8787490932941437, "actor_loss": -676.3345179403982, "actor_mean_entropy": -0.07351688139380948, "alpha_loss": 0.009969392802656418, "alpha_value": 0.19142774932301437, "duration": 24.534663200378418, "step": 49750}
{"episode_reward": 827.6029610469518, "episode": 399.0, "critic_loss": 73.61637649536132, "critic_target_Q_variance_m=2": 114652.4931875, "critic_Q1_variance_k=2": 1.860870960712433, "critic_Q2_variance_k=2": 1.8509769005775452, "actor_loss": -676.5759945824033, "actor_mean_entropy": -0.1201078709628847, "alpha_loss": 0.00039291586948647384, "alpha_value": 0.1911764063947044, "duration": 24.76389789581299, "step": 49875}
{"episode_reward": 836.8180413835029, "episode": 400.0, "critic_loss": 72.56298670959472, "critic_target_Q_variance_m=2": 114926.5859375, "critic_Q1_variance_k=2": 1.8266241340637206, "critic_Q2_variance_k=2": 1.8255004296302795, "actor_loss": -676.1102324455015, "actor_mean_entropy": -0.06220268788597276, "alpha_loss": -0.004038686496055414, "alpha_value": 0.19124639783476857, "duration": 23.70693016052246, "step": 50000}
