{"episode_reward": 0.0, "episode": 1.0, "duration": 7.235405206680298, "step": 500}
{"episode_reward": 4.0, "episode": 2.0, "duration": 1.2972073554992676, "step": 1000}
{"episode_reward": 0.0, "episode": 3.0, "critic_loss": 0.045369191116240534, "critic_target_Q_variance_m=2": 0.2655725388262614, "critic_Q1_variance_k=2": 0.00014995569861627123, "critic_Q2_variance_k=2": 0.00014803664106333988, "actor_loss": -0.959403649545174, "actor_mean_entropy": 2.548195002029379, "alpha_loss": 0.3128362440223022, "alpha_value": 0.09406045434756079, "duration": 434.79206562042236, "step": 1500}
{"episode_reward": 12.0, "episode": 4.0, "critic_loss": 0.0650676023773849, "critic_target_Q_variance_m=2": 0.6206333760023117, "critic_Q1_variance_k=2": 0.0004938107829511864, "critic_Q2_variance_k=2": 0.0004994736438093242, "actor_loss": -1.6809773378372193, "actor_mean_entropy": 2.6002738609313965, "alpha_loss": 0.2924244608879089, "alpha_value": 0.08743135843043809, "duration": 138.99798345565796, "step": 2000}
{"episode_reward": 0.0, "episode": 5.0, "critic_loss": 0.05493572226120159, "critic_target_Q_variance_m=2": 0.760811546087265, "critic_Q1_variance_k=2": 0.0004565210831424338, "critic_Q2_variance_k=2": 0.0004572288107010536, "actor_loss": -1.851960210800171, "actor_mean_entropy": 2.582108048439026, "alpha_loss": 0.28421583223342894, "alpha_value": 0.08539224975540974, "duration": 139.8675835132599, "step": 2500}
{"episode_reward": 3.0, "episode": 6.0, "critic_loss": 0.061076018740888686, "critic_target_Q_variance_m=2": 0.9121440254449844, "critic_Q1_variance_k=2": 0.00047617943411751187, "critic_Q2_variance_k=2": 0.0004722812063046149, "actor_loss": -2.013965751171112, "actor_mean_entropy": 2.5892863988876345, "alpha_loss": 0.2783085750341415, "alpha_value": 0.08341295149269519, "duration": 138.75497269630432, "step": 3000}
{"episode_reward": 4.0, "episode": 7.0, "critic_loss": 0.07025363697763533, "critic_target_Q_variance_m=2": 1.0985625106096268, "critic_Q1_variance_k=2": 0.000834112611511955, "critic_Q2_variance_k=2": 0.0008317233660054626, "actor_loss": -2.194736053466797, "actor_mean_entropy": 2.5963702993392945, "alpha_loss": 0.270834854722023, "alpha_value": 0.0814908182029721, "duration": 138.48277354240417, "step": 3500}
{"episode_reward": 6.0, "episode": 8.0, "critic_loss": 0.06323304532747716, "critic_target_Q_variance_m=2": 1.2411796355247497, "critic_Q1_variance_k=2": 0.0008722184786747676, "critic_Q2_variance_k=2": 0.000879007918498246, "actor_loss": -2.324203884124756, "actor_mean_entropy": 2.5986272525787353, "alpha_loss": 0.264554780960083, "alpha_value": 0.07962391689101596, "duration": 138.6392946243286, "step": 4000}
