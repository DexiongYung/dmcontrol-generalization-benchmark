{"episode_reward": 0.0, "episode": 1.0, "duration": 7.235405206680298, "step": 500}
{"episode_reward": 4.0, "episode": 2.0, "duration": 1.2972073554992676, "step": 1000}
{"episode_reward": 0.0, "episode": 3.0, "critic_loss": 0.045369191116240534, "critic_target_Q_variance_m=2": 0.2655725388262614, "critic_Q1_variance_k=2": 0.00014995569861627123, "critic_Q2_variance_k=2": 0.00014803664106333988, "actor_loss": -0.959403649545174, "actor_mean_entropy": 2.548195002029379, "alpha_loss": 0.3128362440223022, "alpha_value": 0.09406045434756079, "duration": 434.79206562042236, "step": 1500}
{"episode_reward": 12.0, "episode": 4.0, "critic_loss": 0.0650676023773849, "critic_target_Q_variance_m=2": 0.6206333760023117, "critic_Q1_variance_k=2": 0.0004938107829511864, "critic_Q2_variance_k=2": 0.0004994736438093242, "actor_loss": -1.6809773378372193, "actor_mean_entropy": 2.6002738609313965, "alpha_loss": 0.2924244608879089, "alpha_value": 0.08743135843043809, "duration": 138.99798345565796, "step": 2000}
{"episode_reward": 0.0, "episode": 5.0, "critic_loss": 0.05493572226120159, "critic_target_Q_variance_m=2": 0.760811546087265, "critic_Q1_variance_k=2": 0.0004565210831424338, "critic_Q2_variance_k=2": 0.0004572288107010536, "actor_loss": -1.851960210800171, "actor_mean_entropy": 2.582108048439026, "alpha_loss": 0.28421583223342894, "alpha_value": 0.08539224975540974, "duration": 139.8675835132599, "step": 2500}
{"episode_reward": 3.0, "episode": 6.0, "critic_loss": 0.061076018740888686, "critic_target_Q_variance_m=2": 0.9121440254449844, "critic_Q1_variance_k=2": 0.00047617943411751187, "critic_Q2_variance_k=2": 0.0004722812063046149, "actor_loss": -2.013965751171112, "actor_mean_entropy": 2.5892863988876345, "alpha_loss": 0.2783085750341415, "alpha_value": 0.08341295149269519, "duration": 138.75497269630432, "step": 3000}
{"episode_reward": 4.0, "episode": 7.0, "critic_loss": 0.07025363697763533, "critic_target_Q_variance_m=2": 1.0985625106096268, "critic_Q1_variance_k=2": 0.000834112611511955, "critic_Q2_variance_k=2": 0.0008317233660054626, "actor_loss": -2.194736053466797, "actor_mean_entropy": 2.5963702993392945, "alpha_loss": 0.270834854722023, "alpha_value": 0.0814908182029721, "duration": 138.48277354240417, "step": 3500}
{"episode_reward": 6.0, "episode": 8.0, "critic_loss": 0.06323304532747716, "critic_target_Q_variance_m=2": 1.2411796355247497, "critic_Q1_variance_k=2": 0.0008722184786747676, "critic_Q2_variance_k=2": 0.000879007918498246, "actor_loss": -2.324203884124756, "actor_mean_entropy": 2.5986272525787353, "alpha_loss": 0.264554780960083, "alpha_value": 0.07962391689101596, "duration": 138.6392946243286, "step": 4000}
{"episode_reward": 8.0, "episode": 9.0, "critic_loss": 0.08976765254233032, "critic_target_Q_variance_m=2": 1.4099176106452942, "critic_Q1_variance_k=2": 0.001231646106520202, "critic_Q2_variance_k=2": 0.0012472709802677855, "actor_loss": -2.4650112314224244, "actor_mean_entropy": 2.608501986503601, "alpha_loss": 0.25662590271234514, "alpha_value": 0.07781215072622447, "duration": 138.28814816474915, "step": 4500}
{"episode_reward": 1.0, "episode": 10.0, "critic_loss": 0.11560907246172428, "critic_target_Q_variance_m=2": 1.6627381353378297, "critic_Q1_variance_k=2": 0.0013248455955763348, "critic_Q2_variance_k=2": 0.0013271044318098576, "actor_loss": -2.662169620513916, "actor_mean_entropy": 2.582488356590271, "alpha_loss": 0.24925459456443785, "alpha_value": 0.07605985589551471, "duration": 138.49190068244934, "step": 5000}
{"episode_reward": 12.0, "episode": 11.0, "critic_loss": 0.1391781281121075, "critic_target_Q_variance_m=2": 1.9343922607898711, "critic_Q1_variance_k=2": 0.0013947193922649603, "critic_Q2_variance_k=2": 0.0014003513943171128, "actor_loss": -2.853723182678223, "actor_mean_entropy": 2.5919816932678224, "alpha_loss": 0.2435859370827675, "alpha_value": 0.07434179305350677, "duration": 138.9664602279663, "step": 5500}
{"episode_reward": 35.0, "episode": 12.0, "critic_loss": 0.18302022288367154, "critic_target_Q_variance_m=2": 2.18632527923584, "critic_Q1_variance_k=2": 0.0019183232090435923, "critic_Q2_variance_k=2": 0.0019118428942747415, "actor_loss": -3.0218237171173095, "actor_mean_entropy": 2.6320604333877564, "alpha_loss": 0.2334590877890587, "alpha_value": 0.07268714850932603, "duration": 139.0205900669098, "step": 6000}
{"episode_reward": 13.0, "episode": 13.0, "critic_loss": 0.19990739185363054, "critic_target_Q_variance_m=2": 2.5050479154586793, "critic_Q1_variance_k=2": 0.0025217334332410246, "critic_Q2_variance_k=2": 0.0024922677625436335, "actor_loss": -3.2235123023986816, "actor_mean_entropy": 2.625391827583313, "alpha_loss": 0.22373974496126176, "alpha_value": 0.07109233396061021, "duration": 137.88388657569885, "step": 6500}
{"episode_reward": 37.0, "episode": 14.0, "critic_loss": 0.23562182112038135, "critic_target_Q_variance_m=2": 2.8613014221191406, "critic_Q1_variance_k=2": 0.003061450026696548, "critic_Q2_variance_k=2": 0.003055842739995569, "actor_loss": -3.431831003189087, "actor_mean_entropy": 2.584544362068176, "alpha_loss": 0.20948360955715178, "alpha_value": 0.0695665568843579, "duration": 138.13636374473572, "step": 7000}
{"episode_reward": 62.0, "episode": 15.0, "critic_loss": 0.29961122094094755, "critic_target_Q_variance_m=2": 3.273531852245331, "critic_Q1_variance_k=2": 0.0041884107147343455, "critic_Q2_variance_k=2": 0.0041441578224767, "actor_loss": -3.6561054182052612, "actor_mean_entropy": 2.531515851020813, "alpha_loss": 0.19524753677845003, "alpha_value": 0.06813257375153595, "duration": 139.25900030136108, "step": 7500}
{"episode_reward": 70.0, "episode": 16.0, "critic_loss": 0.394843877017498, "critic_target_Q_variance_m=2": 3.7544126677513123, "critic_Q1_variance_k=2": 0.005259018928045407, "critic_Q2_variance_k=2": 0.005286531652556732, "actor_loss": -3.883349736213684, "actor_mean_entropy": 2.519752233505249, "alpha_loss": 0.18292588621377945, "alpha_value": 0.06675252898363884, "duration": 138.11143231391907, "step": 8000}
{"episode_reward": 110.0, "episode": 17.0, "critic_loss": 0.5467520662099123, "critic_target_Q_variance_m=2": 4.483380412578582, "critic_Q1_variance_k=2": 0.007550914253108203, "critic_Q2_variance_k=2": 0.007468694446142763, "actor_loss": -4.206239078521729, "actor_mean_entropy": 2.430014699935913, "alpha_loss": 0.15360309287905693, "alpha_value": 0.06548891898699752, "duration": 138.25666403770447, "step": 8500}
{"episode_reward": 125.0, "episode": 18.0, "critic_loss": 0.6747265403866768, "critic_target_Q_variance_m=2": 5.399826907157898, "critic_Q1_variance_k=2": 0.010010711689479649, "critic_Q2_variance_k=2": 0.00999629294173792, "actor_loss": -4.559758075714111, "actor_mean_entropy": 2.371041639328003, "alpha_loss": 0.12670670595765113, "alpha_value": 0.06440327652810714, "duration": 138.294429063797, "step": 9000}
{"episode_reward": 245.0, "episode": 19.0, "critic_loss": 0.8570890968441963, "critic_target_Q_variance_m=2": 7.040285784721375, "critic_Q1_variance_k=2": 0.014027863805182278, "critic_Q2_variance_k=2": 0.01403981789201498, "actor_loss": -5.197099088668823, "actor_mean_entropy": 2.2305192203521726, "alpha_loss": 0.07587925055623054, "alpha_value": 0.06355236254996839, "duration": 138.51906538009644, "step": 9500}
{"episode_reward": 383.0, "episode": 20.0, "critic_loss": 1.0687276208400727, "critic_target_Q_variance_m=2": 10.462562776565552, "critic_Q1_variance_k=2": 0.019154386781156062, "critic_Q2_variance_k=2": 0.019322986122220755, "actor_loss": -6.342353832244873, "actor_mean_entropy": 2.1175812673568726, "alpha_loss": 0.045762318663299086, "alpha_value": 0.06302954805648663, "duration": 137.92105102539062, "step": 10000}
{"episode_reward": 367.0, "episode": 21.0, "critic_loss": 1.1099563010931015, "critic_target_Q_variance_m=2": 15.448884496688843, "critic_Q1_variance_k=2": 0.02024551260471344, "critic_Q2_variance_k=2": 0.020448105132207274, "actor_loss": -7.715148944854736, "actor_mean_entropy": 2.0057008876800535, "alpha_loss": 0.03508601648081094, "alpha_value": 0.06263840476065065, "duration": 144.50306749343872, "step": 10500}
{"episode_reward": 354.0, "episode": 22.0, "critic_loss": 1.1599916142225266, "critic_target_Q_variance_m=2": 20.8548200302124, "critic_Q1_variance_k=2": 0.01972134172730148, "critic_Q2_variance_k=2": 0.019967063205316663, "actor_loss": -8.963821449279784, "actor_mean_entropy": 1.909611680984497, "alpha_loss": 0.039509798186831174, "alpha_value": 0.062217038563779435, "duration": 138.30748987197876, "step": 11000}
{"episode_reward": 400.0, "episode": 23.0, "critic_loss": 1.2082052367925644, "critic_target_Q_variance_m=2": 27.10401626586914, "critic_Q1_variance_k=2": 0.020897884679958224, "critic_Q2_variance_k=2": 0.021096853267401457, "actor_loss": -10.169655750274659, "actor_mean_entropy": 1.8232953572273254, "alpha_loss": 0.0302082803864032, "alpha_value": 0.06175688925443018, "duration": 138.14544367790222, "step": 11500}
{"episode_reward": 439.0, "episode": 24.0, "critic_loss": 1.3401034976243973, "critic_target_Q_variance_m=2": 34.78306453323364, "critic_Q1_variance_k=2": 0.023719104684889317, "critic_Q2_variance_k=2": 0.023902847500517965, "actor_loss": -11.55934253692627, "actor_mean_entropy": 1.754841206073761, "alpha_loss": 0.00959674814902246, "alpha_value": 0.06148768996130351, "duration": 138.63806748390198, "step": 12000}
{"episode_reward": 462.0, "episode": 25.0, "critic_loss": 1.448813094496727, "critic_target_Q_variance_m=2": 44.506696990966795, "critic_Q1_variance_k=2": 0.02686060209199786, "critic_Q2_variance_k=2": 0.02678415647521615, "actor_loss": -13.111886280059814, "actor_mean_entropy": 1.6850671286582948, "alpha_loss": -0.0028222856195643546, "alpha_value": 0.061440866437489555, "duration": 138.22226095199585, "step": 12500}
{"episode_reward": 490.0, "episode": 26.0, "critic_loss": 1.3744970395565033, "critic_target_Q_variance_m=2": 56.9727631149292, "critic_Q1_variance_k=2": 0.025696396982297302, "critic_Q2_variance_k=2": 0.025761997343972325, "actor_loss": -14.937042278289795, "actor_mean_entropy": 1.6492187824249267, "alpha_loss": -0.009714851092081518, "alpha_value": 0.06157508059883568, "duration": 137.76798725128174, "step": 13000}
{"episode_reward": 477.0, "episode": 27.0, "critic_loss": 1.2921164492368697, "critic_target_Q_variance_m=2": 71.03533540344239, "critic_Q1_variance_k=2": 0.024148986987769603, "critic_Q2_variance_k=2": 0.02411491634696722, "actor_loss": -16.74055513381958, "actor_mean_entropy": 1.5901513795852662, "alpha_loss": -0.008235573600511997, "alpha_value": 0.06175311832925396, "duration": 138.63554787635803, "step": 13500}
{"episode_reward": 479.0, "episode": 28.0, "critic_loss": 1.3124928625822068, "critic_target_Q_variance_m=2": 86.50822479248046, "critic_Q1_variance_k=2": 0.0242281474173069, "critic_Q2_variance_k=2": 0.024140729755163192, "actor_loss": -18.492374504089355, "actor_mean_entropy": 1.576892165660858, "alpha_loss": -0.008860658558551221, "alpha_value": 0.06195093530167499, "duration": 138.60782289505005, "step": 14000}
{"episode_reward": 508.0, "episode": 29.0, "critic_loss": 1.2660700311660766, "critic_target_Q_variance_m=2": 103.21857948303223, "critic_Q1_variance_k=2": 0.02371720494143665, "critic_Q2_variance_k=2": 0.02369942379370332, "actor_loss": -20.199339820861816, "actor_mean_entropy": 1.565065330505371, "alpha_loss": -0.00918500784318894, "alpha_value": 0.062168438574735134, "duration": 138.0078842639923, "step": 14500}
{"episode_reward": 495.0, "episode": 30.0, "critic_loss": 1.3258212081193923, "critic_target_Q_variance_m=2": 120.6363303527832, "critic_Q1_variance_k=2": 0.024243434077128766, "critic_Q2_variance_k=2": 0.024366544272750618, "actor_loss": -21.839192344665527, "actor_mean_entropy": 1.5699476852416991, "alpha_loss": -0.010822674514725805, "alpha_value": 0.06246867277670391, "duration": 138.82942914962769, "step": 15000}
{"episode_reward": 495.0, "episode": 31.0, "critic_loss": 1.2744159165620803, "critic_target_Q_variance_m=2": 139.366236328125, "critic_Q1_variance_k=2": 0.024505920017138125, "critic_Q2_variance_k=2": 0.024558837780728936, "actor_loss": -23.516929313659666, "actor_mean_entropy": 1.5500984849929809, "alpha_loss": -0.01269663687190041, "alpha_value": 0.06286937555695, "duration": 138.1273283958435, "step": 15500}
{"episode_reward": 475.0, "episode": 32.0, "critic_loss": 1.341322042107582, "critic_target_Q_variance_m=2": 159.9017907409668, "critic_Q1_variance_k=2": 0.024878555281087757, "critic_Q2_variance_k=2": 0.024995267890393733, "actor_loss": -25.181948638916015, "actor_mean_entropy": 1.5427590594291687, "alpha_loss": -0.014166131625883281, "alpha_value": 0.06335428100820088, "duration": 138.15333557128906, "step": 16000}
{"episode_reward": 517.0, "episode": 33.0, "critic_loss": 1.274040096640587, "critic_target_Q_variance_m=2": 180.52241107177736, "critic_Q1_variance_k=2": 0.023842893281951546, "critic_Q2_variance_k=2": 0.02389248883165419, "actor_loss": -26.767404235839845, "actor_mean_entropy": 1.518254340648651, "alpha_loss": -0.011012978163547814, "alpha_value": 0.06385915101156021, "duration": 136.85582375526428, "step": 16500}
{"episode_reward": 533.0, "episode": 34.0, "critic_loss": 1.270937734603882, "critic_target_Q_variance_m=2": 203.10921902465822, "critic_Q1_variance_k=2": 0.02467168753221631, "critic_Q2_variance_k=2": 0.02466048294492066, "actor_loss": -28.406236122131347, "actor_mean_entropy": 1.500572934627533, "alpha_loss": -0.012998296085279436, "alpha_value": 0.06439427665465826, "duration": 138.16250562667847, "step": 17000}
{"episode_reward": 517.0, "episode": 35.0, "critic_loss": 1.2355201654434205, "critic_target_Q_variance_m=2": 225.97179083251953, "critic_Q1_variance_k=2": 0.023726205537095667, "critic_Q2_variance_k=2": 0.023760036578401922, "actor_loss": -29.977462684631348, "actor_mean_entropy": 1.5172569603919983, "alpha_loss": -0.015615475877188147, "alpha_value": 0.06511043469472722, "duration": 138.3747842311859, "step": 17500}
{"episode_reward": 546.0, "episode": 36.0, "critic_loss": 1.1639109674692154, "critic_target_Q_variance_m=2": 250.1960887145996, "critic_Q1_variance_k=2": 0.02300003713183105, "critic_Q2_variance_k=2": 0.022950669851154088, "actor_loss": -31.52956019592285, "actor_mean_entropy": 1.486663432598114, "alpha_loss": -0.013373957782983779, "alpha_value": 0.06590389073278027, "duration": 138.14602971076965, "step": 18000}
{"episode_reward": 516.0, "episode": 37.0, "critic_loss": 1.1790677970647812, "critic_target_Q_variance_m=2": 274.5237680358887, "critic_Q1_variance_k=2": 0.0230471468064934, "critic_Q2_variance_k=2": 0.023054043559357525, "actor_loss": -33.098266876220706, "actor_mean_entropy": 1.4716796712875366, "alpha_loss": -0.012670697247143835, "alpha_value": 0.0666445208036566, "duration": 138.55039429664612, "step": 18500}
{"episode_reward": 536.0, "episode": 38.0, "critic_loss": 1.150010719537735, "critic_target_Q_variance_m=2": 299.82758782958985, "critic_Q1_variance_k=2": 0.022561280701309444, "critic_Q2_variance_k=2": 0.0224742283038795, "actor_loss": -34.561061538696286, "actor_mean_entropy": 1.4852363901138306, "alpha_loss": -0.013515728028025479, "alpha_value": 0.06751095558782909, "duration": 137.75366187095642, "step": 19000}
{"episode_reward": 525.0, "episode": 39.0, "critic_loss": 1.1505546803474427, "critic_target_Q_variance_m=2": 326.10303186035156, "critic_Q1_variance_k=2": 0.022085537841543556, "critic_Q2_variance_k=2": 0.022156848687678577, "actor_loss": -36.10209944152832, "actor_mean_entropy": 1.465197253227234, "alpha_loss": -0.013679368001408876, "alpha_value": 0.06846371974864024, "duration": 138.23687171936035, "step": 19500}
{"episode_reward": 530.0, "episode": 40.0, "critic_loss": 1.162240075826645, "critic_target_Q_variance_m=2": 353.33578240966796, "critic_Q1_variance_k=2": 0.021530602667480706, "critic_Q2_variance_k=2": 0.021443579636514186, "actor_loss": -37.56086027526855, "actor_mean_entropy": 1.4402820963859557, "alpha_loss": -0.012077257005497813, "alpha_value": 0.06940904532907671, "duration": 138.0264368057251, "step": 20000}
{"episode_reward": 533.0, "episode": 41.0, "critic_loss": 1.098724915623665, "critic_target_Q_variance_m=2": 380.04019787597656, "critic_Q1_variance_k=2": 0.020433473248034715, "critic_Q2_variance_k=2": 0.020501225691288708, "actor_loss": -38.96768760681152, "actor_mean_entropy": 1.51076260471344, "alpha_loss": -0.007018435866106301, "alpha_value": 0.07011398250467743, "duration": 144.37500596046448, "step": 20500}
{"episode_reward": 500.0, "episode": 42.0, "critic_loss": 1.1130472481250764, "critic_target_Q_variance_m=2": 406.62100799560545, "critic_Q1_variance_k=2": 0.02121694911643863, "critic_Q2_variance_k=2": 0.021158990683034062, "actor_loss": -40.26723017883301, "actor_mean_entropy": 1.4736426949501038, "alpha_loss": -0.010329894501715899, "alpha_value": 0.07079420826593831, "duration": 138.11875414848328, "step": 21000}
{"episode_reward": 549.0, "episode": 43.0, "critic_loss": 1.1632139834165574, "critic_target_Q_variance_m=2": 433.4468713378906, "critic_Q1_variance_k=2": 0.02086228735372424, "critic_Q2_variance_k=2": 0.020880496952682733, "actor_loss": -41.54325131225586, "actor_mean_entropy": 1.4673196291923523, "alpha_loss": -0.007982135135680437, "alpha_value": 0.07164692301796058, "duration": 138.35732197761536, "step": 21500}
{"episode_reward": 546.0, "episode": 44.0, "critic_loss": 1.0346382938623429, "critic_target_Q_variance_m=2": 462.83947442626953, "critic_Q1_variance_k=2": 0.019361440343782305, "critic_Q2_variance_k=2": 0.019555399646982552, "actor_loss": -42.98544578552246, "actor_mean_entropy": 1.459420464992523, "alpha_loss": -0.0057037829817272725, "alpha_value": 0.07225028816790754, "duration": 138.01059937477112, "step": 22000}
{"episode_reward": 546.0, "episode": 45.0, "critic_loss": 1.0137057551145554, "critic_target_Q_variance_m=2": 490.40728363037107, "critic_Q1_variance_k=2": 0.018631750734522938, "critic_Q2_variance_k=2": 0.018838483098894358, "actor_loss": -44.251820220947266, "actor_mean_entropy": 1.450865967273712, "alpha_loss": -0.004112539263442159, "alpha_value": 0.07270793096334385, "duration": 138.39457988739014, "step": 22500}
{"episode_reward": 547.0, "episode": 46.0, "critic_loss": 1.0420598863363266, "critic_target_Q_variance_m=2": 518.6352526245117, "critic_Q1_variance_k=2": 0.019102374821901323, "critic_Q2_variance_k=2": 0.019307757312431933, "actor_loss": -45.48407438659668, "actor_mean_entropy": 1.4430352387428285, "alpha_loss": -0.005533113912679255, "alpha_value": 0.07324760785027765, "duration": 138.7760636806488, "step": 23000}
{"episode_reward": 549.0, "episode": 47.0, "critic_loss": 1.0590698775053025, "critic_target_Q_variance_m=2": 546.8755767822265, "critic_Q1_variance_k=2": 0.01955544830672443, "critic_Q2_variance_k=2": 0.019848162697628142, "actor_loss": -46.7429638671875, "actor_mean_entropy": 1.426426965713501, "alpha_loss": -0.002891436834586784, "alpha_value": 0.07369172232662018, "duration": 138.12451076507568, "step": 23500}
{"episode_reward": 558.0, "episode": 48.0, "critic_loss": 1.1063973468542099, "critic_target_Q_variance_m=2": 575.6930051269532, "critic_Q1_variance_k=2": 0.01945276309363544, "critic_Q2_variance_k=2": 0.019636107420548797, "actor_loss": -47.9422417755127, "actor_mean_entropy": 1.4548050565719604, "alpha_loss": -0.0021663201353512703, "alpha_value": 0.07386459437404051, "duration": 138.39667296409607, "step": 24000}
{"episode_reward": 556.0, "episode": 49.0, "critic_loss": 1.0976411925554275, "critic_target_Q_variance_m=2": 604.5170205078125, "critic_Q1_variance_k=2": 0.01924559844098985, "critic_Q2_variance_k=2": 0.01925345507264137, "actor_loss": -49.12740176391601, "actor_mean_entropy": 1.4113873658180236, "alpha_loss": -0.00480264694429934, "alpha_value": 0.0743392021597278, "duration": 138.08188247680664, "step": 24500}
{"episode_reward": 548.0, "episode": 50.0, "critic_loss": 1.0605137867927552, "critic_target_Q_variance_m=2": 634.284277709961, "critic_Q1_variance_k=2": 0.01941412245668471, "critic_Q2_variance_k=2": 0.0194326893389225, "actor_loss": -50.31470832824707, "actor_mean_entropy": 1.4245406484603882, "alpha_loss": -0.0016351555432192982, "alpha_value": 0.0747322610066672, "duration": 137.9806673526764, "step": 25000}
{"episode_reward": 541.0, "episode": 51.0, "critic_loss": 1.0539351915121078, "critic_target_Q_variance_m=2": 662.2731378173828, "critic_Q1_variance_k=2": 0.018427007518708707, "critic_Q2_variance_k=2": 0.018602247148752214, "actor_loss": -51.39885618591308, "actor_mean_entropy": 1.4417703437805176, "alpha_loss": -0.004269019613973796, "alpha_value": 0.07503126685229411, "duration": 138.79737949371338, "step": 25500}
{"episode_reward": 565.0, "episode": 52.0, "critic_loss": 1.0518690195083618, "critic_target_Q_variance_m=2": 691.2148076171875, "critic_Q1_variance_k=2": 0.018702752316370606, "critic_Q2_variance_k=2": 0.018661282312124966, "actor_loss": -52.55177217102051, "actor_mean_entropy": 1.4450194201469422, "alpha_loss": 0.0011489220533985644, "alpha_value": 0.07525882354153114, "duration": 137.89807438850403, "step": 26000}
{"episode_reward": 539.0, "episode": 53.0, "critic_loss": 1.0175039229393006, "critic_target_Q_variance_m=2": 719.2906970214843, "critic_Q1_variance_k=2": 0.018642946500331162, "critic_Q2_variance_k=2": 0.018711266500875352, "actor_loss": -53.634208786010745, "actor_mean_entropy": 1.3793729948997497, "alpha_loss": -7.662667287513614e-05, "alpha_value": 0.0751481099918306, "duration": 137.12829160690308, "step": 26500}
{"episode_reward": 549.0, "episode": 54.0, "critic_loss": 1.0539602048397063, "critic_target_Q_variance_m=2": 748.7771068115235, "critic_Q1_variance_k=2": 0.018961456760764123, "critic_Q2_variance_k=2": 0.01913068930618465, "actor_loss": -54.683389816284176, "actor_mean_entropy": 1.3709842567443848, "alpha_loss": -0.0009585717064328491, "alpha_value": 0.07526699093326597, "duration": 139.0347819328308, "step": 27000}
{"episode_reward": 554.0, "episode": 55.0, "critic_loss": 1.0592749975919724, "critic_target_Q_variance_m=2": 779.0848488769532, "critic_Q1_variance_k=2": 0.018414992386475204, "critic_Q2_variance_k=2": 0.018487179946154356, "actor_loss": -55.78380308532715, "actor_mean_entropy": 1.3860473523139953, "alpha_loss": -0.001342178045772016, "alpha_value": 0.07544613039966887, "duration": 138.65779948234558, "step": 27500}
{"episode_reward": 564.0, "episode": 56.0, "critic_loss": 1.0396044704914094, "critic_target_Q_variance_m=2": 808.5232874755859, "critic_Q1_variance_k=2": 0.01825691849924624, "critic_Q2_variance_k=2": 0.01837982122041285, "actor_loss": -56.839449905395504, "actor_mean_entropy": 1.3901307339668274, "alpha_loss": -0.00032549035781994463, "alpha_value": 0.07549661996460148, "duration": 138.17571139335632, "step": 28000}
{"episode_reward": 572.0, "episode": 57.0, "critic_loss": 1.0817102273702621, "critic_target_Q_variance_m=2": 838.7742884521484, "critic_Q1_variance_k=2": 0.019003793051466347, "critic_Q2_variance_k=2": 0.01895834443718195, "actor_loss": -57.920893630981446, "actor_mean_entropy": 1.3933810787200929, "alpha_loss": -0.001016343603376299, "alpha_value": 0.07555137292085744, "duration": 138.4300560951233, "step": 28500}
{"episode_reward": 564.0, "episode": 58.0, "critic_loss": 1.1330246353149414, "critic_target_Q_variance_m=2": 867.99458203125, "critic_Q1_variance_k=2": 0.018381101759150625, "critic_Q2_variance_k=2": 0.01858190960995853, "actor_loss": -58.90078425598144, "actor_mean_entropy": 1.3781655316352843, "alpha_loss": 0.000309085754211992, "alpha_value": 0.07559818380437854, "duration": 138.57156252861023, "step": 29000}
{"episode_reward": 535.0, "episode": 59.0, "critic_loss": 1.1008701452016831, "critic_target_Q_variance_m=2": 896.3959816894532, "critic_Q1_variance_k=2": 0.018961769757792353, "critic_Q2_variance_k=2": 0.01903123881481588, "actor_loss": -59.846226119995116, "actor_mean_entropy": 1.3603034539222718, "alpha_loss": -0.0013196781477890908, "alpha_value": 0.0756528107299011, "duration": 138.39352917671204, "step": 29500}
{"episode_reward": 566.0, "episode": 60.0, "critic_loss": 1.0590350192785263, "critic_target_Q_variance_m=2": 928.0756173095704, "critic_Q1_variance_k=2": 0.017847845422104002, "critic_Q2_variance_k=2": 0.01776424252986908, "actor_loss": -60.89760331726074, "actor_mean_entropy": 1.3706315355300904, "alpha_loss": 0.000532224040478468, "alpha_value": 0.07575857348630112, "duration": 137.50083923339844, "step": 30000}
{"episode_reward": 575.0, "episode": 61.0, "critic_loss": 1.006777538895607, "critic_target_Q_variance_m=2": 955.816359375, "critic_Q1_variance_k=2": 0.01782766504585743, "critic_Q2_variance_k=2": 0.017746176758781075, "actor_loss": -61.82134803771973, "actor_mean_entropy": 1.363844084739685, "alpha_loss": 0.003616627390496433, "alpha_value": 0.07547277497354257, "duration": 144.34763884544373, "step": 30500}
{"episode_reward": 567.0, "episode": 62.0, "critic_loss": 1.1043285759687425, "critic_target_Q_variance_m=2": 983.2902243652344, "critic_Q1_variance_k=2": 0.01832381883636117, "critic_Q2_variance_k=2": 0.01849913764744997, "actor_loss": -62.721667663574216, "actor_mean_entropy": 1.3506115698814392, "alpha_loss": 0.0030291567463427782, "alpha_value": 0.07494814943527991, "duration": 138.22629928588867, "step": 31000}
{"episode_reward": 544.0, "episode": 63.0, "critic_loss": 1.0874894704818725, "critic_target_Q_variance_m=2": 1012.0769923095703, "critic_Q1_variance_k=2": 0.018140021541155876, "critic_Q2_variance_k=2": 0.018332812855020166, "actor_loss": -63.58154005432129, "actor_mean_entropy": 1.3623693933486938, "alpha_loss": 0.0023949284735135736, "alpha_value": 0.07470922446795594, "duration": 138.62693405151367, "step": 31500}
{"episode_reward": 561.0, "episode": 64.0, "critic_loss": 1.0736756098270417, "critic_target_Q_variance_m=2": 1039.2350083007811, "critic_Q1_variance_k=2": 0.018109173050150276, "critic_Q2_variance_k=2": 0.018242805246263743, "actor_loss": -64.44972021484375, "actor_mean_entropy": 1.334243528366089, "alpha_loss": 0.002161061156075448, "alpha_value": 0.0743253639166383, "duration": 138.10639691352844, "step": 32000}
{"episode_reward": 589.0, "episode": 65.0, "critic_loss": 1.1383752150535584, "critic_target_Q_variance_m=2": 1068.9094591064454, "critic_Q1_variance_k=2": 0.019390603709965943, "critic_Q2_variance_k=2": 0.01941453517600894, "actor_loss": -65.37449981689453, "actor_mean_entropy": 1.344348355770111, "alpha_loss": -0.0008549784659408032, "alpha_value": 0.07432981263480931, "duration": 138.90070724487305, "step": 32500}
{"episode_reward": 572.0, "episode": 66.0, "critic_loss": 1.134124516248703, "critic_target_Q_variance_m=2": 1095.5465627441406, "critic_Q1_variance_k=2": 0.019031345983967184, "critic_Q2_variance_k=2": 0.0191031509693712, "actor_loss": -66.1380791015625, "actor_mean_entropy": 1.3401136198043824, "alpha_loss": 0.0016968229038175195, "alpha_value": 0.07421307245957473, "duration": 138.0001618862152, "step": 33000}
{"episode_reward": 575.0, "episode": 67.0, "critic_loss": 1.175872161269188, "critic_target_Q_variance_m=2": 1124.44308203125, "critic_Q1_variance_k=2": 0.019529929460957645, "critic_Q2_variance_k=2": 0.019682186843827366, "actor_loss": -67.0653623046875, "actor_mean_entropy": 1.3233166694641114, "alpha_loss": -0.000583991982974112, "alpha_value": 0.0742356616924664, "duration": 138.53691148757935, "step": 33500}
{"episode_reward": 578.0, "episode": 68.0, "critic_loss": 1.1607343487143515, "critic_target_Q_variance_m=2": 1153.11458203125, "critic_Q1_variance_k=2": 0.01943996739014983, "critic_Q2_variance_k=2": 0.01951976411603391, "actor_loss": -67.88941909790039, "actor_mean_entropy": 1.3299143767356874, "alpha_loss": -0.001793204784858972, "alpha_value": 0.07436446808636071, "duration": 138.2888524532318, "step": 34000}
{"episode_reward": 583.0, "episode": 69.0, "critic_loss": 1.2470380046367646, "critic_target_Q_variance_m=2": 1179.868232421875, "critic_Q1_variance_k=2": 0.02003041191957891, "critic_Q2_variance_k=2": 0.0201838439386338, "actor_loss": -68.67101031494141, "actor_mean_entropy": 1.3416905841827393, "alpha_loss": -0.0037783802836202085, "alpha_value": 0.07474830739484742, "duration": 138.00950145721436, "step": 34500}
{"episode_reward": 599.0, "episode": 70.0, "critic_loss": 1.1840993389487267, "critic_target_Q_variance_m=2": 1208.588928466797, "critic_Q1_variance_k=2": 0.0195264796204865, "critic_Q2_variance_k=2": 0.019656668482348323, "actor_loss": -69.53402270507813, "actor_mean_entropy": 1.3579662199020386, "alpha_loss": -0.0007552991639822722, "alpha_value": 0.07495987346704443, "duration": 138.12455892562866, "step": 35000}
{"episode_reward": 580.0, "episode": 71.0, "critic_loss": 1.1845259132385253, "critic_target_Q_variance_m=2": 1236.7077797851562, "critic_Q1_variance_k=2": 0.0200066668279469, "critic_Q2_variance_k=2": 0.020225810997188093, "actor_loss": -70.31948977661133, "actor_mean_entropy": 1.3018953452110291, "alpha_loss": -0.0022674845354631545, "alpha_value": 0.07523814322594821, "duration": 138.13654565811157, "step": 35500}
{"episode_reward": 626.0, "episode": 72.0, "critic_loss": 1.2361955169439316, "critic_target_Q_variance_m=2": 1265.287994873047, "critic_Q1_variance_k=2": 0.01990514175966382, "critic_Q2_variance_k=2": 0.020124186949804425, "actor_loss": -71.08408810424805, "actor_mean_entropy": 1.3391915469169617, "alpha_loss": 0.0018578128297813236, "alpha_value": 0.07523117632921501, "duration": 138.55215716362, "step": 36000}
{"episode_reward": 590.0, "episode": 73.0, "critic_loss": 1.265921961069107, "critic_target_Q_variance_m=2": 1293.1376665039063, "critic_Q1_variance_k=2": 0.020943497026339172, "critic_Q2_variance_k=2": 0.021096406249329448, "actor_loss": -71.93164788818359, "actor_mean_entropy": 1.282397416114807, "alpha_loss": -0.0015659208954311907, "alpha_value": 0.07512366426944288, "duration": 137.29444289207458, "step": 36500}
{"episode_reward": 616.0, "episode": 74.0, "critic_loss": 1.2789935655593871, "critic_target_Q_variance_m=2": 1319.9208532714845, "critic_Q1_variance_k=2": 0.021828556822612883, "critic_Q2_variance_k=2": 0.022204394415020944, "actor_loss": -72.66387881469727, "actor_mean_entropy": 1.3007720575332642, "alpha_loss": -0.005078172986395657, "alpha_value": 0.07557369483236168, "duration": 138.3278889656067, "step": 37000}
{"episode_reward": 622.0, "episode": 75.0, "critic_loss": 1.4025467318296432, "critic_target_Q_variance_m=2": 1345.5841813964844, "critic_Q1_variance_k=2": 0.02238690958917141, "critic_Q2_variance_k=2": 0.022693891625851392, "actor_loss": -73.39345443725585, "actor_mean_entropy": 1.2841307821273804, "alpha_loss": -0.004963522121310234, "alpha_value": 0.076192677905809, "duration": 139.00326943397522, "step": 37500}
{"episode_reward": 616.0, "episode": 76.0, "critic_loss": 1.403866970539093, "critic_target_Q_variance_m=2": 1375.7236652832032, "critic_Q1_variance_k=2": 0.021934073073789476, "critic_Q2_variance_k=2": 0.022075804896652697, "actor_loss": -74.20765237426758, "actor_mean_entropy": 1.2607632899284362, "alpha_loss": -0.0062483424576930706, "alpha_value": 0.07692982979786266, "duration": 139.3063907623291, "step": 38000}
{"episode_reward": 623.0, "episode": 77.0, "critic_loss": 1.385768035888672, "critic_target_Q_variance_m=2": 1402.9387407226563, "critic_Q1_variance_k=2": 0.022532056299969554, "critic_Q2_variance_k=2": 0.022913722902536394, "actor_loss": -74.90750506591797, "actor_mean_entropy": 1.2727642302513122, "alpha_loss": -0.00508321392768994, "alpha_value": 0.07764138698529283, "duration": 138.26430249214172, "step": 38500}
{"episode_reward": 681.0, "episode": 78.0, "critic_loss": 1.4647719982862473, "critic_target_Q_variance_m=2": 1430.8897783203124, "critic_Q1_variance_k=2": 0.024206600224599244, "critic_Q2_variance_k=2": 0.024477538641542198, "actor_loss": -75.6734662475586, "actor_mean_entropy": 1.240446261882782, "alpha_loss": -0.008792131661903114, "alpha_value": 0.07851508322962271, "duration": 138.88888716697693, "step": 39000}
{"episode_reward": 633.0, "episode": 79.0, "critic_loss": 1.4880435931682587, "critic_target_Q_variance_m=2": 1460.323955810547, "critic_Q1_variance_k=2": 0.024184405773878096, "critic_Q2_variance_k=2": 0.02446292237378657, "actor_loss": -76.42631625366211, "actor_mean_entropy": 1.2735445013046265, "alpha_loss": -0.008024455879814922, "alpha_value": 0.07948328205494393, "duration": 138.48577570915222, "step": 39500}
{"episode_reward": 634.0, "episode": 80.0, "critic_loss": 1.5658772521018982, "critic_target_Q_variance_m=2": 1490.9328559570313, "critic_Q1_variance_k=2": 0.024911375982686876, "critic_Q2_variance_k=2": 0.02531739868223667, "actor_loss": -77.26032479858398, "actor_mean_entropy": 1.2415470542907714, "alpha_loss": -0.008969887360464782, "alpha_value": 0.08040065595314455, "duration": 137.68109345436096, "step": 40000}
{"episode_reward": 648.0, "episode": 81.0, "critic_loss": 1.6786185991764069, "critic_target_Q_variance_m=2": 1519.9182114257812, "critic_Q1_variance_k=2": 0.026858911702409387, "critic_Q2_variance_k=2": 0.02722837433218956, "actor_loss": -77.9388874206543, "actor_mean_entropy": 1.2609812760353087, "alpha_loss": -0.007927350724115968, "alpha_value": 0.08140866004369561, "duration": 144.31654143333435, "step": 40500}
{"episode_reward": 668.0, "episode": 82.0, "critic_loss": 1.8422343121767044, "critic_target_Q_variance_m=2": 1549.197560546875, "critic_Q1_variance_k=2": 0.028309592155739666, "critic_Q2_variance_k=2": 0.028597599605098365, "actor_loss": -78.72259790039062, "actor_mean_entropy": 1.2327971954345702, "alpha_loss": -0.00742659751791507, "alpha_value": 0.08234158148431599, "duration": 138.52411890029907, "step": 41000}
{"episode_reward": 675.0, "episode": 83.0, "critic_loss": 1.8170106949806213, "critic_target_Q_variance_m=2": 1580.3091032714844, "critic_Q1_variance_k=2": 0.028153805132955314, "critic_Q2_variance_k=2": 0.028525337275117635, "actor_loss": -79.5009786682129, "actor_mean_entropy": 1.228968113899231, "alpha_loss": -0.008118787652812898, "alpha_value": 0.08328989700537213, "duration": 138.69047451019287, "step": 41500}
{"episode_reward": 677.0, "episode": 84.0, "critic_loss": 1.9056488301753998, "critic_target_Q_variance_m=2": 1608.9617756347657, "critic_Q1_variance_k=2": 0.02934340388327837, "critic_Q2_variance_k=2": 0.02977325500547886, "actor_loss": -80.22121423339844, "actor_mean_entropy": 1.2180186738967895, "alpha_loss": -0.013367708955891431, "alpha_value": 0.08452022260835078, "duration": 138.10622644424438, "step": 42000}
{"episode_reward": 670.0, "episode": 85.0, "critic_loss": 2.0035660746097563, "critic_target_Q_variance_m=2": 1644.9790927734375, "critic_Q1_variance_k=2": 0.02968419086933136, "critic_Q2_variance_k=2": 0.030019633017480372, "actor_loss": -81.1056923828125, "actor_mean_entropy": 1.2147904453277587, "alpha_loss": -0.009158430508803576, "alpha_value": 0.08582286338699727, "duration": 138.51588559150696, "step": 42500}
{"episode_reward": 661.0, "episode": 86.0, "critic_loss": 1.998863365650177, "critic_target_Q_variance_m=2": 1676.8854143066405, "critic_Q1_variance_k=2": 0.029049590094015, "critic_Q2_variance_k=2": 0.029447987182065843, "actor_loss": -81.90880599975586, "actor_mean_entropy": 1.212613424539566, "alpha_loss": -0.010139215745963156, "alpha_value": 0.08695839060762227, "duration": 138.91851687431335, "step": 43000}
{"episode_reward": 705.0, "episode": 87.0, "critic_loss": 2.015327912569046, "critic_target_Q_variance_m=2": 1705.2835231933593, "critic_Q1_variance_k=2": 0.029556150667369364, "critic_Q2_variance_k=2": 0.02995186371356249, "actor_loss": -82.59599685668945, "actor_mean_entropy": 1.2299813556671142, "alpha_loss": -0.009191914380062371, "alpha_value": 0.08802791437742306, "duration": 138.68630719184875, "step": 43500}
{"episode_reward": 681.0, "episode": 88.0, "critic_loss": 2.0671923773288725, "critic_target_Q_variance_m=2": 1737.2101643066405, "critic_Q1_variance_k=2": 0.03188776356726885, "critic_Q2_variance_k=2": 0.032393990751355885, "actor_loss": -83.40398220825195, "actor_mean_entropy": 1.2000067477226257, "alpha_loss": -0.006541160131804645, "alpha_value": 0.0889472481108799, "duration": 139.24828839302063, "step": 44000}
{"episode_reward": 744.0, "episode": 89.0, "critic_loss": 2.1885838947296143, "critic_target_Q_variance_m=2": 1772.7596486816406, "critic_Q1_variance_k=2": 0.03310211993381381, "critic_Q2_variance_k=2": 0.033613277435302735, "actor_loss": -84.21074130249023, "actor_mean_entropy": 1.170556867837906, "alpha_loss": -0.010064768427982927, "alpha_value": 0.08988431788729292, "duration": 138.37118339538574, "step": 44500}
{"episode_reward": 719.0, "episode": 90.0, "critic_loss": 2.2316116809844972, "critic_target_Q_variance_m=2": 1805.8172329101562, "critic_Q1_variance_k=2": 0.0324708308391273, "critic_Q2_variance_k=2": 0.033331130251288414, "actor_loss": -85.02090209960937, "actor_mean_entropy": 1.1563786561489104, "alpha_loss": -0.008118774593807757, "alpha_value": 0.0908757031637171, "duration": 138.40834951400757, "step": 45000}
{"episode_reward": 674.0, "episode": 91.0, "critic_loss": 2.1256102249622346, "critic_target_Q_variance_m=2": 1841.1105432128907, "critic_Q1_variance_k=2": 0.03359419741109013, "critic_Q2_variance_k=2": 0.0340467151850462, "actor_loss": -85.84243020629883, "actor_mean_entropy": 1.1684000840187072, "alpha_loss": -0.011507182259112597, "alpha_value": 0.09202475110556511, "duration": 138.4960162639618, "step": 45500}
{"episode_reward": 703.0, "episode": 92.0, "critic_loss": 2.3692278757095337, "critic_target_Q_variance_m=2": 1874.9868120117187, "critic_Q1_variance_k=2": 0.034490233223885294, "critic_Q2_variance_k=2": 0.0349935502782464, "actor_loss": -86.62984048461914, "actor_mean_entropy": 1.177897463798523, "alpha_loss": -0.01150376256275922, "alpha_value": 0.09336640024312676, "duration": 138.5666308403015, "step": 46000}
{"episode_reward": 709.0, "episode": 93.0, "critic_loss": 2.35034873175621, "critic_target_Q_variance_m=2": 1911.916819580078, "critic_Q1_variance_k=2": 0.03491428028792143, "critic_Q2_variance_k=2": 0.03540345778688789, "actor_loss": -87.46409744262695, "actor_mean_entropy": 1.1778458647727967, "alpha_loss": -0.011489385476335883, "alpha_value": 0.09458430292643526, "duration": 133.1142566204071, "step": 46500}
{"episode_reward": 704.0, "episode": 94.0, "critic_loss": 2.2506806724071504, "critic_target_Q_variance_m=2": 1945.8652236328126, "critic_Q1_variance_k=2": 0.03342969263717532, "critic_Q2_variance_k=2": 0.03399670323356986, "actor_loss": -88.21831298828126, "actor_mean_entropy": 1.1540272443294526, "alpha_loss": -0.010977600444108247, "alpha_value": 0.09588855779753883, "duration": 105.28268575668335, "step": 47000}
{"episode_reward": 674.0, "episode": 95.0, "critic_loss": 2.3742165763378145, "critic_target_Q_variance_m=2": 1978.1100837402344, "critic_Q1_variance_k=2": 0.03464472563564777, "critic_Q2_variance_k=2": 0.03507371926307678, "actor_loss": -88.99625360107422, "actor_mean_entropy": 1.18272345662117, "alpha_loss": -0.006600820141844451, "alpha_value": 0.0968620498917559, "duration": 94.6656596660614, "step": 47500}
{"episode_reward": 689.0, "episode": 96.0, "critic_loss": 2.392973672389984, "critic_target_Q_variance_m=2": 2015.0956694335937, "critic_Q1_variance_k=2": 0.035654702693223954, "critic_Q2_variance_k=2": 0.03609244630113244, "actor_loss": -89.8103152770996, "actor_mean_entropy": 1.1618025324344634, "alpha_loss": -0.006435542233288288, "alpha_value": 0.09750818173680266, "duration": 95.63675332069397, "step": 48000}
{"episode_reward": 704.0, "episode": 97.0, "critic_loss": 2.3092079582214358, "critic_target_Q_variance_m=2": 2046.2622724609375, "critic_Q1_variance_k=2": 0.03606193992309272, "critic_Q2_variance_k=2": 0.03655470137670636, "actor_loss": -90.49105792236328, "actor_mean_entropy": 1.1629159195423127, "alpha_loss": -0.0036409709653817115, "alpha_value": 0.0981401534281946, "duration": 95.93069529533386, "step": 48500}
{"episode_reward": 654.0, "episode": 98.0, "critic_loss": 2.4112733101844785, "critic_target_Q_variance_m=2": 2083.67267578125, "critic_Q1_variance_k=2": 0.03485542606562376, "critic_Q2_variance_k=2": 0.03540242736041546, "actor_loss": -91.28978540039063, "actor_mean_entropy": 1.1361687307357788, "alpha_loss": -0.00687489059753716, "alpha_value": 0.09878057029172395, "duration": 94.79666495323181, "step": 49000}
{"episode_reward": 731.0, "episode": 99.0, "critic_loss": 2.332153613328934, "critic_target_Q_variance_m=2": 2113.2097768554686, "critic_Q1_variance_k=2": 0.034936520421877504, "critic_Q2_variance_k=2": 0.035295967292040584, "actor_loss": -91.93822128295898, "actor_mean_entropy": 1.1446974153518676, "alpha_loss": -0.005971927549224347, "alpha_value": 0.09962006263521625, "duration": 95.75855302810669, "step": 49500}
{"episode_reward": 710.0, "episode": 100.0, "critic_loss": 2.284243070602417, "critic_target_Q_variance_m=2": 2147.037482910156, "critic_Q1_variance_k=2": 0.03405954862013459, "critic_Q2_variance_k=2": 0.034426599204540255, "actor_loss": -92.70010934448243, "actor_mean_entropy": 1.1293443448543548, "alpha_loss": -0.004292412588372827, "alpha_value": 0.10006669511172864, "duration": 84.94790863990784, "step": 50000}
