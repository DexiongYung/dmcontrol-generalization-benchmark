{"episode_reward": 0.0, "episode": 1.0, "duration": 5.048606872558594, "step": 500}
{"episode_reward": 4.0, "episode": 2.0, "duration": 0.7894423007965088, "step": 1000}
{"episode_reward": 0.0, "episode": 3.0, "critic_loss": 0.01973616029502836, "actor_loss": -0.9304677470355296, "actor_mean_entropy": 2.5442477707341733, "alpha_loss": 0.31267201994136395, "alpha_value": 0.09407802988518268, "duration": 164.87461280822754, "step": 1500}
{"episode_reward": 9.0, "episode": 4.0, "critic_loss": 0.024511120965704323, "actor_loss": -1.3179453282356262, "actor_mean_entropy": 2.6043411378860473, "alpha_loss": 0.28833756053447723, "alpha_value": 0.0874684955815857, "duration": 48.971254110336304, "step": 2000}
{"episode_reward": 0.0, "episode": 5.0, "critic_loss": 0.028862238619010896, "actor_loss": -1.3246461238861085, "actor_mean_entropy": 2.5960925645828246, "alpha_loss": 0.28115282332897185, "alpha_value": 0.08544821992949925, "duration": 49.36368536949158, "step": 2500}
{"episode_reward": 6.0, "episode": 6.0, "critic_loss": 0.03978820247668773, "actor_loss": -1.3254335470199585, "actor_mean_entropy": 2.6064924001693726, "alpha_loss": 0.27468136727809905, "alpha_value": 0.0834775321857553, "duration": 49.815478563308716, "step": 3000}
{"episode_reward": 16.0, "episode": 7.0, "critic_loss": 0.04604825733229518, "actor_loss": -1.4385633287429809, "actor_mean_entropy": 2.628405248641968, "alpha_loss": 0.2653532351255417, "alpha_value": 0.08157053059614011, "duration": 49.202680826187134, "step": 3500}
{"episode_reward": 18.0, "episode": 8.0, "critic_loss": 0.07695802170597017, "actor_loss": -1.5776057810783386, "actor_mean_entropy": 2.622508334159851, "alpha_loss": 0.25514111715555193, "alpha_value": 0.07973485122039345, "duration": 49.23548483848572, "step": 4000}
{"episode_reward": 26.0, "episode": 9.0, "critic_loss": 0.08864007345587015, "actor_loss": -1.671374469280243, "actor_mean_entropy": 2.5976266632080076, "alpha_loss": 0.24898585557937622, "alpha_value": 0.07795265826330049, "duration": 49.29833626747131, "step": 4500}
{"episode_reward": 11.0, "episode": 10.0, "critic_loss": 0.10493399142846466, "actor_loss": -1.7779480886459351, "actor_mean_entropy": 2.627736798286438, "alpha_loss": 0.2424962509870529, "alpha_value": 0.07620955183080613, "duration": 49.323935985565186, "step": 5000}
{"episode_reward": 15.0, "episode": 11.0, "critic_loss": 0.08848970523662865, "actor_loss": -1.9205347533226014, "actor_mean_entropy": 2.5976497573852537, "alpha_loss": 0.23556692469120025, "alpha_value": 0.07451346080015282, "duration": 49.14303946495056, "step": 5500}
{"episode_reward": 24.0, "episode": 12.0, "critic_loss": 0.1409031718187034, "actor_loss": -2.0571559085845945, "actor_mean_entropy": 2.5880102071762083, "alpha_loss": 0.22739919221401214, "alpha_value": 0.0728647258481588, "duration": 49.229243993759155, "step": 6000}
{"episode_reward": 27.0, "episode": 13.0, "critic_loss": 0.13613100608065726, "actor_loss": -2.19659370136261, "actor_mean_entropy": 2.5727396593093874, "alpha_loss": 0.21620984953641892, "alpha_value": 0.07127711377136033, "duration": 49.59116888046265, "step": 6500}
{"episode_reward": 12.0, "episode": 14.0, "critic_loss": 0.1614237364344299, "actor_loss": -2.3611534328460695, "actor_mean_entropy": 2.5469141006469727, "alpha_loss": 0.20385249024629593, "alpha_value": 0.06976146491038199, "duration": 49.074063777923584, "step": 7000}
{"episode_reward": 22.0, "episode": 15.0, "critic_loss": 0.1809571328088641, "actor_loss": -2.5212703790664674, "actor_mean_entropy": 2.558840763092041, "alpha_loss": 0.19261369621753693, "alpha_value": 0.0683095300390997, "duration": 49.97609257698059, "step": 7500}
{"episode_reward": 17.0, "episode": 16.0, "critic_loss": 0.1890027331635356, "actor_loss": -2.658008831977844, "actor_mean_entropy": 2.596302927970886, "alpha_loss": 0.189883642911911, "alpha_value": 0.06689126889271622, "duration": 48.958598136901855, "step": 8000}
{"episode_reward": 23.0, "episode": 17.0, "critic_loss": 0.160367129817605, "actor_loss": -2.8339479818344118, "actor_mean_entropy": 2.5698179054260253, "alpha_loss": 0.18333142894506455, "alpha_value": 0.06547582394308114, "duration": 36.62813663482666, "step": 8500}
{"episode_reward": 22.0, "episode": 18.0, "critic_loss": 0.2368971902281046, "actor_loss": -3.0125323295593263, "actor_mean_entropy": 2.532481756210327, "alpha_loss": 0.17476774418354035, "alpha_value": 0.06410391466031758, "duration": 32.875526428222656, "step": 9000}
{"episode_reward": 123.0, "episode": 19.0, "critic_loss": 0.2557621035426855, "actor_loss": -3.2177659282684328, "actor_mean_entropy": 2.505477096557617, "alpha_loss": 0.1694529219865799, "alpha_value": 0.06276601884001769, "duration": 31.729660987854004, "step": 9500}
{"episode_reward": 85.0, "episode": 20.0, "critic_loss": 0.2792045109719038, "actor_loss": -3.400604266166687, "actor_mean_entropy": 2.483629111289978, "alpha_loss": 0.15679106134176254, "alpha_value": 0.061473491709670994, "duration": 29.53749132156372, "step": 10000}
