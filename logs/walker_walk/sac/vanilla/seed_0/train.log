{"episode_reward": 0.0, "episode": 1.0, "duration": 2.593716621398926, "step": 250}
{"episode_reward": 51.702662558795076, "episode": 2.0, "duration": 0.4881749153137207, "step": 500}
{"episode_reward": 64.99570868557767, "episode": 3.0, "duration": 0.48836255073547363, "step": 750}
{"episode_reward": 57.68951042190992, "episode": 4.0, "duration": 0.48793506622314453, "step": 1000}
{"episode_reward": 51.742837732540245, "episode": 5.0, "critic_loss": 0.09985967747586741, "actor_loss": -4.045994544222378, "actor_mean_entropy": 7.847311139637041, "alpha_loss": 0.8788443041892451, "alpha_value": 0.09475797364877665, "duration": 106.32270455360413, "step": 1250}
{"episode_reward": 84.986321591232, "episode": 6.0, "critic_loss": 0.12940438601374626, "actor_loss": -7.202520805358887, "actor_mean_entropy": 8.039496196746827, "alpha_loss": 0.8122361369132995, "alpha_value": 0.08941870568244926, "duration": 25.27310085296631, "step": 1500}
{"episode_reward": 62.572102985346504, "episode": 7.0, "critic_loss": 0.16991230648756028, "actor_loss": -7.669549049377442, "actor_mean_entropy": 8.095743690490723, "alpha_loss": 0.8228179011344909, "alpha_value": 0.08835435594437586, "duration": 25.503353357315063, "step": 1750}
{"episode_reward": 118.77213081453097, "episode": 8.0, "critic_loss": 0.16457830318808556, "actor_loss": -8.252053981781005, "actor_mean_entropy": 8.110975593566895, "alpha_loss": 0.8058907537460327, "alpha_value": 0.08729923584247284, "duration": 25.49471640586853, "step": 2000}
{"episode_reward": 88.42020782279961, "episode": 9.0, "critic_loss": 0.27974709874391557, "actor_loss": -8.711149055480957, "actor_mean_entropy": 8.030626937866211, "alpha_loss": 0.778779914855957, "alpha_value": 0.08627901430720696, "duration": 24.524660348892212, "step": 2250}
{"episode_reward": 86.15171284516728, "episode": 10.0, "critic_loss": 0.1828997654914856, "actor_loss": -9.18134635925293, "actor_mean_entropy": 8.034689014434814, "alpha_loss": 0.7737188038825988, "alpha_value": 0.08528389844172851, "duration": 24.709150552749634, "step": 2500}
{"episode_reward": 60.070649900804064, "episode": 11.0, "critic_loss": 0.2814096305966377, "actor_loss": -9.698992294311523, "actor_mean_entropy": 8.038807136535645, "alpha_loss": 0.7609846420288086, "alpha_value": 0.08429450040067038, "duration": 24.62331461906433, "step": 2750}
{"episode_reward": 89.82087273135443, "episode": 12.0, "critic_loss": 0.3529322058558464, "actor_loss": -10.096399536132813, "actor_mean_entropy": 8.035459594726563, "alpha_loss": 0.7576441769599914, "alpha_value": 0.08332300784526833, "duration": 24.33684539794922, "step": 3000}
{"episode_reward": 75.05911442578252, "episode": 13.0, "critic_loss": 0.23308040645718575, "actor_loss": -10.533110168457032, "actor_mean_entropy": 8.087901885986328, "alpha_loss": 0.7511684002876282, "alpha_value": 0.08235922524418039, "duration": 24.418224334716797, "step": 3250}
{"episode_reward": 49.86567634344509, "episode": 14.0, "critic_loss": 0.2285505020916462, "actor_loss": -10.909474502563477, "actor_mean_entropy": 8.0532336769104, "alpha_loss": 0.7389776668548584, "alpha_value": 0.08140475152067482, "duration": 24.53542447090149, "step": 3500}
{"episode_reward": 77.76029792792914, "episode": 15.0, "critic_loss": 0.339271132171154, "actor_loss": -11.437336196899414, "actor_mean_entropy": 8.067989475250243, "alpha_loss": 0.7351275687217712, "alpha_value": 0.08046567428434004, "duration": 24.437551736831665, "step": 3750}
{"episode_reward": 117.6159789460452, "episode": 16.0, "critic_loss": 0.3280728450417519, "actor_loss": -11.946707214355468, "actor_mean_entropy": 8.08592387008667, "alpha_loss": 0.7183479619026184, "alpha_value": 0.07954093855114563, "duration": 24.66559338569641, "step": 4000}
{"episode_reward": 126.0450686951737, "episode": 17.0, "critic_loss": 0.5350910701155662, "actor_loss": -12.362760345458984, "actor_mean_entropy": 7.995184070587158, "alpha_loss": 0.7044101815223693, "alpha_value": 0.07863674054818513, "duration": 24.53726863861084, "step": 4250}
{"episode_reward": 39.50230252262578, "episode": 18.0, "critic_loss": 0.5147609623670578, "actor_loss": -12.7458872756958, "actor_mean_entropy": 8.02614183807373, "alpha_loss": 0.7026314845085144, "alpha_value": 0.07774272079816345, "duration": 24.73691749572754, "step": 4500}
{"episode_reward": 60.51378624545724, "episode": 19.0, "critic_loss": 0.32450439524650576, "actor_loss": -13.137462982177734, "actor_mean_entropy": 7.975765483856201, "alpha_loss": 0.6795135388374328, "alpha_value": 0.07686564389834984, "duration": 24.566242694854736, "step": 4750}
{"episode_reward": 36.801079737616575, "episode": 20.0, "critic_loss": 0.41609138816595076, "actor_loss": -13.49294856262207, "actor_mean_entropy": 8.04483275604248, "alpha_loss": 0.6830020513534546, "alpha_value": 0.07600062749991437, "duration": 24.591933727264404, "step": 5000}
{"episode_reward": 86.35048961575356, "episode": 21.0, "critic_loss": 0.3891553965806961, "actor_loss": -13.947610549926758, "actor_mean_entropy": 8.003972229003907, "alpha_loss": 0.6697508702278138, "alpha_value": 0.0751379844176372, "duration": 24.50607204437256, "step": 5250}
{"episode_reward": 80.51266193653214, "episode": 22.0, "critic_loss": 0.43703646218776704, "actor_loss": -14.405910110473632, "actor_mean_entropy": 8.00897269821167, "alpha_loss": 0.6576917920112609, "alpha_value": 0.07429453432659375, "duration": 24.56731343269348, "step": 5500}
{"episode_reward": 86.52900163103656, "episode": 23.0, "critic_loss": 0.48645751690864564, "actor_loss": -14.758987007141114, "actor_mean_entropy": 7.961826442718506, "alpha_loss": 0.6424924664497376, "alpha_value": 0.07346806354931773, "duration": 24.414970874786377, "step": 5750}
{"episode_reward": 51.88913304478213, "episode": 24.0, "critic_loss": 0.46651399219036105, "actor_loss": -15.077660186767577, "actor_mean_entropy": 8.004702514648438, "alpha_loss": 0.6308975229263306, "alpha_value": 0.07265555457546495, "duration": 24.60011911392212, "step": 6000}
{"episode_reward": 89.79627656420053, "episode": 25.0, "critic_loss": 0.5424336546063423, "actor_loss": -15.420085083007812, "actor_mean_entropy": 8.00823212814331, "alpha_loss": 0.6287158989906311, "alpha_value": 0.071849910055576, "duration": 24.45387625694275, "step": 6250}
{"episode_reward": 77.03369176808928, "episode": 26.0, "critic_loss": 0.6014235861301422, "actor_loss": -15.874681686401367, "actor_mean_entropy": 7.982556430816651, "alpha_loss": 0.6215723314285279, "alpha_value": 0.07104631140297439, "duration": 24.496979475021362, "step": 6500}
{"episode_reward": 76.31771692578269, "episode": 27.0, "critic_loss": 0.5350910837650299, "actor_loss": -16.192392402648927, "actor_mean_entropy": 7.955928733825684, "alpha_loss": 0.6074092302322388, "alpha_value": 0.07026048792928409, "duration": 24.677079916000366, "step": 6750}
{"episode_reward": 113.64637299965372, "episode": 28.0, "critic_loss": 0.5823930253982544, "actor_loss": -16.595436614990234, "actor_mean_entropy": 7.964127395629883, "alpha_loss": 0.5903842649459838, "alpha_value": 0.0694897138699002, "duration": 24.67145347595215, "step": 7000}
{"episode_reward": 82.80087871443733, "episode": 29.0, "critic_loss": 0.6741934579610824, "actor_loss": -16.829311065673828, "actor_mean_entropy": 7.922506072998047, "alpha_loss": 0.573614143371582, "alpha_value": 0.06873914345649589, "duration": 24.448325634002686, "step": 7250}
{"episode_reward": 82.28337794058542, "episode": 30.0, "critic_loss": 0.6376950924396515, "actor_loss": -17.22379214477539, "actor_mean_entropy": 7.927537590026856, "alpha_loss": 0.5780831198692322, "alpha_value": 0.06799260859363375, "duration": 24.370741605758667, "step": 7500}
{"episode_reward": 95.04383314689993, "episode": 31.0, "critic_loss": 0.7211361280679702, "actor_loss": -17.55806478881836, "actor_mean_entropy": 7.975246635437012, "alpha_loss": 0.5716614456176757, "alpha_value": 0.06724434278984517, "duration": 24.540562868118286, "step": 7750}
{"episode_reward": 69.12164685923621, "episode": 32.0, "critic_loss": 0.7567891421318054, "actor_loss": -17.874124267578125, "actor_mean_entropy": 7.999323642730713, "alpha_loss": 0.5663984966278076, "alpha_value": 0.06650220979658189, "duration": 24.53080916404724, "step": 8000}
{"episode_reward": 99.72192584330739, "episode": 33.0, "critic_loss": 0.8228439098596573, "actor_loss": -18.144998718261718, "actor_mean_entropy": 8.044079597473145, "alpha_loss": 0.5578796005249024, "alpha_value": 0.06576752380327322, "duration": 24.581289768218994, "step": 8250}
{"episode_reward": 73.47626412742406, "episode": 34.0, "critic_loss": 0.8552972118854523, "actor_loss": -18.338129638671877, "actor_mean_entropy": 8.033850662231446, "alpha_loss": 0.5545405158996582, "alpha_value": 0.06503559876625858, "duration": 24.740805864334106, "step": 8500}
{"episode_reward": 59.65668544894564, "episode": 35.0, "critic_loss": 0.8614410533905029, "actor_loss": -18.656187469482422, "actor_mean_entropy": 8.017621376037598, "alpha_loss": 0.5422931408882141, "alpha_value": 0.06432022416493927, "duration": 24.65113377571106, "step": 8750}
{"episode_reward": 87.77400336206723, "episode": 36.0, "critic_loss": 0.7760176982879639, "actor_loss": -19.061351943969726, "actor_mean_entropy": 7.970261783599853, "alpha_loss": 0.5298116173744202, "alpha_value": 0.0636137456487462, "duration": 24.59789776802063, "step": 9000}
{"episode_reward": 67.34078942576171, "episode": 37.0, "critic_loss": 0.8953947803974152, "actor_loss": -19.367020538330078, "actor_mean_entropy": 8.004505573272706, "alpha_loss": 0.5263200538158417, "alpha_value": 0.0629185841496687, "duration": 24.68063235282898, "step": 9250}
{"episode_reward": 101.38935278481081, "episode": 38.0, "critic_loss": 0.9327068580389023, "actor_loss": -19.58741033935547, "actor_mean_entropy": 8.06380507659912, "alpha_loss": 0.5260258738994599, "alpha_value": 0.06222308455227249, "duration": 24.597285270690918, "step": 9500}
{"episode_reward": 63.28494176060729, "episode": 39.0, "critic_loss": 0.8797565901279449, "actor_loss": -19.88330335998535, "actor_mean_entropy": 8.039572483062743, "alpha_loss": 0.5167635161876678, "alpha_value": 0.06152991437301719, "duration": 24.557724952697754, "step": 9750}
{"episode_reward": 68.55604620597872, "episode": 40.0, "critic_loss": 0.8518715901374817, "actor_loss": -20.197569076538088, "actor_mean_entropy": 8.023820163726807, "alpha_loss": 0.5058976559638977, "alpha_value": 0.060851624560344965, "duration": 24.801223754882812, "step": 10000}
