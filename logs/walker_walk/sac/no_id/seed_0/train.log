{"episode_reward": 0.0, "episode": 1.0, "duration": 2.6181275844573975, "step": 250}
{"episode_reward": 51.702662558795076, "episode": 2.0, "duration": 0.49215149879455566, "step": 500}
{"episode_reward": 64.99570868557767, "episode": 3.0, "duration": 0.49373316764831543, "step": 750}
{"episode_reward": 57.68951042190992, "episode": 4.0, "duration": 0.4966459274291992, "step": 1000}
{"episode_reward": 51.742837732540245, "episode": 5.0, "critic_loss": 0.18373796962398448, "actor_loss": -4.0331190314122765, "actor_mean_entropy": 7.68912039596415, "alpha_loss": 0.8149932961234843, "alpha_value": 0.0948765997700378, "duration": 86.52701473236084, "step": 1250}
{"episode_reward": 41.29162168054783, "episode": 6.0, "critic_loss": 0.19961544847488402, "actor_loss": -6.835664066314697, "actor_mean_entropy": 8.140008045196533, "alpha_loss": 0.7442652468681336, "alpha_value": 0.09002709259618, "duration": 15.304203987121582, "step": 1500}
{"episode_reward": 86.04648292377212, "episode": 7.0, "critic_loss": 0.14768284103274346, "actor_loss": -7.164969242095947, "actor_mean_entropy": 8.268708671569824, "alpha_loss": 0.7755707130432129, "alpha_value": 0.08894186585737744, "duration": 15.541151285171509, "step": 1750}
{"episode_reward": 48.996427574227035, "episode": 8.0, "critic_loss": 0.2401690548658371, "actor_loss": -7.606582157135009, "actor_mean_entropy": 8.349267524719238, "alpha_loss": 0.7813986625671386, "alpha_value": 0.08783710148239365, "duration": 24.617814540863037, "step": 2000}
{"episode_reward": 92.07595149836145, "episode": 9.0, "critic_loss": 0.27470941776037217, "actor_loss": -8.043497837066651, "actor_mean_entropy": 8.326765769958497, "alpha_loss": 0.773161226272583, "alpha_value": 0.08674653711279193, "duration": 25.54505157470703, "step": 2250}
{"episode_reward": 116.72437567962035, "episode": 10.0, "critic_loss": 0.25151840707659723, "actor_loss": -8.531753395080566, "actor_mean_entropy": 8.255634830474854, "alpha_loss": 0.7523798670768738, "alpha_value": 0.08569354488826593, "duration": 25.38078761100769, "step": 2500}
{"episode_reward": 83.06913432313574, "episode": 11.0, "critic_loss": 0.3321842369437218, "actor_loss": -9.048532844543457, "actor_mean_entropy": 8.199433307647706, "alpha_loss": 0.7256920461654663, "alpha_value": 0.084677428645591, "duration": 25.239991664886475, "step": 2750}
{"episode_reward": 123.43688702442428, "episode": 12.0, "critic_loss": 0.44271235626935956, "actor_loss": -9.495719352722167, "actor_mean_entropy": 8.197344478607178, "alpha_loss": 0.7067250871658325, "alpha_value": 0.08369518970067064, "duration": 25.482529878616333, "step": 3000}
{"episode_reward": 78.64947876940559, "episode": 13.0, "critic_loss": 0.4681020485758781, "actor_loss": -9.860507972717285, "actor_mean_entropy": 8.195993782043457, "alpha_loss": 0.6864013376235962, "alpha_value": 0.08274553721854336, "duration": 24.768325090408325, "step": 3250}
{"episode_reward": 66.71310106456014, "episode": 14.0, "critic_loss": 0.3976924486160278, "actor_loss": -10.269731567382813, "actor_mean_entropy": 8.191761417388916, "alpha_loss": 0.6808587517738343, "alpha_value": 0.0818085320350816, "duration": 24.575133562088013, "step": 3500}
{"episode_reward": 71.09203980123885, "episode": 15.0, "critic_loss": 0.39482697439193726, "actor_loss": -10.761169326782227, "actor_mean_entropy": 8.159930137634277, "alpha_loss": 0.668023226261139, "alpha_value": 0.08088295026142266, "duration": 24.509252309799194, "step": 3750}
{"episode_reward": 84.7887758911346, "episode": 16.0, "critic_loss": 0.40005109572410585, "actor_loss": -11.171045692443847, "actor_mean_entropy": 8.160165603637695, "alpha_loss": 0.6533606939315796, "alpha_value": 0.079977470761359, "duration": 24.54755210876465, "step": 4000}
{"episode_reward": 52.66853112390131, "episode": 17.0, "critic_loss": 0.40515246605873106, "actor_loss": -11.565765411376953, "actor_mean_entropy": 8.09677960205078, "alpha_loss": 0.6456094846725464, "alpha_value": 0.07908773155240566, "duration": 24.569822072982788, "step": 4250}
{"episode_reward": 62.10635032084028, "episode": 18.0, "critic_loss": 0.457328861117363, "actor_loss": -11.936375076293945, "actor_mean_entropy": 8.106259593963623, "alpha_loss": 0.641679319858551, "alpha_value": 0.0782015961555026, "duration": 26.40797519683838, "step": 4500}
{"episode_reward": 70.06558378346193, "episode": 19.0, "critic_loss": 0.35840638720989226, "actor_loss": -12.353626571655273, "actor_mean_entropy": 8.196235939025879, "alpha_loss": 0.6461571102142334, "alpha_value": 0.07731257355201908, "duration": 24.808417320251465, "step": 4750}
{"episode_reward": 43.487930657298556, "episode": 20.0, "critic_loss": 0.3406695901751518, "actor_loss": -12.752324081420898, "actor_mean_entropy": 8.209010185241699, "alpha_loss": 0.6406846146583557, "alpha_value": 0.07642890503746093, "duration": 24.618247270584106, "step": 5000}
{"episode_reward": 77.39041119747354, "episode": 21.0, "critic_loss": 0.5124312201142311, "actor_loss": -13.133853546142578, "actor_mean_entropy": 8.167765563964844, "alpha_loss": 0.6233047471046448, "alpha_value": 0.07555900066874649, "duration": 24.522048711776733, "step": 5250}
{"episode_reward": 108.53670736035708, "episode": 22.0, "critic_loss": 0.6199887043237686, "actor_loss": -13.526196807861329, "actor_mean_entropy": 8.165681686401367, "alpha_loss": 0.6131248307228089, "alpha_value": 0.07470984044473311, "duration": 24.6239492893219, "step": 5500}
{"episode_reward": 70.93757066227076, "episode": 23.0, "critic_loss": 0.42513722568750384, "actor_loss": -13.784425201416015, "actor_mean_entropy": 8.191905345916748, "alpha_loss": 0.6124288654327392, "alpha_value": 0.07386854840861895, "duration": 24.703641176223755, "step": 5750}
{"episode_reward": 57.46926435373602, "episode": 24.0, "critic_loss": 0.3784822422862053, "actor_loss": -14.103240020751953, "actor_mean_entropy": 8.218292999267579, "alpha_loss": 0.6094289197921753, "alpha_value": 0.07302594083274548, "duration": 24.613287925720215, "step": 6000}
{"episode_reward": 88.43837195153061, "episode": 25.0, "critic_loss": 0.5904758998155594, "actor_loss": -14.503914848327637, "actor_mean_entropy": 8.188265132904053, "alpha_loss": 0.5977257885932923, "alpha_value": 0.07219839315568519, "duration": 24.72318196296692, "step": 6250}
{"episode_reward": 130.6201134190138, "episode": 26.0, "critic_loss": 0.5275805884599686, "actor_loss": -14.85839688873291, "actor_mean_entropy": 8.17059846496582, "alpha_loss": 0.583832576751709, "alpha_value": 0.07138590403103233, "duration": 24.61845636367798, "step": 6500}
{"episode_reward": 56.8411893466689, "episode": 27.0, "critic_loss": 0.42076385879516603, "actor_loss": -15.118872871398926, "actor_mean_entropy": 8.150294345855713, "alpha_loss": 0.5728794207572937, "alpha_value": 0.07059303605523407, "duration": 24.575442790985107, "step": 6750}
{"episode_reward": 48.666601493055616, "episode": 28.0, "critic_loss": 0.4906813843846321, "actor_loss": -15.439049743652344, "actor_mean_entropy": 8.163912811279296, "alpha_loss": 0.5682755522727966, "alpha_value": 0.06980729441143005, "duration": 24.548337936401367, "step": 7000}
{"episode_reward": 129.15384135349586, "episode": 29.0, "critic_loss": 0.5776220698356629, "actor_loss": -15.882718048095704, "actor_mean_entropy": 8.208783615112305, "alpha_loss": 0.5617898564338684, "alpha_value": 0.06902879255915552, "duration": 24.60495138168335, "step": 7250}
{"episode_reward": 70.53990805126816, "episode": 30.0, "critic_loss": 0.5859395425319671, "actor_loss": -16.20233275604248, "actor_mean_entropy": 8.134607940673828, "alpha_loss": 0.5459473509788513, "alpha_value": 0.06826562812385557, "duration": 24.735979080200195, "step": 7500}
{"episode_reward": 114.27553404905913, "episode": 31.0, "critic_loss": 0.684618327498436, "actor_loss": -16.437692276000977, "actor_mean_entropy": 8.179930690765381, "alpha_loss": 0.5399490840435028, "alpha_value": 0.06751396021361146, "duration": 24.60804057121277, "step": 7750}
{"episode_reward": 59.42382424124299, "episode": 32.0, "critic_loss": 0.6112870463132858, "actor_loss": -16.68086346435547, "actor_mean_entropy": 8.192396049499513, "alpha_loss": 0.5419548139572143, "alpha_value": 0.06676352497348462, "duration": 24.56295132637024, "step": 8000}
{"episode_reward": 67.72596712011544, "episode": 33.0, "critic_loss": 0.6797339143753052, "actor_loss": -16.894398078918456, "actor_mean_entropy": 8.172620841979981, "alpha_loss": 0.5284380261898041, "alpha_value": 0.06602216794676351, "duration": 24.896747827529907, "step": 8250}
{"episode_reward": 84.47080018808727, "episode": 34.0, "critic_loss": 0.7300913463830948, "actor_loss": -17.2153953704834, "actor_mean_entropy": 8.167103492736816, "alpha_loss": 0.5227524218559265, "alpha_value": 0.06528774878994935, "duration": 24.649433374404907, "step": 8500}
{"episode_reward": 90.29211868350549, "episode": 35.0, "critic_loss": 0.7059489998817444, "actor_loss": -17.44690444946289, "actor_mean_entropy": 8.179818927764893, "alpha_loss": 0.5145921747684479, "alpha_value": 0.06456536053209795, "duration": 24.485448598861694, "step": 8750}
{"episode_reward": 118.43538361871221, "episode": 36.0, "critic_loss": 0.7077562328577042, "actor_loss": -17.761577697753907, "actor_mean_entropy": 8.110785026550293, "alpha_loss": 0.49646692037582396, "alpha_value": 0.06386092124156321, "duration": 24.487163543701172, "step": 9000}
{"episode_reward": 80.80244346825702, "episode": 37.0, "critic_loss": 0.7401833816766739, "actor_loss": -18.124129272460937, "actor_mean_entropy": 8.126641101837158, "alpha_loss": 0.4870907325744629, "alpha_value": 0.06317074737179314, "duration": 25.252744674682617, "step": 9250}
{"episode_reward": 63.39977574650678, "episode": 38.0, "critic_loss": 0.6765433131456375, "actor_loss": -18.25007015991211, "actor_mean_entropy": 8.132481182098388, "alpha_loss": 0.478441700220108, "alpha_value": 0.06249096588554544, "duration": 24.76999282836914, "step": 9500}
{"episode_reward": 66.73243394221855, "episode": 39.0, "critic_loss": 0.6734755859375, "actor_loss": -18.538765167236328, "actor_mean_entropy": 8.11618304824829, "alpha_loss": 0.4738223686218262, "alpha_value": 0.0618161122676772, "duration": 24.502378702163696, "step": 9750}
{"episode_reward": 81.63511047017005, "episode": 40.0, "critic_loss": 0.8173125492334365, "actor_loss": -18.761703735351563, "actor_mean_entropy": 8.133017784118652, "alpha_loss": 0.4661625144481659, "alpha_value": 0.061148230729252726, "duration": 24.43441152572632, "step": 10000}
