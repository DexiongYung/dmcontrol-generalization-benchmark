{"episode_reward": 0.0, "episode": 1.0, "duration": 2.574619770050049, "step": 250}
{"episode_reward": 51.702662558795076, "episode": 2.0, "duration": 0.4860415458679199, "step": 500}
{"episode_reward": 64.99570868557767, "episode": 3.0, "duration": 0.4863471984863281, "step": 750}
{"episode_reward": 57.68951042190992, "episode": 4.0, "duration": 0.48567938804626465, "step": 1000}
{"episode_reward": 51.742837732540245, "episode": 5.0, "critic_loss": 0.7323575560764086, "critic_target_Q_variance_m=2": 4.823404597993895, "critic_Q1_variance_k=2": 0.016782310605063095, "critic_Q2_variance_k=2": 0.01669816520537941, "actor_loss": -4.012406141149191, "actor_mean_entropy": 7.80790006138676, "alpha_loss": 0.8768431677937083, "alpha_value": 0.09475005243326481, "duration": 161.3674430847168, "step": 1250}
{"episode_reward": 61.93425687269602, "episode": 6.0, "critic_loss": 1.3501468646526336, "critic_target_Q_variance_m=2": 11.181064163208008, "critic_Q1_variance_k=2": 0.03297428795695305, "critic_Q2_variance_k=2": 0.03291625291109085, "actor_loss": -6.872135707855224, "actor_mean_entropy": 7.7555812606811525, "alpha_loss": 0.7301862163543701, "alpha_value": 0.08953933230162599, "duration": 29.888057470321655, "step": 1500}
{"episode_reward": 100.79698450686058, "episode": 7.0, "critic_loss": 1.2980965480804443, "critic_target_Q_variance_m=2": 12.403312435150147, "critic_Q1_variance_k=2": 0.03277660643681884, "critic_Q2_variance_k=2": 0.0326871945373714, "actor_loss": -7.219734870910645, "actor_mean_entropy": 7.559329154968261, "alpha_loss": 0.7197087774276734, "alpha_value": 0.08857882441254408, "duration": 29.94293999671936, "step": 1750}
{"episode_reward": 43.02782842874919, "episode": 8.0, "critic_loss": 1.6839602429866791, "critic_target_Q_variance_m=2": 14.342585544586182, "critic_Q1_variance_k=2": 0.04264868765324354, "critic_Q2_variance_k=2": 0.04234480944275856, "actor_loss": -7.722372409820557, "actor_mean_entropy": 7.501188838958741, "alpha_loss": 0.7027388978004455, "alpha_value": 0.08763108162468727, "duration": 30.108052015304565, "step": 2000}
{"episode_reward": 83.17904675429567, "episode": 9.0, "critic_loss": 1.6565165140628815, "critic_target_Q_variance_m=2": 15.715522525787353, "critic_Q1_variance_k=2": 0.04592702329903841, "critic_Q2_variance_k=2": 0.044989589393138886, "actor_loss": -8.022629177093506, "actor_mean_entropy": 7.464324420928955, "alpha_loss": 0.6994507694244385, "alpha_value": 0.0866737898253763, "duration": 30.08354425430298, "step": 2250}
{"episode_reward": 62.66284699985043, "episode": 10.0, "critic_loss": 1.9222958171367646, "critic_target_Q_variance_m=2": 17.815373207092286, "critic_Q1_variance_k=2": 0.048807274103164676, "critic_Q2_variance_k=2": 0.04873615476489067, "actor_loss": -8.487996658325196, "actor_mean_entropy": 7.457775802612304, "alpha_loss": 0.6946862573623658, "alpha_value": 0.08572882783499997, "duration": 29.979739904403687, "step": 2500}
{"episode_reward": 50.37078822455084, "episode": 11.0, "critic_loss": 1.6053353395462036, "critic_target_Q_variance_m=2": 19.82934703063965, "critic_Q1_variance_k=2": 0.04304242567718029, "critic_Q2_variance_k=2": 0.043186147280037404, "actor_loss": -8.953913520812987, "actor_mean_entropy": 7.463027305603028, "alpha_loss": 0.6822204446792602, "alpha_value": 0.08478299005842213, "duration": 30.346237897872925, "step": 2750}
{"episode_reward": 58.9208381147886, "episode": 12.0, "critic_loss": 1.7317270703315735, "critic_target_Q_variance_m=2": 22.226775009155272, "critic_Q1_variance_k=2": 0.04684781567007303, "critic_Q2_variance_k=2": 0.04695976773649454, "actor_loss": -9.444034233093262, "actor_mean_entropy": 7.423018016815186, "alpha_loss": 0.6798700461387635, "alpha_value": 0.08384512833697792, "duration": 46.05834674835205, "step": 3000}
{"episode_reward": 72.26699747781032, "episode": 13.0, "critic_loss": 1.8481951744556426, "critic_target_Q_variance_m=2": 25.6989029006958, "critic_Q1_variance_k=2": 0.047106922179460525, "critic_Q2_variance_k=2": 0.047143691457808015, "actor_loss": -10.078445533752442, "actor_mean_entropy": 7.438834377288819, "alpha_loss": 0.6771901063919067, "alpha_value": 0.08290517105926029, "duration": 49.71797561645508, "step": 3250}
{"episode_reward": 117.76591702079871, "episode": 14.0, "critic_loss": 1.659298777103424, "critic_target_Q_variance_m=2": 29.287610786437988, "critic_Q1_variance_k=2": 0.04407823646068573, "critic_Q2_variance_k=2": 0.04336460585147142, "actor_loss": -10.732652786254883, "actor_mean_entropy": 7.456868236541748, "alpha_loss": 0.6671114315986634, "alpha_value": 0.08197605690422934, "duration": 49.25931262969971, "step": 3500}
{"episode_reward": 77.68505568042136, "episode": 15.0, "critic_loss": 1.6528108894824982, "critic_target_Q_variance_m=2": 31.76162212371826, "critic_Q1_variance_k=2": 0.04198031873255968, "critic_Q2_variance_k=2": 0.04196213755011559, "actor_loss": -11.128102409362793, "actor_mean_entropy": 7.536587291717529, "alpha_loss": 0.6792220735549926, "alpha_value": 0.08103999057266861, "duration": 68.88039064407349, "step": 3750}
{"episode_reward": 72.30774361823718, "episode": 16.0, "critic_loss": 1.5362096517086028, "critic_target_Q_variance_m=2": 34.416265640258786, "critic_Q1_variance_k=2": 0.041027397476136686, "critic_Q2_variance_k=2": 0.040448326848447326, "actor_loss": -11.575610588073731, "actor_mean_entropy": 7.4464719696044925, "alpha_loss": 0.676877429485321, "alpha_value": 0.08010306754465356, "duration": 70.82735204696655, "step": 4000}
{"episode_reward": 114.14021995746221, "episode": 17.0, "critic_loss": 2.116055785894394, "critic_target_Q_variance_m=2": 39.77925163269043, "critic_Q1_variance_k=2": 0.04950906416028738, "critic_Q2_variance_k=2": 0.04943113578483462, "actor_loss": -12.377721832275391, "actor_mean_entropy": 7.485424121856689, "alpha_loss": 0.670094485282898, "alpha_value": 0.07917109404133557, "duration": 70.80829644203186, "step": 4250}
{"episode_reward": 164.1846924446946, "episode": 18.0, "critic_loss": 2.181547074317932, "critic_target_Q_variance_m=2": 44.49384893798828, "critic_Q1_variance_k=2": 0.05411539915949106, "critic_Q2_variance_k=2": 0.05403290202468634, "actor_loss": -13.032939453125, "actor_mean_entropy": 7.389372562408448, "alpha_loss": 0.6462588963508606, "alpha_value": 0.07826488126271026, "duration": 71.23028135299683, "step": 4500}
{"episode_reward": 112.03794743132747, "episode": 19.0, "critic_loss": 2.3217050604820253, "critic_target_Q_variance_m=2": 48.407107299804686, "critic_Q1_variance_k=2": 0.058561174780130384, "critic_Q2_variance_k=2": 0.0587504937723279, "actor_loss": -13.589716079711915, "actor_mean_entropy": 7.236460529327393, "alpha_loss": 0.6244368424415588, "alpha_value": 0.07738653497337403, "duration": 69.68216824531555, "step": 4750}
{"episode_reward": 137.91315698823496, "episode": 20.0, "critic_loss": 2.6448368186950684, "critic_target_Q_variance_m=2": 53.53638255310059, "critic_Q1_variance_k=2": 0.058739277079701425, "critic_Q2_variance_k=2": 0.05805923198908568, "actor_loss": -14.31633194732666, "actor_mean_entropy": 7.12843416595459, "alpha_loss": 0.597378080368042, "alpha_value": 0.0765472978145743, "duration": 69.76048994064331, "step": 5000}
{"episode_reward": 102.0397593515219, "episode": 21.0, "critic_loss": 2.898084952354431, "critic_target_Q_variance_m=2": 58.736183975219724, "critic_Q1_variance_k=2": 0.06388523524254561, "critic_Q2_variance_k=2": 0.06324300079792738, "actor_loss": -14.943040504455567, "actor_mean_entropy": 7.016613372802734, "alpha_loss": 0.5766230483055115, "alpha_value": 0.07573018033628065, "duration": 69.24894571304321, "step": 5250}
{"episode_reward": 190.88965410388155, "episode": 22.0, "critic_loss": 3.4552938385009764, "critic_target_Q_variance_m=2": 63.75447630310059, "critic_Q1_variance_k=2": 0.08090828435122967, "critic_Q2_variance_k=2": 0.07987956239283085, "actor_loss": -15.590609405517577, "actor_mean_entropy": 7.012264778137207, "alpha_loss": 0.5644267091751098, "alpha_value": 0.07493084704870948, "duration": 69.81883883476257, "step": 5500}
{"episode_reward": 138.68549105820168, "episode": 23.0, "critic_loss": 3.775247031211853, "critic_target_Q_variance_m=2": 70.67620536804199, "critic_Q1_variance_k=2": 0.08935753675550222, "critic_Q2_variance_k=2": 0.08830595630407333, "actor_loss": -16.307804000854492, "actor_mean_entropy": 6.884020446777344, "alpha_loss": 0.5408469445705414, "alpha_value": 0.07415365706921098, "duration": 69.66850519180298, "step": 5750}
{"episode_reward": 233.49083096245582, "episode": 24.0, "critic_loss": 3.9214105072021486, "critic_target_Q_variance_m=2": 78.21619390869141, "critic_Q1_variance_k=2": 0.09527005974948406, "critic_Q2_variance_k=2": 0.09405095686018466, "actor_loss": -17.14810011291504, "actor_mean_entropy": 6.74740270614624, "alpha_loss": 0.5113578922748566, "alpha_value": 0.07339902158806244, "duration": 70.16053700447083, "step": 6000}
{"episode_reward": 216.9128628888857, "episode": 25.0, "critic_loss": 4.890229990005493, "critic_target_Q_variance_m=2": 84.96210708618165, "critic_Q1_variance_k=2": 0.12045363794267178, "critic_Q2_variance_k=2": 0.11782081964612007, "actor_loss": -17.8625604095459, "actor_mean_entropy": 6.6269495429992675, "alpha_loss": 0.47464479064941406, "alpha_value": 0.07268884700339585, "duration": 69.58414721488953, "step": 6250}
{"episode_reward": 212.35279236427883, "episode": 26.0, "critic_loss": 5.967612274169922, "critic_target_Q_variance_m=2": 95.9068814086914, "critic_Q1_variance_k=2": 0.1457644415795803, "critic_Q2_variance_k=2": 0.1452672835290432, "actor_loss": -18.95951628112793, "actor_mean_entropy": 6.459163497924805, "alpha_loss": 0.44694807028770445, "alpha_value": 0.07201473209253538, "duration": 69.5944652557373, "step": 6500}
{"episode_reward": 249.81854417807847, "episode": 27.0, "critic_loss": 6.560062690734863, "critic_target_Q_variance_m=2": 105.3829345703125, "critic_Q1_variance_k=2": 0.1489090107381344, "critic_Q2_variance_k=2": 0.14770968307554722, "actor_loss": -19.828858383178712, "actor_mean_entropy": 6.275694076538086, "alpha_loss": 0.4281074376106262, "alpha_value": 0.07135677466813818, "duration": 69.39043712615967, "step": 6750}
{"episode_reward": 279.41711764475616, "episode": 28.0, "critic_loss": 7.8487710752487185, "critic_target_Q_variance_m=2": 118.8696838684082, "critic_Q1_variance_k=2": 0.17616103237867356, "critic_Q2_variance_k=2": 0.1736816467344761, "actor_loss": -21.07770608520508, "actor_mean_entropy": 6.29794178390503, "alpha_loss": 0.3917359802722931, "alpha_value": 0.07072592854885779, "duration": 69.85165095329285, "step": 7000}
{"episode_reward": 236.36458552851863, "episode": 29.0, "critic_loss": 8.353983403205872, "critic_target_Q_variance_m=2": 130.06215551757813, "critic_Q1_variance_k=2": 0.18963828828930854, "critic_Q2_variance_k=2": 0.1854526184797287, "actor_loss": -22.07524057006836, "actor_mean_entropy": 6.098381114959717, "alpha_loss": 0.3772426507472992, "alpha_value": 0.07012457982526171, "duration": 69.08968186378479, "step": 7250}
{"episode_reward": 253.06525228869657, "episode": 30.0, "critic_loss": 9.58466795539856, "critic_target_Q_variance_m=2": 140.33342782592774, "critic_Q1_variance_k=2": 0.21654943880438804, "critic_Q2_variance_k=2": 0.21488659265637397, "actor_loss": -22.84659390258789, "actor_mean_entropy": 6.040938640594482, "alpha_loss": 0.3417635282278061, "alpha_value": 0.06954151955522055, "duration": 69.3866376876831, "step": 7500}
{"episode_reward": 160.44192698991793, "episode": 31.0, "critic_loss": 10.78054306602478, "critic_target_Q_variance_m=2": 151.71260943603517, "critic_Q1_variance_k=2": 0.23524281451106072, "critic_Q2_variance_k=2": 0.23600553873181343, "actor_loss": -23.872527526855468, "actor_mean_entropy": 5.85646757888794, "alpha_loss": 0.32239017593860625, "alpha_value": 0.06899591802910574, "duration": 69.12133598327637, "step": 7750}
