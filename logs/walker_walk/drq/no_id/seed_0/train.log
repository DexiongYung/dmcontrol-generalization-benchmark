{"episode_reward": 0.0, "episode": 1.0, "duration": 2.574619770050049, "step": 250}
{"episode_reward": 51.702662558795076, "episode": 2.0, "duration": 0.4860415458679199, "step": 500}
{"episode_reward": 64.99570868557767, "episode": 3.0, "duration": 0.4863471984863281, "step": 750}
{"episode_reward": 57.68951042190992, "episode": 4.0, "duration": 0.48567938804626465, "step": 1000}
{"episode_reward": 51.742837732540245, "episode": 5.0, "critic_loss": 0.7323575560764086, "critic_target_Q_variance_m=2": 4.823404597993895, "critic_Q1_variance_k=2": 0.016782310605063095, "critic_Q2_variance_k=2": 0.01669816520537941, "actor_loss": -4.012406141149191, "actor_mean_entropy": 7.80790006138676, "alpha_loss": 0.8768431677937083, "alpha_value": 0.09475005243326481, "duration": 161.3674430847168, "step": 1250}
{"episode_reward": 61.93425687269602, "episode": 6.0, "critic_loss": 1.3501468646526336, "critic_target_Q_variance_m=2": 11.181064163208008, "critic_Q1_variance_k=2": 0.03297428795695305, "critic_Q2_variance_k=2": 0.03291625291109085, "actor_loss": -6.872135707855224, "actor_mean_entropy": 7.7555812606811525, "alpha_loss": 0.7301862163543701, "alpha_value": 0.08953933230162599, "duration": 29.888057470321655, "step": 1500}
{"episode_reward": 100.79698450686058, "episode": 7.0, "critic_loss": 1.2980965480804443, "critic_target_Q_variance_m=2": 12.403312435150147, "critic_Q1_variance_k=2": 0.03277660643681884, "critic_Q2_variance_k=2": 0.0326871945373714, "actor_loss": -7.219734870910645, "actor_mean_entropy": 7.559329154968261, "alpha_loss": 0.7197087774276734, "alpha_value": 0.08857882441254408, "duration": 29.94293999671936, "step": 1750}
{"episode_reward": 43.02782842874919, "episode": 8.0, "critic_loss": 1.6839602429866791, "critic_target_Q_variance_m=2": 14.342585544586182, "critic_Q1_variance_k=2": 0.04264868765324354, "critic_Q2_variance_k=2": 0.04234480944275856, "actor_loss": -7.722372409820557, "actor_mean_entropy": 7.501188838958741, "alpha_loss": 0.7027388978004455, "alpha_value": 0.08763108162468727, "duration": 30.108052015304565, "step": 2000}
{"episode_reward": 83.17904675429567, "episode": 9.0, "critic_loss": 1.6565165140628815, "critic_target_Q_variance_m=2": 15.715522525787353, "critic_Q1_variance_k=2": 0.04592702329903841, "critic_Q2_variance_k=2": 0.044989589393138886, "actor_loss": -8.022629177093506, "actor_mean_entropy": 7.464324420928955, "alpha_loss": 0.6994507694244385, "alpha_value": 0.0866737898253763, "duration": 30.08354425430298, "step": 2250}
{"episode_reward": 62.66284699985043, "episode": 10.0, "critic_loss": 1.9222958171367646, "critic_target_Q_variance_m=2": 17.815373207092286, "critic_Q1_variance_k=2": 0.048807274103164676, "critic_Q2_variance_k=2": 0.04873615476489067, "actor_loss": -8.487996658325196, "actor_mean_entropy": 7.457775802612304, "alpha_loss": 0.6946862573623658, "alpha_value": 0.08572882783499997, "duration": 29.979739904403687, "step": 2500}
{"episode_reward": 50.37078822455084, "episode": 11.0, "critic_loss": 1.6053353395462036, "critic_target_Q_variance_m=2": 19.82934703063965, "critic_Q1_variance_k=2": 0.04304242567718029, "critic_Q2_variance_k=2": 0.043186147280037404, "actor_loss": -8.953913520812987, "actor_mean_entropy": 7.463027305603028, "alpha_loss": 0.6822204446792602, "alpha_value": 0.08478299005842213, "duration": 30.346237897872925, "step": 2750}
{"episode_reward": 58.9208381147886, "episode": 12.0, "critic_loss": 1.7317270703315735, "critic_target_Q_variance_m=2": 22.226775009155272, "critic_Q1_variance_k=2": 0.04684781567007303, "critic_Q2_variance_k=2": 0.04695976773649454, "actor_loss": -9.444034233093262, "actor_mean_entropy": 7.423018016815186, "alpha_loss": 0.6798700461387635, "alpha_value": 0.08384512833697792, "duration": 46.05834674835205, "step": 3000}
{"episode_reward": 72.26699747781032, "episode": 13.0, "critic_loss": 1.8481951744556426, "critic_target_Q_variance_m=2": 25.6989029006958, "critic_Q1_variance_k=2": 0.047106922179460525, "critic_Q2_variance_k=2": 0.047143691457808015, "actor_loss": -10.078445533752442, "actor_mean_entropy": 7.438834377288819, "alpha_loss": 0.6771901063919067, "alpha_value": 0.08290517105926029, "duration": 49.71797561645508, "step": 3250}
{"episode_reward": 117.76591702079871, "episode": 14.0, "critic_loss": 1.659298777103424, "critic_target_Q_variance_m=2": 29.287610786437988, "critic_Q1_variance_k=2": 0.04407823646068573, "critic_Q2_variance_k=2": 0.04336460585147142, "actor_loss": -10.732652786254883, "actor_mean_entropy": 7.456868236541748, "alpha_loss": 0.6671114315986634, "alpha_value": 0.08197605690422934, "duration": 49.25931262969971, "step": 3500}
{"episode_reward": 77.68505568042136, "episode": 15.0, "critic_loss": 1.6528108894824982, "critic_target_Q_variance_m=2": 31.76162212371826, "critic_Q1_variance_k=2": 0.04198031873255968, "critic_Q2_variance_k=2": 0.04196213755011559, "actor_loss": -11.128102409362793, "actor_mean_entropy": 7.536587291717529, "alpha_loss": 0.6792220735549926, "alpha_value": 0.08103999057266861, "duration": 68.88039064407349, "step": 3750}
{"episode_reward": 72.30774361823718, "episode": 16.0, "critic_loss": 1.5362096517086028, "critic_target_Q_variance_m=2": 34.416265640258786, "critic_Q1_variance_k=2": 0.041027397476136686, "critic_Q2_variance_k=2": 0.040448326848447326, "actor_loss": -11.575610588073731, "actor_mean_entropy": 7.4464719696044925, "alpha_loss": 0.676877429485321, "alpha_value": 0.08010306754465356, "duration": 70.82735204696655, "step": 4000}
{"episode_reward": 114.14021995746221, "episode": 17.0, "critic_loss": 2.116055785894394, "critic_target_Q_variance_m=2": 39.77925163269043, "critic_Q1_variance_k=2": 0.04950906416028738, "critic_Q2_variance_k=2": 0.04943113578483462, "actor_loss": -12.377721832275391, "actor_mean_entropy": 7.485424121856689, "alpha_loss": 0.670094485282898, "alpha_value": 0.07917109404133557, "duration": 70.80829644203186, "step": 4250}
{"episode_reward": 164.1846924446946, "episode": 18.0, "critic_loss": 2.181547074317932, "critic_target_Q_variance_m=2": 44.49384893798828, "critic_Q1_variance_k=2": 0.05411539915949106, "critic_Q2_variance_k=2": 0.05403290202468634, "actor_loss": -13.032939453125, "actor_mean_entropy": 7.389372562408448, "alpha_loss": 0.6462588963508606, "alpha_value": 0.07826488126271026, "duration": 71.23028135299683, "step": 4500}
{"episode_reward": 112.03794743132747, "episode": 19.0, "critic_loss": 2.3217050604820253, "critic_target_Q_variance_m=2": 48.407107299804686, "critic_Q1_variance_k=2": 0.058561174780130384, "critic_Q2_variance_k=2": 0.0587504937723279, "actor_loss": -13.589716079711915, "actor_mean_entropy": 7.236460529327393, "alpha_loss": 0.6244368424415588, "alpha_value": 0.07738653497337403, "duration": 69.68216824531555, "step": 4750}
{"episode_reward": 137.91315698823496, "episode": 20.0, "critic_loss": 2.6448368186950684, "critic_target_Q_variance_m=2": 53.53638255310059, "critic_Q1_variance_k=2": 0.058739277079701425, "critic_Q2_variance_k=2": 0.05805923198908568, "actor_loss": -14.31633194732666, "actor_mean_entropy": 7.12843416595459, "alpha_loss": 0.597378080368042, "alpha_value": 0.0765472978145743, "duration": 69.76048994064331, "step": 5000}
{"episode_reward": 102.0397593515219, "episode": 21.0, "critic_loss": 2.898084952354431, "critic_target_Q_variance_m=2": 58.736183975219724, "critic_Q1_variance_k=2": 0.06388523524254561, "critic_Q2_variance_k=2": 0.06324300079792738, "actor_loss": -14.943040504455567, "actor_mean_entropy": 7.016613372802734, "alpha_loss": 0.5766230483055115, "alpha_value": 0.07573018033628065, "duration": 69.24894571304321, "step": 5250}
{"episode_reward": 190.88965410388155, "episode": 22.0, "critic_loss": 3.4552938385009764, "critic_target_Q_variance_m=2": 63.75447630310059, "critic_Q1_variance_k=2": 0.08090828435122967, "critic_Q2_variance_k=2": 0.07987956239283085, "actor_loss": -15.590609405517577, "actor_mean_entropy": 7.012264778137207, "alpha_loss": 0.5644267091751098, "alpha_value": 0.07493084704870948, "duration": 69.81883883476257, "step": 5500}
{"episode_reward": 138.68549105820168, "episode": 23.0, "critic_loss": 3.775247031211853, "critic_target_Q_variance_m=2": 70.67620536804199, "critic_Q1_variance_k=2": 0.08935753675550222, "critic_Q2_variance_k=2": 0.08830595630407333, "actor_loss": -16.307804000854492, "actor_mean_entropy": 6.884020446777344, "alpha_loss": 0.5408469445705414, "alpha_value": 0.07415365706921098, "duration": 69.66850519180298, "step": 5750}
{"episode_reward": 233.49083096245582, "episode": 24.0, "critic_loss": 3.9214105072021486, "critic_target_Q_variance_m=2": 78.21619390869141, "critic_Q1_variance_k=2": 0.09527005974948406, "critic_Q2_variance_k=2": 0.09405095686018466, "actor_loss": -17.14810011291504, "actor_mean_entropy": 6.74740270614624, "alpha_loss": 0.5113578922748566, "alpha_value": 0.07339902158806244, "duration": 70.16053700447083, "step": 6000}
{"episode_reward": 216.9128628888857, "episode": 25.0, "critic_loss": 4.890229990005493, "critic_target_Q_variance_m=2": 84.96210708618165, "critic_Q1_variance_k=2": 0.12045363794267178, "critic_Q2_variance_k=2": 0.11782081964612007, "actor_loss": -17.8625604095459, "actor_mean_entropy": 6.6269495429992675, "alpha_loss": 0.47464479064941406, "alpha_value": 0.07268884700339585, "duration": 69.58414721488953, "step": 6250}
{"episode_reward": 212.35279236427883, "episode": 26.0, "critic_loss": 5.967612274169922, "critic_target_Q_variance_m=2": 95.9068814086914, "critic_Q1_variance_k=2": 0.1457644415795803, "critic_Q2_variance_k=2": 0.1452672835290432, "actor_loss": -18.95951628112793, "actor_mean_entropy": 6.459163497924805, "alpha_loss": 0.44694807028770445, "alpha_value": 0.07201473209253538, "duration": 69.5944652557373, "step": 6500}
{"episode_reward": 249.81854417807847, "episode": 27.0, "critic_loss": 6.560062690734863, "critic_target_Q_variance_m=2": 105.3829345703125, "critic_Q1_variance_k=2": 0.1489090107381344, "critic_Q2_variance_k=2": 0.14770968307554722, "actor_loss": -19.828858383178712, "actor_mean_entropy": 6.275694076538086, "alpha_loss": 0.4281074376106262, "alpha_value": 0.07135677466813818, "duration": 69.39043712615967, "step": 6750}
{"episode_reward": 279.41711764475616, "episode": 28.0, "critic_loss": 7.8487710752487185, "critic_target_Q_variance_m=2": 118.8696838684082, "critic_Q1_variance_k=2": 0.17616103237867356, "critic_Q2_variance_k=2": 0.1736816467344761, "actor_loss": -21.07770608520508, "actor_mean_entropy": 6.29794178390503, "alpha_loss": 0.3917359802722931, "alpha_value": 0.07072592854885779, "duration": 69.85165095329285, "step": 7000}
{"episode_reward": 236.36458552851863, "episode": 29.0, "critic_loss": 8.353983403205872, "critic_target_Q_variance_m=2": 130.06215551757813, "critic_Q1_variance_k=2": 0.18963828828930854, "critic_Q2_variance_k=2": 0.1854526184797287, "actor_loss": -22.07524057006836, "actor_mean_entropy": 6.098381114959717, "alpha_loss": 0.3772426507472992, "alpha_value": 0.07012457982526171, "duration": 69.08968186378479, "step": 7250}
{"episode_reward": 253.06525228869657, "episode": 30.0, "critic_loss": 9.58466795539856, "critic_target_Q_variance_m=2": 140.33342782592774, "critic_Q1_variance_k=2": 0.21654943880438804, "critic_Q2_variance_k=2": 0.21488659265637397, "actor_loss": -22.84659390258789, "actor_mean_entropy": 6.040938640594482, "alpha_loss": 0.3417635282278061, "alpha_value": 0.06954151955522055, "duration": 69.3866376876831, "step": 7500}
{"episode_reward": 160.44192698991793, "episode": 31.0, "critic_loss": 10.78054306602478, "critic_target_Q_variance_m=2": 151.71260943603517, "critic_Q1_variance_k=2": 0.23524281451106072, "critic_Q2_variance_k=2": 0.23600553873181343, "actor_loss": -23.872527526855468, "actor_mean_entropy": 5.85646757888794, "alpha_loss": 0.32239017593860625, "alpha_value": 0.06899591802910574, "duration": 69.12133598327637, "step": 7750}
{"episode_reward": 182.74548537860764, "episode": 32.0, "critic_loss": 11.140025623321533, "critic_target_Q_variance_m=2": 164.96085430908204, "critic_Q1_variance_k=2": 0.23538946822285653, "critic_Q2_variance_k=2": 0.23425408291816713, "actor_loss": -24.878654022216796, "actor_mean_entropy": 5.768873168945312, "alpha_loss": 0.31066124749183655, "alpha_value": 0.06845304518394932, "duration": 69.1938693523407, "step": 8000}
{"episode_reward": 254.24546660852926, "episode": 33.0, "critic_loss": 11.992853107452392, "critic_target_Q_variance_m=2": 179.96073297119142, "critic_Q1_variance_k=2": 0.26782718461751936, "critic_Q2_variance_k=2": 0.26197148725390434, "actor_loss": -26.000951644897462, "actor_mean_entropy": 5.540876121520996, "alpha_loss": 0.3016444823741913, "alpha_value": 0.06792791954556077, "duration": 69.37389326095581, "step": 8250}
{"episode_reward": 122.12146106371203, "episode": 34.0, "critic_loss": 12.891728189468385, "critic_target_Q_variance_m=2": 189.9511537475586, "critic_Q1_variance_k=2": 0.2777854614853859, "critic_Q2_variance_k=2": 0.27457212352752686, "actor_loss": -26.80029132080078, "actor_mean_entropy": 5.414959350585938, "alpha_loss": 0.2942012288570404, "alpha_value": 0.06738190000865243, "duration": 69.298166513443, "step": 8500}
{"episode_reward": 195.62754925989248, "episode": 35.0, "critic_loss": 12.94591056060791, "critic_target_Q_variance_m=2": 205.49287213134767, "critic_Q1_variance_k=2": 0.2826185176968575, "critic_Q2_variance_k=2": 0.27608001935482024, "actor_loss": -27.88869842529297, "actor_mean_entropy": 5.403457344055176, "alpha_loss": 0.2679068475961685, "alpha_value": 0.06685264570962395, "duration": 69.4532859325409, "step": 8750}
{"episode_reward": 291.16898940661144, "episode": 36.0, "critic_loss": 11.981336980819702, "critic_target_Q_variance_m=2": 224.15101495361327, "critic_Q1_variance_k=2": 0.27553180304169655, "critic_Q2_variance_k=2": 0.2672483639419079, "actor_loss": -29.218793518066406, "actor_mean_entropy": 5.219211326599121, "alpha_loss": 0.24243199956417083, "alpha_value": 0.06635957750839029, "duration": 69.36997437477112, "step": 9000}
{"episode_reward": 310.1355947299238, "episode": 37.0, "critic_loss": 14.036782876968385, "critic_target_Q_variance_m=2": 243.0772799682617, "critic_Q1_variance_k=2": 0.3103870849013329, "critic_Q2_variance_k=2": 0.30581091183424, "actor_loss": -30.56784161376953, "actor_mean_entropy": 5.269250522613525, "alpha_loss": 0.2265826575756073, "alpha_value": 0.06590008494345627, "duration": 69.28580951690674, "step": 9250}
{"episode_reward": 263.8411784819716, "episode": 38.0, "critic_loss": 12.485887371063232, "critic_target_Q_variance_m=2": 260.5053162231445, "critic_Q1_variance_k=2": 0.27766385209560396, "critic_Q2_variance_k=2": 0.274186565220356, "actor_loss": -31.856999084472655, "actor_mean_entropy": 5.247594844818115, "alpha_loss": 0.19543744218349457, "alpha_value": 0.06546483813545069, "duration": 69.82747960090637, "step": 9500}
{"episode_reward": 224.47097937076853, "episode": 39.0, "critic_loss": 12.906799221038819, "critic_target_Q_variance_m=2": 280.61903338623046, "critic_Q1_variance_k=2": 0.3013163408637047, "critic_Q2_variance_k=2": 0.30076426070928575, "actor_loss": -33.08793162536621, "actor_mean_entropy": 5.209946739196777, "alpha_loss": 0.19477488058805464, "alpha_value": 0.06504684200873721, "duration": 69.44399189949036, "step": 9750}
{"episode_reward": 289.3538084878052, "episode": 40.0, "critic_loss": 11.94375133895874, "critic_target_Q_variance_m=2": 300.259650390625, "critic_Q1_variance_k=2": 0.2741472516059876, "critic_Q2_variance_k=2": 0.27343454778194426, "actor_loss": -34.33838409423828, "actor_mean_entropy": 5.143072715759278, "alpha_loss": 0.18749123644828797, "alpha_value": 0.06461624998659396, "duration": 69.43733716011047, "step": 10000}
{"episode_reward": 212.66643420248766, "episode": 41.0, "critic_loss": 11.409371812820435, "critic_target_Q_variance_m=2": 318.7342984619141, "critic_Q1_variance_k=2": 0.2651349739730358, "critic_Q2_variance_k=2": 0.2681739167571068, "actor_loss": -35.4082064819336, "actor_mean_entropy": 5.168511932373047, "alpha_loss": 0.18465173989534378, "alpha_value": 0.06418879745706506, "duration": 72.90383005142212, "step": 10250}
{"episode_reward": 294.7323193433985, "episode": 42.0, "critic_loss": 11.704160638809205, "critic_target_Q_variance_m=2": 337.59896362304687, "critic_Q1_variance_k=2": 0.2719824661314487, "critic_Q2_variance_k=2": 0.2696018881499767, "actor_loss": -36.52139758300781, "actor_mean_entropy": 5.117799816131591, "alpha_loss": 0.2051797478199005, "alpha_value": 0.06372365245204449, "duration": 68.88336730003357, "step": 10500}
{"episode_reward": 242.56765184848467, "episode": 43.0, "critic_loss": 11.392795894622802, "critic_target_Q_variance_m=2": 357.628921875, "critic_Q1_variance_k=2": 0.2627958561778069, "critic_Q2_variance_k=2": 0.2646101301908493, "actor_loss": -37.52473992919922, "actor_mean_entropy": 5.15935062789917, "alpha_loss": 0.2145217844247818, "alpha_value": 0.06319569312125785, "duration": 69.33571219444275, "step": 10750}
{"episode_reward": 169.05275807762777, "episode": 44.0, "critic_loss": 10.869499555587769, "critic_target_Q_variance_m=2": 376.99579113769533, "critic_Q1_variance_k=2": 0.2738641420006752, "critic_Q2_variance_k=2": 0.27516557079553605, "actor_loss": -38.589991790771485, "actor_mean_entropy": 5.16892268371582, "alpha_loss": 0.21135142731666565, "alpha_value": 0.0626546470753185, "duration": 70.38641452789307, "step": 11000}
{"episode_reward": 359.19178661926225, "episode": 45.0, "critic_loss": 11.471987174987794, "critic_target_Q_variance_m=2": 400.37346130371094, "critic_Q1_variance_k=2": 0.2741285435557365, "critic_Q2_variance_k=2": 0.27343627524375913, "actor_loss": -39.81873434448242, "actor_mean_entropy": 5.068306339263916, "alpha_loss": 0.19756969487667084, "alpha_value": 0.0621204437440845, "duration": 69.14176964759827, "step": 11250}
{"episode_reward": 339.63554698102826, "episode": 46.0, "critic_loss": 11.679825197219849, "critic_target_Q_variance_m=2": 420.4869285888672, "critic_Q1_variance_k=2": 0.2876349324584007, "critic_Q2_variance_k=2": 0.2841608951687813, "actor_loss": -40.67068167114258, "actor_mean_entropy": 5.149999668121338, "alpha_loss": 0.19619611608982085, "alpha_value": 0.06159854155652211, "duration": 69.29158401489258, "step": 11500}
{"episode_reward": 264.3810868045588, "episode": 47.0, "critic_loss": 12.154230449676513, "critic_target_Q_variance_m=2": 441.94051733398436, "critic_Q1_variance_k=2": 0.2902411554455757, "critic_Q2_variance_k=2": 0.28647428554296495, "actor_loss": -41.85061215209961, "actor_mean_entropy": 5.082126491546631, "alpha_loss": 0.20686434090137482, "alpha_value": 0.06104471349367367, "duration": 68.85101675987244, "step": 11750}
{"episode_reward": 386.74535193716514, "episode": 48.0, "critic_loss": 11.338696180343629, "critic_target_Q_variance_m=2": 463.9487568359375, "critic_Q1_variance_k=2": 0.28949304032325746, "critic_Q2_variance_k=2": 0.29167493718862536, "actor_loss": -42.80870092773438, "actor_mean_entropy": 5.151554355621338, "alpha_loss": 0.2024007740020752, "alpha_value": 0.06046825547515858, "duration": 69.32897734642029, "step": 12000}
{"episode_reward": 362.0327589215896, "episode": 49.0, "critic_loss": 11.020247396469117, "critic_target_Q_variance_m=2": 489.71691186523435, "critic_Q1_variance_k=2": 0.28149352318048476, "critic_Q2_variance_k=2": 0.27972016561031343, "actor_loss": -44.04775637817383, "actor_mean_entropy": 5.0835299415588375, "alpha_loss": 0.18605124652385713, "alpha_value": 0.05992190878691033, "duration": 69.48025012016296, "step": 12250}
{"episode_reward": 340.3830941581087, "episode": 50.0, "critic_loss": 11.463800338745116, "critic_target_Q_variance_m=2": 515.2712956542969, "critic_Q1_variance_k=2": 0.28879086625576017, "critic_Q2_variance_k=2": 0.2923066902160645, "actor_loss": -45.22093936157226, "actor_mean_entropy": 5.011534404754639, "alpha_loss": 0.17663209199905394, "alpha_value": 0.05939641598998629, "duration": 69.18621850013733, "step": 12500}
{"episode_reward": 357.3528776431969, "episode": 51.0, "critic_loss": 11.74069896888733, "critic_target_Q_variance_m=2": 539.5083892822265, "critic_Q1_variance_k=2": 0.29863059568405154, "critic_Q2_variance_k=2": 0.297134839951992, "actor_loss": -46.32986511230469, "actor_mean_entropy": 5.0311294975280765, "alpha_loss": 0.16098804956674576, "alpha_value": 0.058898086635193095, "duration": 69.35638499259949, "step": 12750}
{"episode_reward": 314.0230894556643, "episode": 52.0, "critic_loss": 12.027890062332153, "critic_target_Q_variance_m=2": 563.3979455566406, "critic_Q1_variance_k=2": 0.2948656298518181, "critic_Q2_variance_k=2": 0.2913995556235313, "actor_loss": -47.24193069458008, "actor_mean_entropy": 5.005510540008545, "alpha_loss": 0.15950431650876998, "alpha_value": 0.058408498678422335, "duration": 69.2758162021637, "step": 13000}
{"episode_reward": 313.1405721155332, "episode": 53.0, "critic_loss": 12.828341960906982, "critic_target_Q_variance_m=2": 588.4531411132813, "critic_Q1_variance_k=2": 0.3151669598817825, "critic_Q2_variance_k=2": 0.30785554856061936, "actor_loss": -48.372366760253904, "actor_mean_entropy": 5.005871925354004, "alpha_loss": 0.1627188692688942, "alpha_value": 0.057907765037800756, "duration": 69.1070396900177, "step": 13250}
{"episode_reward": 335.22603635605617, "episode": 54.0, "critic_loss": 11.020108879089355, "critic_target_Q_variance_m=2": 614.9009052734375, "critic_Q1_variance_k=2": 0.28278728425502775, "critic_Q2_variance_k=2": 0.2786035869717598, "actor_loss": -49.39968338012695, "actor_mean_entropy": 4.990624584197998, "alpha_loss": 0.16165446996688843, "alpha_value": 0.057390415119692305, "duration": 68.93735933303833, "step": 13500}
{"episode_reward": 403.2552182674575, "episode": 55.0, "critic_loss": 12.159025215148926, "critic_target_Q_variance_m=2": 641.1799562988281, "critic_Q1_variance_k=2": 0.30025473898649213, "critic_Q2_variance_k=2": 0.2986412393450737, "actor_loss": -50.43161096191406, "actor_mean_entropy": 4.88868493270874, "alpha_loss": 0.14580616688728332, "alpha_value": 0.05689837798086294, "duration": 67.22067952156067, "step": 13750}
{"episode_reward": 330.0828895535496, "episode": 56.0, "critic_loss": 12.542081930160522, "critic_target_Q_variance_m=2": 666.1162963867188, "critic_Q1_variance_k=2": 0.3182653722167015, "critic_Q2_variance_k=2": 0.3154007875323296, "actor_loss": -51.47729183959961, "actor_mean_entropy": 4.86459489440918, "alpha_loss": 0.1483683221936226, "alpha_value": 0.05640166673563696, "duration": 69.07484006881714, "step": 14000}
{"episode_reward": 393.220639385556, "episode": 57.0, "critic_loss": 13.164641445159912, "critic_target_Q_variance_m=2": 697.8699255371093, "critic_Q1_variance_k=2": 0.328394097507, "critic_Q2_variance_k=2": 0.32323509800434114, "actor_loss": -52.65466781616211, "actor_mean_entropy": 4.818955059051514, "alpha_loss": 0.14005351275205613, "alpha_value": 0.055904304798190065, "duration": 69.16491270065308, "step": 14250}
{"episode_reward": 389.18224352246244, "episode": 58.0, "critic_loss": 13.155953990936279, "critic_target_Q_variance_m=2": 725.6584018554687, "critic_Q1_variance_k=2": 0.33204146701097487, "critic_Q2_variance_k=2": 0.32910551273822786, "actor_loss": -53.83973681640625, "actor_mean_entropy": 4.723432926177979, "alpha_loss": 0.11644653964042663, "alpha_value": 0.05546540961676229, "duration": 69.31125831604004, "step": 14500}
{"episode_reward": 374.59753541829207, "episode": 59.0, "critic_loss": 12.908516983032227, "critic_target_Q_variance_m=2": 758.0982407226562, "critic_Q1_variance_k=2": 0.31697463542222976, "critic_Q2_variance_k=2": 0.31543969017267226, "actor_loss": -54.88530908203125, "actor_mean_entropy": 4.735941207885742, "alpha_loss": 0.11679747331142426, "alpha_value": 0.05504662970115729, "duration": 69.37451457977295, "step": 14750}
{"episode_reward": 383.7305076842164, "episode": 60.0, "critic_loss": 12.647737852096558, "critic_target_Q_variance_m=2": 787.5557946777344, "critic_Q1_variance_k=2": 0.3124149598479271, "critic_Q2_variance_k=2": 0.3113956771492958, "actor_loss": -56.12337759399414, "actor_mean_entropy": 4.789560947418213, "alpha_loss": 0.10848747563362121, "alpha_value": 0.05462482801793901, "duration": 69.07003283500671, "step": 15000}
{"episode_reward": 301.99780499828273, "episode": 61.0, "critic_loss": 12.99973338508606, "critic_target_Q_variance_m=2": 820.0015500488281, "critic_Q1_variance_k=2": 0.3108036479949951, "critic_Q2_variance_k=2": 0.30851595145463945, "actor_loss": -57.23737985229492, "actor_mean_entropy": 4.810979812622071, "alpha_loss": 0.10136048579216003, "alpha_value": 0.05423692100135478, "duration": 69.23601603507996, "step": 15250}
{"episode_reward": 348.9009375860001, "episode": 62.0, "critic_loss": 12.113556348800659, "critic_target_Q_variance_m=2": 853.069080078125, "critic_Q1_variance_k=2": 0.29767604529857633, "critic_Q2_variance_k=2": 0.297923945069313, "actor_loss": -58.35697848510742, "actor_mean_entropy": 4.650811773300171, "alpha_loss": 0.10309997786581516, "alpha_value": 0.05383017398201647, "duration": 69.1569550037384, "step": 15500}
{"episode_reward": 386.3399320455924, "episode": 63.0, "critic_loss": 12.105788518905639, "critic_target_Q_variance_m=2": 885.5474255371093, "critic_Q1_variance_k=2": 0.29742994117736815, "critic_Q2_variance_k=2": 0.2970004702806473, "actor_loss": -59.496395111083984, "actor_mean_entropy": 4.745229206085205, "alpha_loss": 0.10193213924765587, "alpha_value": 0.053409512966346225, "duration": 68.97674489021301, "step": 15750}
{"episode_reward": 297.0325456478534, "episode": 64.0, "critic_loss": 11.739296407699586, "critic_target_Q_variance_m=2": 916.7683381347656, "critic_Q1_variance_k=2": 0.28653752034902574, "critic_Q2_variance_k=2": 0.2896938722729683, "actor_loss": -60.46786245727539, "actor_mean_entropy": 4.781859001159668, "alpha_loss": 0.10669715337455273, "alpha_value": 0.052985566680458916, "duration": 69.21977806091309, "step": 16000}
{"episode_reward": 332.01479414032644, "episode": 65.0, "critic_loss": 12.301766910552978, "critic_target_Q_variance_m=2": 947.5329106445313, "critic_Q1_variance_k=2": 0.3043482428193092, "critic_Q2_variance_k=2": 0.30299961614608767, "actor_loss": -61.56598709106445, "actor_mean_entropy": 4.741942058563232, "alpha_loss": 0.09648661375045776, "alpha_value": 0.05253430435743709, "duration": 69.18643832206726, "step": 16250}
{"episode_reward": 455.8716754018766, "episode": 66.0, "critic_loss": 11.966019365310668, "critic_target_Q_variance_m=2": 982.1905522460937, "critic_Q1_variance_k=2": 0.2989389505982399, "critic_Q2_variance_k=2": 0.297722301363945, "actor_loss": -62.72759225463867, "actor_mean_entropy": 4.661133060455322, "alpha_loss": 0.09970462877303361, "alpha_value": 0.05210148804306624, "duration": 68.92280888557434, "step": 16500}
{"episode_reward": 396.35776576975536, "episode": 67.0, "critic_loss": 12.179909952163696, "critic_target_Q_variance_m=2": 1020.5134868164063, "critic_Q1_variance_k=2": 0.2956738825440407, "critic_Q2_variance_k=2": 0.293263143658638, "actor_loss": -63.90376934814453, "actor_mean_entropy": 4.6322456741333005, "alpha_loss": 0.09776752272248268, "alpha_value": 0.051651566250641046, "duration": 68.99005270004272, "step": 16750}
{"episode_reward": 417.38000249441154, "episode": 68.0, "critic_loss": 12.197734788894653, "critic_target_Q_variance_m=2": 1051.735927001953, "critic_Q1_variance_k=2": 0.3064216328263283, "critic_Q2_variance_k=2": 0.30836383402347567, "actor_loss": -64.79597280883789, "actor_mean_entropy": 4.598445596694947, "alpha_loss": 0.09514319922029972, "alpha_value": 0.051214114074761063, "duration": 69.46749114990234, "step": 17000}
{"episode_reward": 391.1722967556522, "episode": 69.0, "critic_loss": 12.798522117614747, "critic_target_Q_variance_m=2": 1087.035138671875, "critic_Q1_variance_k=2": 0.303288590490818, "critic_Q2_variance_k=2": 0.3105017495751381, "actor_loss": -65.91894244384765, "actor_mean_entropy": 4.620008350372315, "alpha_loss": 0.08844333939254284, "alpha_value": 0.05076794240881274, "duration": 69.54013013839722, "step": 17250}
{"episode_reward": 320.2786034895107, "episode": 70.0, "critic_loss": 12.45216003036499, "critic_target_Q_variance_m=2": 1120.0245224609375, "critic_Q1_variance_k=2": 0.29575679790973664, "critic_Q2_variance_k=2": 0.29717565995454787, "actor_loss": -66.92434588623047, "actor_mean_entropy": 4.624298618316651, "alpha_loss": 0.10905647906661034, "alpha_value": 0.050314541652873565, "duration": 69.08781147003174, "step": 17500}
{"episode_reward": 390.0225957966471, "episode": 71.0, "critic_loss": 12.796583282470703, "critic_target_Q_variance_m=2": 1155.3558544921875, "critic_Q1_variance_k=2": 0.30292245811223983, "critic_Q2_variance_k=2": 0.3054985608458519, "actor_loss": -67.96954736328125, "actor_mean_entropy": 4.484006908416748, "alpha_loss": 0.09732584995031357, "alpha_value": 0.04980736480815757, "duration": 68.94994163513184, "step": 17750}
{"episode_reward": 367.37937255727985, "episode": 72.0, "critic_loss": 12.523926149368286, "critic_target_Q_variance_m=2": 1191.1716342773439, "critic_Q1_variance_k=2": 0.3209352468252182, "critic_Q2_variance_k=2": 0.32103704917430875, "actor_loss": -69.07442791748046, "actor_mean_entropy": 4.441240859985352, "alpha_loss": 0.08595582386851311, "alpha_value": 0.04934911504712821, "duration": 69.07965183258057, "step": 18000}
{"episode_reward": 467.91902452684076, "episode": 73.0, "critic_loss": 12.517281284332276, "critic_target_Q_variance_m=2": 1229.888451171875, "critic_Q1_variance_k=2": 0.2997282050251961, "critic_Q2_variance_k=2": 0.3047322754263878, "actor_loss": -70.23975653076172, "actor_mean_entropy": 4.3961469860076905, "alpha_loss": 0.08367447546124458, "alpha_value": 0.04891906128897766, "duration": 69.21414566040039, "step": 18250}
{"episode_reward": 394.1579328996951, "episode": 74.0, "critic_loss": 12.70987985610962, "critic_target_Q_variance_m=2": 1263.8741313476562, "critic_Q1_variance_k=2": 0.30160026741027834, "critic_Q2_variance_k=2": 0.2984276583790779, "actor_loss": -71.2151923828125, "actor_mean_entropy": 4.49612248802185, "alpha_loss": 0.07330366592109204, "alpha_value": 0.04852109277595939, "duration": 69.47314882278442, "step": 18500}
{"episode_reward": 439.0239189339102, "episode": 75.0, "critic_loss": 12.031740398406983, "critic_target_Q_variance_m=2": 1306.205634765625, "critic_Q1_variance_k=2": 0.3029718430042267, "critic_Q2_variance_k=2": 0.3020998477935791, "actor_loss": -72.33598944091797, "actor_mean_entropy": 4.38862979888916, "alpha_loss": 0.0828883820027113, "alpha_value": 0.04810999313672354, "duration": 69.1397922039032, "step": 18750}
{"episode_reward": 472.0848889203231, "episode": 76.0, "critic_loss": 12.344316318511963, "critic_target_Q_variance_m=2": 1342.348376953125, "critic_Q1_variance_k=2": 0.31222421252727506, "critic_Q2_variance_k=2": 0.31001549285650254, "actor_loss": -73.35546899414062, "actor_mean_entropy": 4.4827131652832035, "alpha_loss": 0.07682190398871899, "alpha_value": 0.04767665462162068, "duration": 69.07152509689331, "step": 19000}
{"episode_reward": 445.5385581437622, "episode": 77.0, "critic_loss": 11.928258127212525, "critic_target_Q_variance_m=2": 1382.8382524414062, "critic_Q1_variance_k=2": 0.3071460200548172, "critic_Q2_variance_k=2": 0.3084823306798935, "actor_loss": -74.50944403076171, "actor_mean_entropy": 4.411966590881348, "alpha_loss": 0.07835416747629642, "alpha_value": 0.0472445473277071, "duration": 69.11545538902283, "step": 19250}
{"episode_reward": 400.80113306752594, "episode": 78.0, "critic_loss": 12.076732303619385, "critic_target_Q_variance_m=2": 1423.826759765625, "critic_Q1_variance_k=2": 0.298871268928051, "critic_Q2_variance_k=2": 0.3034840240478516, "actor_loss": -75.5740322265625, "actor_mean_entropy": 4.412090703964234, "alpha_loss": 0.07342288807034493, "alpha_value": 0.04681153278069453, "duration": 69.32883071899414, "step": 19500}
{"episode_reward": 437.21194231263513, "episode": 79.0, "critic_loss": 12.494432075500487, "critic_target_Q_variance_m=2": 1459.2482465820312, "critic_Q1_variance_k=2": 0.3157652129530907, "critic_Q2_variance_k=2": 0.3155414348244667, "actor_loss": -76.53124389648437, "actor_mean_entropy": 4.233365440368653, "alpha_loss": 0.07150113918632268, "alpha_value": 0.046406850103083264, "duration": 69.26276898384094, "step": 19750}
{"episode_reward": 436.3266334690719, "episode": 80.0, "critic_loss": 13.616258476257324, "critic_target_Q_variance_m=2": 1502.4789262695313, "critic_Q1_variance_k=2": 0.31874897998571394, "critic_Q2_variance_k=2": 0.3245232720375061, "actor_loss": -77.62575708007813, "actor_mean_entropy": 4.196770467758179, "alpha_loss": 0.06800767302513122, "alpha_value": 0.04600867187012104, "duration": 69.00707387924194, "step": 20000}
{"episode_reward": 410.13601741063394, "episode": 81.0, "critic_loss": 13.485582565307617, "critic_target_Q_variance_m=2": 1542.4916298828125, "critic_Q1_variance_k=2": 0.3320730402469635, "critic_Q2_variance_k=2": 0.33108129090070726, "actor_loss": -78.64506964111328, "actor_mean_entropy": 4.235559156417847, "alpha_loss": 0.06686860120296478, "alpha_value": 0.04561184426512391, "duration": 72.65254735946655, "step": 20250}
{"episode_reward": 413.3251142775736, "episode": 82.0, "critic_loss": 14.104670413970947, "critic_target_Q_variance_m=2": 1580.4950600585937, "critic_Q1_variance_k=2": 0.3353570104837418, "critic_Q2_variance_k=2": 0.33400986701250074, "actor_loss": -79.61425476074218, "actor_mean_entropy": 4.120285406112671, "alpha_loss": 0.05845195046067238, "alpha_value": 0.0452077439693709, "duration": 69.44902181625366, "step": 20500}
{"episode_reward": 424.0846908749603, "episode": 83.0, "critic_loss": 13.067763149261475, "critic_target_Q_variance_m=2": 1624.36300390625, "critic_Q1_variance_k=2": 0.33421635305881503, "critic_Q2_variance_k=2": 0.3363469156622887, "actor_loss": -80.7779473876953, "actor_mean_entropy": 4.0440321521759035, "alpha_loss": 0.05620975599065423, "alpha_value": 0.044862164158148914, "duration": 69.89394950866699, "step": 20750}
{"episode_reward": 455.6541706822959, "episode": 84.0, "critic_loss": 13.925646091461182, "critic_target_Q_variance_m=2": 1666.8973393554688, "critic_Q1_variance_k=2": 0.3411023833155632, "critic_Q2_variance_k=2": 0.33966021990776063, "actor_loss": -81.76759088134766, "actor_mean_entropy": 4.069439939498901, "alpha_loss": 0.05428336937725544, "alpha_value": 0.044512566281033956, "duration": 68.8388774394989, "step": 21000}
{"episode_reward": 416.860688191837, "episode": 85.0, "critic_loss": 13.516313304901123, "critic_target_Q_variance_m=2": 1713.4224047851562, "critic_Q1_variance_k=2": 0.32693467181921004, "critic_Q2_variance_k=2": 0.3271665866374969, "actor_loss": -82.87394635009765, "actor_mean_entropy": 4.1039969367980955, "alpha_loss": 0.05124693773686886, "alpha_value": 0.04416981159009619, "duration": 69.01707077026367, "step": 21250}
{"episode_reward": 363.8994487782739, "episode": 86.0, "critic_loss": 13.450000919342042, "critic_target_Q_variance_m=2": 1761.649814453125, "critic_Q1_variance_k=2": 0.34394606155157087, "critic_Q2_variance_k=2": 0.34800583219528197, "actor_loss": -84.057970703125, "actor_mean_entropy": 3.950678232192993, "alpha_loss": 0.05077071753330529, "alpha_value": 0.04383014848863342, "duration": 69.25892496109009, "step": 21500}
{"episode_reward": 450.29776738529864, "episode": 87.0, "critic_loss": 13.784422878265381, "critic_target_Q_variance_m=2": 1805.5118857421876, "critic_Q1_variance_k=2": 0.33305331075191497, "critic_Q2_variance_k=2": 0.3344627894163132, "actor_loss": -85.10892205810546, "actor_mean_entropy": 4.001519220352173, "alpha_loss": 0.05341536593809724, "alpha_value": 0.043466262405407796, "duration": 69.26079654693604, "step": 21750}
{"episode_reward": 449.6462286097741, "episode": 88.0, "critic_loss": 14.117997230529785, "critic_target_Q_variance_m=2": 1845.8177563476563, "critic_Q1_variance_k=2": 0.3391907376050949, "critic_Q2_variance_k=2": 0.3381478545665741, "actor_loss": -86.03696270751954, "actor_mean_entropy": 4.081716896057129, "alpha_loss": 0.045587064497172834, "alpha_value": 0.043112670591195404, "duration": 69.41306114196777, "step": 22000}
{"episode_reward": 473.43737727258593, "episode": 89.0, "critic_loss": 14.144609046936035, "critic_target_Q_variance_m=2": 1895.4443833007813, "critic_Q1_variance_k=2": 0.3445188791155815, "critic_Q2_variance_k=2": 0.3445661083459854, "actor_loss": -87.22964825439453, "actor_mean_entropy": 3.988846523284912, "alpha_loss": 0.035420872524380684, "alpha_value": 0.042813163698320555, "duration": 68.84437131881714, "step": 22250}
{"episode_reward": 457.3180905276412, "episode": 90.0, "critic_loss": 14.623686054229736, "critic_target_Q_variance_m=2": 1939.2842255859375, "critic_Q1_variance_k=2": 0.34723250871896744, "critic_Q2_variance_k=2": 0.3501688658595085, "actor_loss": -88.2577339477539, "actor_mean_entropy": 4.06300287437439, "alpha_loss": 0.02919973542355001, "alpha_value": 0.04256395442177017, "duration": 68.91680574417114, "step": 22500}
{"episode_reward": 466.75244632284085, "episode": 91.0, "critic_loss": 14.532738899230957, "critic_target_Q_variance_m=2": 1984.1545073242187, "critic_Q1_variance_k=2": 0.3580180209875107, "critic_Q2_variance_k=2": 0.36171362972259524, "actor_loss": -89.10630462646485, "actor_mean_entropy": 4.0474270191192625, "alpha_loss": 0.039914552818983796, "alpha_value": 0.04231517581899654, "duration": 69.13828754425049, "step": 22750}
{"episode_reward": 457.4162537477577, "episode": 92.0, "critic_loss": 14.622807365417481, "critic_target_Q_variance_m=2": 2034.6054970703126, "critic_Q1_variance_k=2": 0.36094097125530245, "critic_Q2_variance_k=2": 0.3635348881483078, "actor_loss": -90.4725835571289, "actor_mean_entropy": 4.02172859954834, "alpha_loss": 0.02081275392882526, "alpha_value": 0.04205656496432614, "duration": 68.90528345108032, "step": 23000}
{"episode_reward": 521.9738190710003, "episode": 93.0, "critic_loss": 14.613576789855957, "critic_target_Q_variance_m=2": 2083.4807939453126, "critic_Q1_variance_k=2": 0.3520460168123245, "critic_Q2_variance_k=2": 0.3492635253071785, "actor_loss": -91.50773388671875, "actor_mean_entropy": 4.02807626914978, "alpha_loss": 0.03567153287492692, "alpha_value": 0.04183724361689753, "duration": 69.91759920120239, "step": 23250}
{"episode_reward": 508.67111231008045, "episode": 94.0, "critic_loss": 13.9425248336792, "critic_target_Q_variance_m=2": 2128.80740234375, "critic_Q1_variance_k=2": 0.34200541108846666, "critic_Q2_variance_k=2": 0.33960429042577744, "actor_loss": -92.49857446289063, "actor_mean_entropy": 3.9737468433380125, "alpha_loss": 0.021161896108649672, "alpha_value": 0.04159007442606762, "duration": 68.79406952857971, "step": 23500}
{"episode_reward": 460.41124019925337, "episode": 95.0, "critic_loss": 14.096062046051026, "critic_target_Q_variance_m=2": 2175.495697265625, "critic_Q1_variance_k=2": 0.34475719469785693, "critic_Q2_variance_k=2": 0.33952650141716, "actor_loss": -93.42498944091797, "actor_mean_entropy": 3.991167444229126, "alpha_loss": 0.028648955933749675, "alpha_value": 0.04135770138023692, "duration": 67.77534627914429, "step": 23750}
{"episode_reward": 435.0281722123946, "episode": 96.0, "critic_loss": 14.338567401885987, "critic_target_Q_variance_m=2": 2225.6730458984375, "critic_Q1_variance_k=2": 0.3393400317430496, "critic_Q2_variance_k=2": 0.3380436187386513, "actor_loss": -94.57976123046875, "actor_mean_entropy": 3.9187237243652344, "alpha_loss": 0.016803217681124808, "alpha_value": 0.04115493824485709, "duration": 69.13471174240112, "step": 24000}
{"episode_reward": 356.43009932427844, "episode": 97.0, "critic_loss": 14.250718309402465, "critic_target_Q_variance_m=2": 2273.628494140625, "critic_Q1_variance_k=2": 0.34324246895313265, "critic_Q2_variance_k=2": 0.3430011041164398, "actor_loss": -95.65791839599609, "actor_mean_entropy": 3.9247394065856933, "alpha_loss": 0.01969065008405596, "alpha_value": 0.04096599306861985, "duration": 69.26376080513, "step": 24250}
{"episode_reward": 466.44177454198064, "episode": 98.0, "critic_loss": 14.592891429901123, "critic_target_Q_variance_m=2": 2320.043728515625, "critic_Q1_variance_k=2": 0.3498616238832474, "critic_Q2_variance_k=2": 0.3530008129477501, "actor_loss": -96.54432080078125, "actor_mean_entropy": 3.8310232486724853, "alpha_loss": 0.024135957801714538, "alpha_value": 0.040750592054630906, "duration": 68.8519241809845, "step": 24500}
{"episode_reward": 453.97392867176256, "episode": 99.0, "critic_loss": 14.232807640075684, "critic_target_Q_variance_m=2": 2375.407783203125, "critic_Q1_variance_k=2": 0.34895212763547895, "critic_Q2_variance_k=2": 0.3421965813040733, "actor_loss": -97.73537963867187, "actor_mean_entropy": 3.8287185401916504, "alpha_loss": 0.021677402628585696, "alpha_value": 0.04048791610528191, "duration": 69.07162523269653, "step": 24750}
{"episode_reward": 464.2908667120426, "episode": 100.0, "critic_loss": 14.11863627243042, "critic_target_Q_variance_m=2": 2419.071435546875, "critic_Q1_variance_k=2": 0.3427998375892639, "critic_Q2_variance_k=2": 0.3413131226301193, "actor_loss": -98.5962109375, "actor_mean_entropy": 3.9633530673980712, "alpha_loss": 0.022858698464930056, "alpha_value": 0.04023879674356383, "duration": 69.25015997886658, "step": 25000}
{"episode_reward": 455.3171462520156, "episode": 101.0, "critic_loss": 14.571948757171631, "critic_target_Q_variance_m=2": 2468.648796875, "critic_Q1_variance_k=2": 0.3501981541514397, "critic_Q2_variance_k=2": 0.3509086211323738, "actor_loss": -99.56531939697265, "actor_mean_entropy": 3.920788909912109, "alpha_loss": 0.01662714799493551, "alpha_value": 0.040042862115728384, "duration": 69.1639232635498, "step": 25250}
{"episode_reward": 529.5509185345971, "episode": 102.0, "critic_loss": 14.227067451477051, "critic_target_Q_variance_m=2": 2516.07687109375, "critic_Q1_variance_k=2": 0.3480812438726425, "critic_Q2_variance_k=2": 0.3509136294126511, "actor_loss": -100.56730480957032, "actor_mean_entropy": 3.9131999282836913, "alpha_loss": 0.014820501612499357, "alpha_value": 0.03984918323324144, "duration": 68.92171573638916, "step": 25500}
{"episode_reward": 432.2099027853658, "episode": 103.0, "critic_loss": 14.330179340362548, "critic_target_Q_variance_m=2": 2557.0851181640624, "critic_Q1_variance_k=2": 0.347237635076046, "critic_Q2_variance_k=2": 0.3493428661823273, "actor_loss": -101.39683276367188, "actor_mean_entropy": 3.7812777919769287, "alpha_loss": 0.0158214302174747, "alpha_value": 0.039657370878901706, "duration": 69.33687233924866, "step": 25750}
{"episode_reward": 429.7162976744448, "episode": 104.0, "critic_loss": 14.456982673645019, "critic_target_Q_variance_m=2": 2613.53926953125, "critic_Q1_variance_k=2": 0.35453365790843966, "critic_Q2_variance_k=2": 0.3479973765015602, "actor_loss": -102.5615542602539, "actor_mean_entropy": 3.832819995880127, "alpha_loss": 0.009941462415270507, "alpha_value": 0.039526051274691346, "duration": 69.35144710540771, "step": 26000}
{"episode_reward": 369.30861275660527, "episode": 105.0, "critic_loss": 14.976184574127197, "critic_target_Q_variance_m=2": 2662.6063818359376, "critic_Q1_variance_k=2": 0.36106828701496124, "critic_Q2_variance_k=2": 0.36640108585357667, "actor_loss": -103.45275714111328, "actor_mean_entropy": 3.7937869243621827, "alpha_loss": 0.008292589573189617, "alpha_value": 0.03938857402476914, "duration": 69.31538462638855, "step": 26250}
{"episode_reward": 541.6864308975757, "episode": 106.0, "critic_loss": 14.068815830230713, "critic_target_Q_variance_m=2": 2711.640494140625, "critic_Q1_variance_k=2": 0.34851091861724853, "critic_Q2_variance_k=2": 0.34797795236110685, "actor_loss": -104.36517633056641, "actor_mean_entropy": 3.8770323352813723, "alpha_loss": 0.012528359610587358, "alpha_value": 0.03924233438681915, "duration": 69.61003851890564, "step": 26500}
{"episode_reward": 474.2631894613776, "episode": 107.0, "critic_loss": 14.577893096923829, "critic_target_Q_variance_m=2": 2762.57421484375, "critic_Q1_variance_k=2": 0.3537824662923813, "critic_Q2_variance_k=2": 0.3561092118024826, "actor_loss": -105.25965466308594, "actor_mean_entropy": 3.806426788330078, "alpha_loss": 0.02096449339389801, "alpha_value": 0.03903836950543436, "duration": 68.997549533844, "step": 26750}
{"episode_reward": 452.7536376303422, "episode": 108.0, "critic_loss": 14.395293704986573, "critic_target_Q_variance_m=2": 2807.42657421875, "critic_Q1_variance_k=2": 0.35098698097467423, "critic_Q2_variance_k=2": 0.3485555256009102, "actor_loss": -106.2361890258789, "actor_mean_entropy": 3.701955268859863, "alpha_loss": 0.017910981220193207, "alpha_value": 0.038731997463608274, "duration": 69.29174566268921, "step": 27000}
{"episode_reward": 493.2953037039605, "episode": 109.0, "critic_loss": 15.003602279663086, "critic_target_Q_variance_m=2": 2857.96208984375, "critic_Q1_variance_k=2": 0.3570536290407181, "critic_Q2_variance_k=2": 0.3571923033595085, "actor_loss": -107.21930249023437, "actor_mean_entropy": 3.7464028015136717, "alpha_loss": 0.00497120448295027, "alpha_value": 0.03856535991300192, "duration": 69.23770642280579, "step": 27250}
{"episode_reward": 465.0819344941227, "episode": 110.0, "critic_loss": 14.767687705993652, "critic_target_Q_variance_m=2": 2904.85940625, "critic_Q1_variance_k=2": 0.35494701766967773, "critic_Q2_variance_k=2": 0.3516556394100189, "actor_loss": -107.92215924072265, "actor_mean_entropy": 3.8468945121765135, "alpha_loss": 0.017004696949385105, "alpha_value": 0.03842807710656823, "duration": 69.16249775886536, "step": 27500}
{"episode_reward": 425.65726050725107, "episode": 111.0, "critic_loss": 15.790784313201904, "critic_target_Q_variance_m=2": 2954.824068359375, "critic_Q1_variance_k=2": 0.38046990913152695, "critic_Q2_variance_k=2": 0.3818056849837303, "actor_loss": -108.95031414794921, "actor_mean_entropy": 3.824529447555542, "alpha_loss": 0.006930226759985089, "alpha_value": 0.03824347474497932, "duration": 68.9997410774231, "step": 27750}
{"episode_reward": 515.6797406936512, "episode": 112.0, "critic_loss": 14.705241722106933, "critic_target_Q_variance_m=2": 3004.282306640625, "critic_Q1_variance_k=2": 0.3722074902653694, "critic_Q2_variance_k=2": 0.3659226675629616, "actor_loss": -109.89298516845703, "actor_mean_entropy": 3.752505590438843, "alpha_loss": 0.004578951105475426, "alpha_value": 0.03813289773296631, "duration": 68.99070811271667, "step": 28000}
{"episode_reward": 479.427331989578, "episode": 113.0, "critic_loss": 14.725216659545898, "critic_target_Q_variance_m=2": 3059.2386279296875, "critic_Q1_variance_k=2": 0.3584068378806114, "critic_Q2_variance_k=2": 0.35622583550214765, "actor_loss": -110.8592509765625, "actor_mean_entropy": 3.91086968421936, "alpha_loss": -0.0037903776513412593, "alpha_value": 0.038151255183215264, "duration": 69.00599026679993, "step": 28250}
{"episode_reward": 607.1082752805909, "episode": 114.0, "critic_loss": 14.909214687347411, "critic_target_Q_variance_m=2": 3113.3179736328125, "critic_Q1_variance_k=2": 0.3747139458656311, "critic_Q2_variance_k=2": 0.37161850875616076, "actor_loss": -111.80179156494141, "actor_mean_entropy": 3.755861431121826, "alpha_loss": 0.002372307674959302, "alpha_value": 0.03815334907677576, "duration": 69.0536437034607, "step": 28500}
{"episode_reward": 483.3298958321538, "episode": 115.0, "critic_loss": 14.815902912139892, "critic_target_Q_variance_m=2": 3164.6764228515626, "critic_Q1_variance_k=2": 0.3771580396294594, "critic_Q2_variance_k=2": 0.3703428410291672, "actor_loss": -112.79037573242188, "actor_mean_entropy": 3.714621671676636, "alpha_loss": 0.005117448011413217, "alpha_value": 0.038051675612993136, "duration": 69.10185480117798, "step": 28750}
{"episode_reward": 550.2039283758506, "episode": 116.0, "critic_loss": 15.417577110290527, "critic_target_Q_variance_m=2": 3216.3119169921874, "critic_Q1_variance_k=2": 0.37827047526836394, "critic_Q2_variance_k=2": 0.38163080942630767, "actor_loss": -113.5788920288086, "actor_mean_entropy": 3.7226550846099853, "alpha_loss": 0.002148605965077877, "alpha_value": 0.03803448864481214, "duration": 69.77740955352783, "step": 29000}
{"episode_reward": 509.7549636038306, "episode": 117.0, "critic_loss": 14.468546600341798, "critic_target_Q_variance_m=2": 3269.5773974609374, "critic_Q1_variance_k=2": 0.37232454591989517, "critic_Q2_variance_k=2": 0.36858836537599565, "actor_loss": -114.61035705566407, "actor_mean_entropy": 3.5901670455932617, "alpha_loss": 0.005337572813034057, "alpha_value": 0.03795482725947166, "duration": 69.06673884391785, "step": 29250}
{"episode_reward": 589.6108242730044, "episode": 118.0, "critic_loss": 15.17845629119873, "critic_target_Q_variance_m=2": 3325.0612646484374, "critic_Q1_variance_k=2": 0.39647306442260744, "critic_Q2_variance_k=2": 0.3919849088191986, "actor_loss": -115.47191302490235, "actor_mean_entropy": 3.6535201206207275, "alpha_loss": 0.00511475794762373, "alpha_value": 0.03784420263314057, "duration": 68.95082449913025, "step": 29500}
{"episode_reward": 558.7286386052842, "episode": 119.0, "critic_loss": 15.080415199279786, "critic_target_Q_variance_m=2": 3382.84582421875, "critic_Q1_variance_k=2": 0.38078671449422835, "critic_Q2_variance_k=2": 0.38182667243480684, "actor_loss": -116.56417846679688, "actor_mean_entropy": 3.5051495513916016, "alpha_loss": 0.0023341738479211926, "alpha_value": 0.037755900882113336, "duration": 69.05641889572144, "step": 29750}
{"episode_reward": 509.365757266628, "episode": 120.0, "critic_loss": 15.863504768371582, "critic_target_Q_variance_m=2": 3442.1025712890623, "critic_Q1_variance_k=2": 0.38857890808582307, "critic_Q2_variance_k=2": 0.38840396630764007, "actor_loss": -117.60731823730468, "actor_mean_entropy": 3.7165995922088624, "alpha_loss": 0.0023451810171827674, "alpha_value": 0.037722768761799766, "duration": 69.3250036239624, "step": 30000}
{"episode_reward": 445.55188778986053, "episode": 121.0, "critic_loss": 16.774690769195555, "critic_target_Q_variance_m=2": 3485.9587890625, "critic_Q1_variance_k=2": 0.40446072673797606, "critic_Q2_variance_k=2": 0.400815627515316, "actor_loss": -118.29600695800781, "actor_mean_entropy": 3.7883429641723634, "alpha_loss": -0.013784132454544306, "alpha_value": 0.03782313218650728, "duration": 73.3138542175293, "step": 30250}
{"episode_reward": 490.8066572909608, "episode": 122.0, "critic_loss": 16.614060565948485, "critic_target_Q_variance_m=2": 3541.14196875, "critic_Q1_variance_k=2": 0.4008246440291405, "critic_Q2_variance_k=2": 0.4011615107655525, "actor_loss": -119.27848321533203, "actor_mean_entropy": 3.724227020263672, "alpha_loss": 0.0005284398151561618, "alpha_value": 0.038007374907217194, "duration": 69.59412360191345, "step": 30500}
{"episode_reward": 464.89883102798336, "episode": 123.0, "critic_loss": 15.806722213745116, "critic_target_Q_variance_m=2": 3593.3067333984377, "critic_Q1_variance_k=2": 0.4014911103844643, "critic_Q2_variance_k=2": 0.396579519033432, "actor_loss": -120.2219892578125, "actor_mean_entropy": 3.5531769199371337, "alpha_loss": 0.0035677074771374466, "alpha_value": 0.03793423610139696, "duration": 69.85260128974915, "step": 30750}
{"episode_reward": 496.467492480537, "episode": 124.0, "critic_loss": 15.71894384765625, "critic_target_Q_variance_m=2": 3649.5305009765625, "critic_Q1_variance_k=2": 0.39607598757743834, "critic_Q2_variance_k=2": 0.39376712077856063, "actor_loss": -121.05629779052734, "actor_mean_entropy": 3.6065457820892335, "alpha_loss": 0.0038745571682229636, "alpha_value": 0.037830299802376705, "duration": 68.94529962539673, "step": 31000}
{"episode_reward": 527.4306290955406, "episode": 125.0, "critic_loss": 16.258730007171632, "critic_target_Q_variance_m=2": 3702.5979091796876, "critic_Q1_variance_k=2": 0.40109091174602507, "critic_Q2_variance_k=2": 0.39788023853302, "actor_loss": -121.87395733642578, "actor_mean_entropy": 3.5929152355194094, "alpha_loss": -0.0016393230007961392, "alpha_value": 0.03778611272277149, "duration": 69.28903007507324, "step": 31250}
{"episode_reward": 542.5518566363188, "episode": 126.0, "critic_loss": 16.025071563720704, "critic_target_Q_variance_m=2": 3761.052943359375, "critic_Q1_variance_k=2": 0.3899897409677506, "critic_Q2_variance_k=2": 0.38579150807857515, "actor_loss": -122.84332330322266, "actor_mean_entropy": 3.6931298332214357, "alpha_loss": -0.008184226585552096, "alpha_value": 0.037905646224868354, "duration": 68.99203181266785, "step": 31500}
{"episode_reward": 515.8702047943027, "episode": 127.0, "critic_loss": 15.9970065574646, "critic_target_Q_variance_m=2": 3824.111787109375, "critic_Q1_variance_k=2": 0.38055829697847365, "critic_Q2_variance_k=2": 0.38832230389118194, "actor_loss": -123.88959967041015, "actor_mean_entropy": 3.7761797943115236, "alpha_loss": -0.006457772247493267, "alpha_value": 0.038075577786329, "duration": 69.30102944374084, "step": 31750}
{"episode_reward": 490.2880759640798, "episode": 128.0, "critic_loss": 15.685378917694091, "critic_target_Q_variance_m=2": 3883.404673828125, "critic_Q1_variance_k=2": 0.38672090822458266, "critic_Q2_variance_k=2": 0.3844491896033287, "actor_loss": -124.87777508544922, "actor_mean_entropy": 3.7388147411346435, "alpha_loss": -0.001558310903608799, "alpha_value": 0.03821808924198403, "duration": 69.22105526924133, "step": 32000}
{"episode_reward": 464.31521699007436, "episode": 129.0, "critic_loss": 15.930868629455567, "critic_target_Q_variance_m=2": 3935.5887998046874, "critic_Q1_variance_k=2": 0.3914061460494995, "critic_Q2_variance_k=2": 0.39435488361120224, "actor_loss": -125.74828778076171, "actor_mean_entropy": 3.6097134799957273, "alpha_loss": 0.00011028939206153154, "alpha_value": 0.038241155013971934, "duration": 69.13835000991821, "step": 32250}
{"episode_reward": 512.2264283240515, "episode": 130.0, "critic_loss": 16.145547050476075, "critic_target_Q_variance_m=2": 3989.513466796875, "critic_Q1_variance_k=2": 0.3915760322213173, "critic_Q2_variance_k=2": 0.39037163692712784, "actor_loss": -126.54104553222656, "actor_mean_entropy": 3.6658691444396974, "alpha_loss": 0.0036544970571994783, "alpha_value": 0.03816514493036774, "duration": 69.22121024131775, "step": 32500}
{"episode_reward": 519.2519567602607, "episode": 131.0, "critic_loss": 15.617449359893799, "critic_target_Q_variance_m=2": 4042.252037109375, "critic_Q1_variance_k=2": 0.3880625423789024, "critic_Q2_variance_k=2": 0.3890641950368881, "actor_loss": -127.34905847167968, "actor_mean_entropy": 3.6353424758911133, "alpha_loss": 0.005697484845295548, "alpha_value": 0.03803339833695949, "duration": 69.2107036113739, "step": 32750}
{"episode_reward": 489.0307267793376, "episode": 132.0, "critic_loss": 15.737530529022218, "critic_target_Q_variance_m=2": 4093.595330078125, "critic_Q1_variance_k=2": 0.3926056587100029, "critic_Q2_variance_k=2": 0.391429852604866, "actor_loss": -128.25203106689452, "actor_mean_entropy": 3.7657919788360594, "alpha_loss": -0.007551179795525968, "alpha_value": 0.03806919724952677, "duration": 69.10466361045837, "step": 33000}
{"episode_reward": 499.8667129477322, "episode": 133.0, "critic_loss": 15.844082984924317, "critic_target_Q_variance_m=2": 4152.36885546875, "critic_Q1_variance_k=2": 0.3936778739094734, "critic_Q2_variance_k=2": 0.39556064414978026, "actor_loss": -129.22080853271484, "actor_mean_entropy": 3.605204008102417, "alpha_loss": 0.0007844424173235893, "alpha_value": 0.03815438702898977, "duration": 68.91808843612671, "step": 33250}
{"episode_reward": 524.4656024310017, "episode": 134.0, "critic_loss": 16.599878562927245, "critic_target_Q_variance_m=2": 4212.64337109375, "critic_Q1_variance_k=2": 0.4154198498725891, "critic_Q2_variance_k=2": 0.40581362146139144, "actor_loss": -130.05147314453126, "actor_mean_entropy": 3.558921730041504, "alpha_loss": -0.0018741881549358369, "alpha_value": 0.03823077013712725, "duration": 68.86241602897644, "step": 33500}
{"episode_reward": 420.2014111229399, "episode": 135.0, "critic_loss": 15.79536867904663, "critic_target_Q_variance_m=2": 4259.262869140625, "critic_Q1_variance_k=2": 0.4055337847471237, "critic_Q2_variance_k=2": 0.40379071789979937, "actor_loss": -130.78207556152344, "actor_mean_entropy": 3.4521534881591798, "alpha_loss": 0.003366781547665596, "alpha_value": 0.038124508449058084, "duration": 67.76487803459167, "step": 33750}
{"episode_reward": 556.8108337380751, "episode": 136.0, "critic_loss": 16.19467286682129, "critic_target_Q_variance_m=2": 4317.874958984375, "critic_Q1_variance_k=2": 0.40201514774560926, "critic_Q2_variance_k=2": 0.40106011617183684, "actor_loss": -131.64972509765624, "actor_mean_entropy": 3.7375771350860596, "alpha_loss": -0.00016408361680805684, "alpha_value": 0.038127416248869395, "duration": 69.23009395599365, "step": 34000}
{"episode_reward": 531.063950207119, "episode": 137.0, "critic_loss": 17.19422756958008, "critic_target_Q_variance_m=2": 4368.292068359375, "critic_Q1_variance_k=2": 0.4112746180891991, "critic_Q2_variance_k=2": 0.4150737407207489, "actor_loss": -132.44232080078126, "actor_mean_entropy": 3.6578704738616943, "alpha_loss": -0.00024076837114989758, "alpha_value": 0.038116999069956324, "duration": 68.98531913757324, "step": 34250}
{"episode_reward": 500.3488102779552, "episode": 138.0, "critic_loss": 16.364478759765625, "critic_target_Q_variance_m=2": 4425.5276171875, "critic_Q1_variance_k=2": 0.401345647752285, "critic_Q2_variance_k=2": 0.3950856124162674, "actor_loss": -133.3150528564453, "actor_mean_entropy": 3.671148389816284, "alpha_loss": -0.0008408418782055377, "alpha_value": 0.03813908492807822, "duration": 69.24620532989502, "step": 34500}
{"episode_reward": 595.7734153790752, "episode": 139.0, "critic_loss": 17.35226396179199, "critic_target_Q_variance_m=2": 4480.921775390625, "critic_Q1_variance_k=2": 0.4222033069729805, "critic_Q2_variance_k=2": 0.4187762871980667, "actor_loss": -134.10693237304687, "actor_mean_entropy": 3.72792907333374, "alpha_loss": 0.0012121679168194531, "alpha_value": 0.038133787303189046, "duration": 69.40596008300781, "step": 34750}
{"episode_reward": 546.4033878394664, "episode": 140.0, "critic_loss": 17.60549502182007, "critic_target_Q_variance_m=2": 4534.452337890625, "critic_Q1_variance_k=2": 0.4277512807250023, "critic_Q2_variance_k=2": 0.42518840193748475, "actor_loss": -134.88395178222657, "actor_mean_entropy": 3.6839981117248537, "alpha_loss": -0.0015372086800634862, "alpha_value": 0.03806015096512192, "duration": 69.32240605354309, "step": 35000}
{"episode_reward": 579.3035685558448, "episode": 141.0, "critic_loss": 17.286589511871338, "critic_target_Q_variance_m=2": 4592.977837890625, "critic_Q1_variance_k=2": 0.4275671114325523, "critic_Q2_variance_k=2": 0.42571514999866483, "actor_loss": -135.7672438964844, "actor_mean_entropy": 3.688438320159912, "alpha_loss": 0.00134928915835917, "alpha_value": 0.03811453195653058, "duration": 69.13891768455505, "step": 35250}
{"episode_reward": 616.9367108707437, "episode": 142.0, "critic_loss": 17.369255867004394, "critic_target_Q_variance_m=2": 4642.563583984375, "critic_Q1_variance_k=2": 0.4392299639582634, "critic_Q2_variance_k=2": 0.437205451965332, "actor_loss": -136.48960095214844, "actor_mean_entropy": 3.730677028656006, "alpha_loss": -0.001969577742740512, "alpha_value": 0.03813459460466926, "duration": 69.00910902023315, "step": 35500}
{"episode_reward": 484.42772718207857, "episode": 143.0, "critic_loss": 16.823488956451417, "critic_target_Q_variance_m=2": 4698.37903515625, "critic_Q1_variance_k=2": 0.414830646276474, "critic_Q2_variance_k=2": 0.4188077062964439, "actor_loss": -137.35065637207032, "actor_mean_entropy": 3.6276423072814943, "alpha_loss": -0.003606213830411434, "alpha_value": 0.03817687089692847, "duration": 69.34795641899109, "step": 35750}
{"episode_reward": 497.9912756601588, "episode": 144.0, "critic_loss": 16.312357006072997, "critic_target_Q_variance_m=2": 4763.08798828125, "critic_Q1_variance_k=2": 0.41864804875850675, "critic_Q2_variance_k=2": 0.4115247368812561, "actor_loss": -138.2032413330078, "actor_mean_entropy": 3.615534662246704, "alpha_loss": 0.0013774083331227302, "alpha_value": 0.038219354441844655, "duration": 69.25158262252808, "step": 36000}
{"episode_reward": 545.5635427371442, "episode": 145.0, "critic_loss": 17.804621620178224, "critic_target_Q_variance_m=2": 4808.798056640625, "critic_Q1_variance_k=2": 0.4248491664528847, "critic_Q2_variance_k=2": 0.4152646046876907, "actor_loss": -138.9040207519531, "actor_mean_entropy": 3.657875955581665, "alpha_loss": -0.004311619892716408, "alpha_value": 0.038271938718676755, "duration": 69.33850908279419, "step": 36250}
{"episode_reward": 527.0465732787434, "episode": 146.0, "critic_loss": 17.185838077545167, "critic_target_Q_variance_m=2": 4873.524265625, "critic_Q1_variance_k=2": 0.4137916498780251, "critic_Q2_variance_k=2": 0.4142391538619995, "actor_loss": -139.87723962402345, "actor_mean_entropy": 3.6073855667114256, "alpha_loss": -0.0029006995745003224, "alpha_value": 0.03836269285795734, "duration": 69.0082938671112, "step": 36500}
{"episode_reward": 566.5405783193868, "episode": 147.0, "critic_loss": 16.843314945220946, "critic_target_Q_variance_m=2": 4929.641259765625, "critic_Q1_variance_k=2": 0.4203064983487129, "critic_Q2_variance_k=2": 0.4148572891950607, "actor_loss": -140.67841918945314, "actor_mean_entropy": 3.7996503009796143, "alpha_loss": -0.007008020742796361, "alpha_value": 0.03847764890410727, "duration": 69.23109006881714, "step": 36750}
{"episode_reward": 461.15760276082773, "episode": 148.0, "critic_loss": 17.759826751708985, "critic_target_Q_variance_m=2": 4984.347234375, "critic_Q1_variance_k=2": 0.4289045256972313, "critic_Q2_variance_k=2": 0.4283952571153641, "actor_loss": -141.47526147460937, "actor_mean_entropy": 3.7733734188079833, "alpha_loss": -0.005123657974414528, "alpha_value": 0.03866771192932757, "duration": 69.348219871521, "step": 37000}
{"episode_reward": 599.7334349498421, "episode": 149.0, "critic_loss": 18.38409912109375, "critic_target_Q_variance_m=2": 5028.730072265625, "critic_Q1_variance_k=2": 0.4245781599879265, "critic_Q2_variance_k=2": 0.4201750384569168, "actor_loss": -142.02036962890625, "actor_mean_entropy": 3.703857734680176, "alpha_loss": 0.005447797443717718, "alpha_value": 0.03864627812020063, "duration": 69.03268527984619, "step": 37250}
{"episode_reward": 483.12469405089604, "episode": 150.0, "critic_loss": 17.208835433959962, "critic_target_Q_variance_m=2": 5093.2577578125, "critic_Q1_variance_k=2": 0.43059576416015627, "critic_Q2_variance_k=2": 0.43041914612054827, "actor_loss": -142.95706811523436, "actor_mean_entropy": 3.6179091510772703, "alpha_loss": -0.005278877181001008, "alpha_value": 0.038637628241132524, "duration": 69.37181687355042, "step": 37500}
{"episode_reward": 573.4708318912357, "episode": 151.0, "critic_loss": 17.628644119262695, "critic_target_Q_variance_m=2": 5149.343306640625, "critic_Q1_variance_k=2": 0.4378602634072304, "critic_Q2_variance_k=2": 0.4380157410502434, "actor_loss": -143.7676682128906, "actor_mean_entropy": 3.539334978103638, "alpha_loss": 0.0031474900674074886, "alpha_value": 0.03862536957541354, "duration": 68.92401313781738, "step": 37750}
{"episode_reward": 613.4460129789929, "episode": 152.0, "critic_loss": 17.985630878448486, "critic_target_Q_variance_m=2": 5204.852498046875, "critic_Q1_variance_k=2": 0.4394694719910622, "critic_Q2_variance_k=2": 0.4429636599421501, "actor_loss": -144.56509533691406, "actor_mean_entropy": 3.660531894683838, "alpha_loss": -0.0012372095976024866, "alpha_value": 0.03866287201681637, "duration": 69.02493166923523, "step": 38000}
{"episode_reward": 644.6507856091124, "episode": 153.0, "critic_loss": 18.013579803466797, "critic_target_Q_variance_m=2": 5257.97798828125, "critic_Q1_variance_k=2": 0.4527024418115616, "critic_Q2_variance_k=2": 0.4522212457060814, "actor_loss": -145.23219226074218, "actor_mean_entropy": 3.6461743602752685, "alpha_loss": -0.005019271841272712, "alpha_value": 0.0387236822713584, "duration": 69.1631555557251, "step": 38250}
{"episode_reward": 521.8827913133581, "episode": 154.0, "critic_loss": 18.22711996459961, "critic_target_Q_variance_m=2": 5316.6701171875, "critic_Q1_variance_k=2": 0.4361828770637512, "critic_Q2_variance_k=2": 0.4340014247894287, "actor_loss": -146.20361279296876, "actor_mean_entropy": 3.643683864593506, "alpha_loss": -0.007788752865977585, "alpha_value": 0.03890287524460316, "duration": 69.0980134010315, "step": 38500}
{"episode_reward": 564.4988364621421, "episode": 155.0, "critic_loss": 18.86027098464966, "critic_target_Q_variance_m=2": 5384.930263671875, "critic_Q1_variance_k=2": 0.46168455749750137, "critic_Q2_variance_k=2": 0.456642370223999, "actor_loss": -147.0415517578125, "actor_mean_entropy": 3.5614048233032225, "alpha_loss": -0.00250131849385798, "alpha_value": 0.03903450477565859, "duration": 68.9564037322998, "step": 38750}
{"episode_reward": 527.2847267607671, "episode": 156.0, "critic_loss": 18.50653532409668, "critic_target_Q_variance_m=2": 5436.9004375, "critic_Q1_variance_k=2": 0.45683084136247637, "critic_Q2_variance_k=2": 0.4577612669467926, "actor_loss": -147.77227465820312, "actor_mean_entropy": 3.5895544548034666, "alpha_loss": -0.006276526598259806, "alpha_value": 0.039172936141368304, "duration": 68.88143801689148, "step": 39000}
{"episode_reward": 450.64416104898316, "episode": 157.0, "critic_loss": 18.23468785095215, "critic_target_Q_variance_m=2": 5491.3488046875, "critic_Q1_variance_k=2": 0.4373370355963707, "critic_Q2_variance_k=2": 0.4418493949174881, "actor_loss": -148.41807788085939, "actor_mean_entropy": 3.783136905670166, "alpha_loss": -0.01505245241895318, "alpha_value": 0.03947079480859034, "duration": 69.31002974510193, "step": 39250}
{"episode_reward": 542.6428621530719, "episode": 158.0, "critic_loss": 17.688417179107667, "critic_target_Q_variance_m=2": 5546.04855859375, "critic_Q1_variance_k=2": 0.43340892291069033, "critic_Q2_variance_k=2": 0.43751500964164736, "actor_loss": -149.2513293457031, "actor_mean_entropy": 3.662494472503662, "alpha_loss": -0.010062561105936766, "alpha_value": 0.03985150249188997, "duration": 69.20396685600281, "step": 39500}
{"episode_reward": 614.816161547691, "episode": 159.0, "critic_loss": 17.787411571502684, "critic_target_Q_variance_m=2": 5607.369201171875, "critic_Q1_variance_k=2": 0.45276480305194855, "critic_Q2_variance_k=2": 0.4513960537314415, "actor_loss": -150.02935595703124, "actor_mean_entropy": 3.7010814208984373, "alpha_loss": -0.006963236132636667, "alpha_value": 0.040058799213376954, "duration": 69.16667151451111, "step": 39750}
{"episode_reward": 639.5231417886262, "episode": 160.0, "critic_loss": 18.03014447402954, "critic_target_Q_variance_m=2": 5662.046326171875, "critic_Q1_variance_k=2": 0.43921701776981353, "critic_Q2_variance_k=2": 0.4423514769077301, "actor_loss": -150.81832482910156, "actor_mean_entropy": 3.5083331089019776, "alpha_loss": -0.006969923950731754, "alpha_value": 0.04025154142629211, "duration": 69.66286182403564, "step": 40000}
{"episode_reward": 519.3813285023698, "episode": 161.0, "critic_loss": 17.503731101989747, "critic_target_Q_variance_m=2": 5715.53147265625, "critic_Q1_variance_k=2": 0.444830490231514, "critic_Q2_variance_k=2": 0.44812499010562895, "actor_loss": -151.45710485839842, "actor_mean_entropy": 3.624614744186401, "alpha_loss": -0.0024707110533490778, "alpha_value": 0.040358286807843875, "duration": 72.78408002853394, "step": 40250}
{"episode_reward": 557.197815613431, "episode": 162.0, "critic_loss": 18.412160011291505, "critic_target_Q_variance_m=2": 5773.475017578125, "critic_Q1_variance_k=2": 0.46169186365604403, "critic_Q2_variance_k=2": 0.45377344381809237, "actor_loss": -152.17447412109374, "actor_mean_entropy": 3.6738913326263427, "alpha_loss": -0.011843540027737617, "alpha_value": 0.04057083154247131, "duration": 69.21329927444458, "step": 40500}
{"episode_reward": 576.2565175092634, "episode": 163.0, "critic_loss": 18.09944420623779, "critic_target_Q_variance_m=2": 5820.649693359375, "critic_Q1_variance_k=2": 0.4494015383124351, "critic_Q2_variance_k=2": 0.4481064574718475, "actor_loss": -152.7488507080078, "actor_mean_entropy": 3.758802713394165, "alpha_loss": 0.0024131028223782778, "alpha_value": 0.040691129949489285, "duration": 69.4896183013916, "step": 40750}
{"episode_reward": 542.7931578564803, "episode": 164.0, "critic_loss": 17.755991844177245, "critic_target_Q_variance_m=2": 5877.603607421875, "critic_Q1_variance_k=2": 0.4459011607170105, "critic_Q2_variance_k=2": 0.4456011995077133, "actor_loss": -153.54473876953125, "actor_mean_entropy": 3.6446869659423826, "alpha_loss": 0.004131279531866312, "alpha_value": 0.04061659480294929, "duration": 69.71221733093262, "step": 41000}
{"episode_reward": 535.7256483036766, "episode": 165.0, "critic_loss": 18.588857917785646, "critic_target_Q_variance_m=2": 5934.26836328125, "critic_Q1_variance_k=2": 0.44919791638851164, "critic_Q2_variance_k=2": 0.4473485339283943, "actor_loss": -154.30084008789063, "actor_mean_entropy": 3.6191919021606447, "alpha_loss": -0.005574132244102657, "alpha_value": 0.04056883413614495, "duration": 69.392418384552, "step": 41250}
{"episode_reward": 623.5579049664423, "episode": 166.0, "critic_loss": 18.723552181243896, "critic_target_Q_variance_m=2": 5983.0695, "critic_Q1_variance_k=2": 0.45954240262508395, "critic_Q2_variance_k=2": 0.4626293480396271, "actor_loss": -154.98554138183593, "actor_mean_entropy": 3.8006490001678466, "alpha_loss": -0.006474274558015167, "alpha_value": 0.04082336222664631, "duration": 70.1328513622284, "step": 41500}
{"episode_reward": 461.7091560236285, "episode": 167.0, "critic_loss": 19.536808403015137, "critic_target_Q_variance_m=2": 6033.39030859375, "critic_Q1_variance_k=2": 0.47630738723278043, "critic_Q2_variance_k=2": 0.4729379061460495, "actor_loss": -155.65978173828125, "actor_mean_entropy": 3.57343017578125, "alpha_loss": -0.000666382135823369, "alpha_value": 0.040886021847192096, "duration": 69.16030812263489, "step": 41750}
{"episode_reward": 462.3587815555453, "episode": 168.0, "critic_loss": 18.97169259262085, "critic_target_Q_variance_m=2": 6099.51290625, "critic_Q1_variance_k=2": 0.46255813068151475, "critic_Q2_variance_k=2": 0.4597977781295776, "actor_loss": -156.42726110839843, "actor_mean_entropy": 3.6508779964447022, "alpha_loss": 0.002409732710570097, "alpha_value": 0.04086666434393741, "duration": 69.73818182945251, "step": 42000}
{"episode_reward": 501.43238519447823, "episode": 169.0, "critic_loss": 19.761911922454836, "critic_target_Q_variance_m=2": 6156.5390390625, "critic_Q1_variance_k=2": 0.47200008821487427, "critic_Q2_variance_k=2": 0.4718923608064651, "actor_loss": -157.1623125, "actor_mean_entropy": 3.5781732864379885, "alpha_loss": 0.006057758336886763, "alpha_value": 0.040738337400983066, "duration": 69.37198448181152, "step": 42250}
{"episode_reward": 560.1763597855212, "episode": 170.0, "critic_loss": 19.133848892211915, "critic_target_Q_variance_m=2": 6214.903009765625, "critic_Q1_variance_k=2": 0.4820627918243408, "critic_Q2_variance_k=2": 0.4830486367344856, "actor_loss": -157.88996594238282, "actor_mean_entropy": 3.556878622055054, "alpha_loss": 0.0025516848061233758, "alpha_value": 0.040640338211959046, "duration": 69.26268291473389, "step": 42500}
{"episode_reward": 581.6605806872755, "episode": 171.0, "critic_loss": 19.25513819885254, "critic_target_Q_variance_m=2": 6273.985060546875, "critic_Q1_variance_k=2": 0.47394982039928435, "critic_Q2_variance_k=2": 0.47458526933193207, "actor_loss": -158.69197216796874, "actor_mean_entropy": 3.520699254989624, "alpha_loss": -0.003329238336533308, "alpha_value": 0.0406683397689062, "duration": 69.36493873596191, "step": 42750}
{"episode_reward": 526.9780432436413, "episode": 172.0, "critic_loss": 20.11198613357544, "critic_target_Q_variance_m=2": 6322.83638671875, "critic_Q1_variance_k=2": 0.4847631639242172, "critic_Q2_variance_k=2": 0.4860765874385834, "actor_loss": -159.2665213623047, "actor_mean_entropy": 3.5591655616760254, "alpha_loss": -0.0009551409669220448, "alpha_value": 0.04067487637270306, "duration": 69.20749521255493, "step": 43000}
{"episode_reward": 564.0688134234742, "episode": 173.0, "critic_loss": 18.947890201568605, "critic_target_Q_variance_m=2": 6374.2537734375, "critic_Q1_variance_k=2": 0.47241227942705155, "critic_Q2_variance_k=2": 0.4694312105178833, "actor_loss": -159.96358557128906, "actor_mean_entropy": 3.573934404373169, "alpha_loss": -0.009506144129671157, "alpha_value": 0.0408764692452374, "duration": 69.09302353858948, "step": 43250}
{"episode_reward": 542.1947077383785, "episode": 174.0, "critic_loss": 18.50260646057129, "critic_target_Q_variance_m=2": 6432.243138671875, "critic_Q1_variance_k=2": 0.4662961809635162, "critic_Q2_variance_k=2": 0.46751827776432037, "actor_loss": -160.6987731933594, "actor_mean_entropy": 3.5327486896514895, "alpha_loss": 0.00277869425714016, "alpha_value": 0.04093425525558186, "duration": 68.82416892051697, "step": 43500}
{"episode_reward": 686.6379778263928, "episode": 175.0, "critic_loss": 19.011990943908692, "critic_target_Q_variance_m=2": 6489.278671875, "critic_Q1_variance_k=2": 0.4577986832857132, "critic_Q2_variance_k=2": 0.4583360018730164, "actor_loss": -161.26832739257813, "actor_mean_entropy": 3.522898670196533, "alpha_loss": 0.0015479240454733371, "alpha_value": 0.040859641617936676, "duration": 67.1402325630188, "step": 43750}
{"episode_reward": 593.6729625089904, "episode": 176.0, "critic_loss": 19.173072620391846, "critic_target_Q_variance_m=2": 6529.71607421875, "critic_Q1_variance_k=2": 0.4604985771179199, "critic_Q2_variance_k=2": 0.4590982068777084, "actor_loss": -161.84698889160157, "actor_mean_entropy": 3.5359909420013427, "alpha_loss": 0.005433027097955346, "alpha_value": 0.04080562412721766, "duration": 69.00646305084229, "step": 44000}
{"episode_reward": 609.0607102852721, "episode": 177.0, "critic_loss": 19.00679744720459, "critic_target_Q_variance_m=2": 6592.894697265625, "critic_Q1_variance_k=2": 0.46251059997081756, "critic_Q2_variance_k=2": 0.46372989618778226, "actor_loss": -162.66301147460936, "actor_mean_entropy": 3.584017213821411, "alpha_loss": -0.0011718301773071288, "alpha_value": 0.04065467295586282, "duration": 69.01972603797913, "step": 44250}
{"episode_reward": 679.3628396304663, "episode": 178.0, "critic_loss": 19.465249073028563, "critic_target_Q_variance_m=2": 6649.394078125, "critic_Q1_variance_k=2": 0.4673465156555176, "critic_Q2_variance_k=2": 0.469156188249588, "actor_loss": -163.26783947753907, "actor_mean_entropy": 3.5213326892852783, "alpha_loss": -0.004474405650980771, "alpha_value": 0.04085214374417625, "duration": 69.44148921966553, "step": 44500}
{"episode_reward": 562.6160790319524, "episode": 179.0, "critic_loss": 19.6462469329834, "critic_target_Q_variance_m=2": 6695.90830078125, "critic_Q1_variance_k=2": 0.47127391082048414, "critic_Q2_variance_k=2": 0.46676083022356035, "actor_loss": -163.87790893554688, "actor_mean_entropy": 3.6412258911132813, "alpha_loss": -0.005141917888075114, "alpha_value": 0.040933461491255256, "duration": 69.28909969329834, "step": 44750}
{"episode_reward": 422.654859147673, "episode": 180.0, "critic_loss": 19.17511721420288, "critic_target_Q_variance_m=2": 6750.56831640625, "critic_Q1_variance_k=2": 0.47276084011793135, "critic_Q2_variance_k=2": 0.4729443323612213, "actor_loss": -164.53995031738282, "actor_mean_entropy": 3.6326154899597167, "alpha_loss": -0.004927870701998472, "alpha_value": 0.041068694993827114, "duration": 69.0110411643982, "step": 45000}
{"episode_reward": 513.298021766972, "episode": 181.0, "critic_loss": 19.429805480957032, "critic_target_Q_variance_m=2": 6802.648361328125, "critic_Q1_variance_k=2": 0.4561644700169563, "critic_Q2_variance_k=2": 0.4594705342054367, "actor_loss": -165.13615173339844, "actor_mean_entropy": 3.532444803237915, "alpha_loss": 0.002888230461627245, "alpha_value": 0.041120126504281075, "duration": 69.80152463912964, "step": 45250}
{"episode_reward": 517.2710936023425, "episode": 182.0, "critic_loss": 19.929932765960693, "critic_target_Q_variance_m=2": 6863.274966796875, "critic_Q1_variance_k=2": 0.4748390496969223, "critic_Q2_variance_k=2": 0.4690473394393921, "actor_loss": -165.99559997558595, "actor_mean_entropy": 3.5703549213409422, "alpha_loss": -0.0026764334104955197, "alpha_value": 0.04101464957430984, "duration": 69.23813438415527, "step": 45500}
{"episode_reward": 595.7942658091565, "episode": 183.0, "critic_loss": 18.620984066009523, "critic_target_Q_variance_m=2": 6926.920265625, "critic_Q1_variance_k=2": 0.45290842044353485, "critic_Q2_variance_k=2": 0.4573546930551529, "actor_loss": -166.71310620117188, "actor_mean_entropy": 3.6758644180297853, "alpha_loss": -0.0006263283053413033, "alpha_value": 0.04112313929106701, "duration": 69.06184935569763, "step": 45750}
{"episode_reward": 537.5030789267078, "episode": 184.0, "critic_loss": 18.774499172210692, "critic_target_Q_variance_m=2": 6977.20832421875, "critic_Q1_variance_k=2": 0.4666804909706116, "critic_Q2_variance_k=2": 0.46824541610479353, "actor_loss": -167.28366882324218, "actor_mean_entropy": 3.5124419021606443, "alpha_loss": -0.01156545084156096, "alpha_value": 0.0413217069380649, "duration": 69.36903762817383, "step": 46000}
{"episode_reward": 522.720789465026, "episode": 185.0, "critic_loss": 18.96786664581299, "critic_target_Q_variance_m=2": 7037.851806640625, "critic_Q1_variance_k=2": 0.48018568789958954, "critic_Q2_variance_k=2": 0.4689390662908554, "actor_loss": -168.01966625976561, "actor_mean_entropy": 3.5793191261291506, "alpha_loss": -0.0012490082029253243, "alpha_value": 0.04146278705197806, "duration": 69.72583723068237, "step": 46250}
{"episode_reward": 610.261223968265, "episode": 186.0, "critic_loss": 19.22339407348633, "critic_target_Q_variance_m=2": 7081.5176640625, "critic_Q1_variance_k=2": 0.4680293233394623, "critic_Q2_variance_k=2": 0.4675345603227615, "actor_loss": -168.49593518066405, "actor_mean_entropy": 3.455054817199707, "alpha_loss": 0.0004186539025977254, "alpha_value": 0.04149316361401013, "duration": 69.11672759056091, "step": 46500}
{"episode_reward": 519.9017826836877, "episode": 187.0, "critic_loss": 20.863854000091553, "critic_target_Q_variance_m=2": 7124.831259765625, "critic_Q1_variance_k=2": 0.4836421008110046, "critic_Q2_variance_k=2": 0.48556744658946993, "actor_loss": -168.99899047851562, "actor_mean_entropy": 3.5264821434020996, "alpha_loss": -0.0055583577593788505, "alpha_value": 0.04153194939223385, "duration": 69.44005155563354, "step": 46750}
{"episode_reward": 441.7343066457277, "episode": 188.0, "critic_loss": 20.9279306640625, "critic_target_Q_variance_m=2": 7167.324255859375, "critic_Q1_variance_k=2": 0.4971653484106064, "critic_Q2_variance_k=2": 0.490566172003746, "actor_loss": -169.49405944824218, "actor_mean_entropy": 3.6816900882720947, "alpha_loss": -0.0027721460503526032, "alpha_value": 0.04165151522623409, "duration": 69.37888741493225, "step": 47000}
{"episode_reward": 564.5198249095773, "episode": 189.0, "critic_loss": 19.360985355377196, "critic_target_Q_variance_m=2": 7225.67199609375, "critic_Q1_variance_k=2": 0.47428478628396986, "critic_Q2_variance_k=2": 0.47126376271247866, "actor_loss": -170.29032299804686, "actor_mean_entropy": 3.7428557415008545, "alpha_loss": -0.001479439820162952, "alpha_value": 0.04173704955441513, "duration": 69.80286192893982, "step": 47250}
{"episode_reward": 554.9394185360188, "episode": 190.0, "critic_loss": 19.799221168518066, "critic_target_Q_variance_m=2": 7273.53950390625, "critic_Q1_variance_k=2": 0.4865763772726059, "critic_Q2_variance_k=2": 0.4834625426530838, "actor_loss": -170.74638256835937, "actor_mean_entropy": 3.610162218093872, "alpha_loss": -0.007061404077336192, "alpha_value": 0.04188190845897514, "duration": 70.47440791130066, "step": 47500}
{"episode_reward": 584.5263366855454, "episode": 191.0, "critic_loss": 20.56825841140747, "critic_target_Q_variance_m=2": 7320.690517578125, "critic_Q1_variance_k=2": 0.4821007252931595, "critic_Q2_variance_k=2": 0.48373448896408083, "actor_loss": -171.316078125, "actor_mean_entropy": 3.6548224391937256, "alpha_loss": -0.008179864424280823, "alpha_value": 0.042015587849894315, "duration": 69.00861167907715, "step": 47750}
{"episode_reward": 569.9503481966556, "episode": 192.0, "critic_loss": 19.908974502563478, "critic_target_Q_variance_m=2": 7366.176703125, "critic_Q1_variance_k=2": 0.47854352509975434, "critic_Q2_variance_k=2": 0.4763471055030823, "actor_loss": -171.8755310058594, "actor_mean_entropy": 3.6133455142974853, "alpha_loss": 0.0017946302518248559, "alpha_value": 0.042096395403903496, "duration": 69.09107160568237, "step": 48000}
{"episode_reward": 588.9712765963283, "episode": 193.0, "critic_loss": 19.47762659072876, "critic_target_Q_variance_m=2": 7413.27858984375, "critic_Q1_variance_k=2": 0.4742423115968704, "critic_Q2_variance_k=2": 0.47067534703016284, "actor_loss": -172.44928674316407, "actor_mean_entropy": 3.6626821269989014, "alpha_loss": -0.010665970234200359, "alpha_value": 0.04220971472425211, "duration": 69.34000277519226, "step": 48250}
{"episode_reward": 588.7697061996491, "episode": 194.0, "critic_loss": 20.10505822753906, "critic_target_Q_variance_m=2": 7466.43895703125, "critic_Q1_variance_k=2": 0.49831477785110473, "critic_Q2_variance_k=2": 0.49715499818325043, "actor_loss": -173.01960815429686, "actor_mean_entropy": 3.6632447624206543, "alpha_loss": 0.0019912840109318495, "alpha_value": 0.04238139552453447, "duration": 69.07422280311584, "step": 48500}
{"episode_reward": 648.9323281527018, "episode": 195.0, "critic_loss": 19.844803775787355, "critic_target_Q_variance_m=2": 7520.6603984375, "critic_Q1_variance_k=2": 0.47772275882959364, "critic_Q2_variance_k=2": 0.4681759415268898, "actor_loss": -173.7134219970703, "actor_mean_entropy": 3.7016095886230467, "alpha_loss": -9.60717648267746e-05, "alpha_value": 0.04235215949858121, "duration": 69.40592217445374, "step": 48750}
{"episode_reward": 555.6830210941513, "episode": 196.0, "critic_loss": 19.186283702850343, "critic_target_Q_variance_m=2": 7578.292732421875, "critic_Q1_variance_k=2": 0.48108446872234345, "critic_Q2_variance_k=2": 0.47693179827928545, "actor_loss": -174.3590802001953, "actor_mean_entropy": 3.705370038986206, "alpha_loss": -0.0020509070167317985, "alpha_value": 0.04237650087547336, "duration": 69.10728788375854, "step": 49000}
{"episode_reward": 579.7437628644395, "episode": 197.0, "critic_loss": 19.78255972290039, "critic_target_Q_variance_m=2": 7609.45687890625, "critic_Q1_variance_k=2": 0.4865768506526947, "critic_Q2_variance_k=2": 0.48670503997802733, "actor_loss": -174.64216955566405, "actor_mean_entropy": 3.6661269397735596, "alpha_loss": -0.0008967986814677715, "alpha_value": 0.04244412667291691, "duration": 69.21364235877991, "step": 49250}
{"episode_reward": 604.5150435111391, "episode": 198.0, "critic_loss": 19.834667011260986, "critic_target_Q_variance_m=2": 7665.0467109375, "critic_Q1_variance_k=2": 0.4932043707370758, "critic_Q2_variance_k=2": 0.49550445210933686, "actor_loss": -175.29098498535157, "actor_mean_entropy": 3.768069314956665, "alpha_loss": 0.0053080295231193305, "alpha_value": 0.042362604398069936, "duration": 69.17352223396301, "step": 49500}
{"episode_reward": 586.9730152255123, "episode": 199.0, "critic_loss": 19.862430488586426, "critic_target_Q_variance_m=2": 7714.318650390625, "critic_Q1_variance_k=2": 0.5009425628185272, "critic_Q2_variance_k=2": 0.5006101506948472, "actor_loss": -175.88761791992187, "actor_mean_entropy": 3.661960693359375, "alpha_loss": -0.004379376144148409, "alpha_value": 0.04232779627122003, "duration": 69.21680545806885, "step": 49750}
{"episode_reward": 625.024321079277, "episode": 200.0, "critic_loss": 19.990342372894286, "critic_target_Q_variance_m=2": 7761.3468984375, "critic_Q1_variance_k=2": 0.48942286694049836, "critic_Q2_variance_k=2": 0.48035820639133453, "actor_loss": -176.36296923828124, "actor_mean_entropy": 3.678161127090454, "alpha_loss": -0.000303340682759881, "alpha_value": 0.04238709836474465, "duration": 69.26810884475708, "step": 50000}
