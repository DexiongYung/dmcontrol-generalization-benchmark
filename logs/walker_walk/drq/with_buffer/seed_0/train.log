{"episode_reward": 0.0, "episode": 1.0, "duration": 2.580713987350464, "step": 250}
{"episode_reward": 51.702662558795076, "episode": 2.0, "duration": 0.48764824867248535, "step": 500}
{"episode_reward": 64.99570868557767, "episode": 3.0, "duration": 0.4897136688232422, "step": 750}
{"episode_reward": 57.68951042190992, "episode": 4.0, "duration": 0.48970746994018555, "step": 1000}
{"episode_reward": 51.742837732540245, "episode": 5.0, "critic_loss": 0.5140804613472892, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -4.028728642139677, "actor_mean_entropy": 7.771566425088886, "alpha_loss": 0.8787957441021963, "alpha_value": 0.09473849991208792, "duration": 102.05924916267395, "step": 1250}
{"episode_reward": 73.52186927728417, "episode": 6.0, "critic_loss": 1.4028892294168471, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -7.054312278747559, "actor_mean_entropy": 7.617227928161621, "alpha_loss": 0.7352287082672119, "alpha_value": 0.08953430276119861, "duration": 18.19626259803772, "step": 1500}
{"episode_reward": 69.87042279159797, "episode": 7.0, "critic_loss": 1.6579243102073669, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -7.516818725585938, "actor_mean_entropy": 7.597372970581055, "alpha_loss": 0.7160134329795838, "alpha_value": 0.08856930184057388, "duration": 18.13668656349182, "step": 1750}
{"episode_reward": 70.84061172383367, "episode": 8.0, "critic_loss": 2.0658996086120607, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -7.947356388092041, "actor_mean_entropy": 7.501830539703369, "alpha_loss": 0.701209728717804, "alpha_value": 0.0876229146833659, "duration": 18.15211772918701, "step": 2000}
{"episode_reward": 79.68222198490453, "episode": 9.0, "critic_loss": 2.346845208406448, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -8.376623023986816, "actor_mean_entropy": 7.413652725219727, "alpha_loss": 0.6810210342407227, "alpha_value": 0.08668889616921867, "duration": 18.807765007019043, "step": 2250}
{"episode_reward": 53.2889027105752, "episode": 10.0, "critic_loss": 2.337172290802002, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -8.993310920715333, "actor_mean_entropy": 7.454184299468994, "alpha_loss": 0.642645290851593, "alpha_value": 0.08577750513861876, "duration": 18.16800355911255, "step": 2500}
{"episode_reward": 45.817260986590284, "episode": 11.0, "critic_loss": 2.597521734714508, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -9.58714437866211, "actor_mean_entropy": 7.438325252532959, "alpha_loss": 0.6093687527179718, "alpha_value": 0.08490556669688995, "duration": 18.11896800994873, "step": 2750}
{"episode_reward": 82.96886347150206, "episode": 12.0, "critic_loss": 3.0738238830566407, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -10.345832649230957, "actor_mean_entropy": 7.371543453216553, "alpha_loss": 0.5831545855998993, "alpha_value": 0.08406421911060981, "duration": 18.13732671737671, "step": 3000}
{"episode_reward": 94.17695249379702, "episode": 13.0, "critic_loss": 2.7443953561782837, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -11.002877464294434, "actor_mean_entropy": 7.40158032989502, "alpha_loss": 0.5909836769104004, "alpha_value": 0.08322571966866475, "duration": 18.17551279067993, "step": 3250}
{"episode_reward": 157.2066110966791, "episode": 14.0, "critic_loss": 2.9409076194763184, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -11.706378128051758, "actor_mean_entropy": 7.227788200378418, "alpha_loss": 0.593915177822113, "alpha_value": 0.08236025546048914, "duration": 18.188416957855225, "step": 3500}
{"episode_reward": 74.78037308594762, "episode": 15.0, "critic_loss": 3.134221783161163, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -12.348709411621094, "actor_mean_entropy": 7.20294429397583, "alpha_loss": 0.5803015270233154, "alpha_value": 0.08150361157165392, "duration": 18.129533290863037, "step": 3750}
{"episode_reward": 118.53656073250757, "episode": 16.0, "critic_loss": 3.283892674446106, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -13.214043090820313, "actor_mean_entropy": 7.116814094543457, "alpha_loss": 0.5672372558116913, "alpha_value": 0.08065762161084353, "duration": 18.155715227127075, "step": 4000}
{"episode_reward": 112.37388660854717, "episode": 17.0, "critic_loss": 3.1321050276756286, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -14.199817665100097, "actor_mean_entropy": 6.991295314788818, "alpha_loss": 0.5604509809017182, "alpha_value": 0.07980865199332833, "duration": 18.53058433532715, "step": 4250}
{"episode_reward": 114.4567798522371, "episode": 18.0, "critic_loss": 3.211310519218445, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -14.865995307922363, "actor_mean_entropy": 6.799417152404785, "alpha_loss": 0.4944760813713074, "alpha_value": 0.07900014238344064, "duration": 18.194397449493408, "step": 4500}
{"episode_reward": 121.732380553167, "episode": 19.0, "critic_loss": 3.323559132575989, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -15.69174755859375, "actor_mean_entropy": 6.804936546325684, "alpha_loss": 0.4936509141921997, "alpha_value": 0.07824967210003074, "duration": 18.32058024406433, "step": 4750}
{"episode_reward": 123.82309545850883, "episode": 20.0, "critic_loss": 3.509962450504303, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -16.821659034729002, "actor_mean_entropy": 6.700890522003174, "alpha_loss": 0.45742091417312625, "alpha_value": 0.07750499968695394, "duration": 18.274075746536255, "step": 5000}
{"episode_reward": 147.82328919015728, "episode": 21.0, "critic_loss": 3.8943513169288635, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -17.77600538635254, "actor_mean_entropy": 6.730169097900391, "alpha_loss": 0.4592898421287537, "alpha_value": 0.07678514997682616, "duration": 18.245718002319336, "step": 5250}
{"episode_reward": 138.34134636822444, "episode": 22.0, "critic_loss": 4.092371840476989, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -18.423289657592772, "actor_mean_entropy": 6.723909809112548, "alpha_loss": 0.4475824029445648, "alpha_value": 0.07604466087859625, "duration": 18.143826007843018, "step": 5500}
{"episode_reward": 69.249346683717, "episode": 23.0, "critic_loss": 3.763454587936401, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -19.23269302368164, "actor_mean_entropy": 6.5779508781433105, "alpha_loss": 0.4179528934955597, "alpha_value": 0.0753335641690178, "duration": 18.170356512069702, "step": 5750}
{"episode_reward": 118.66000779660274, "episode": 24.0, "critic_loss": 3.73331014585495, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -20.177552703857423, "actor_mean_entropy": 6.568037822723388, "alpha_loss": 0.42041082310676575, "alpha_value": 0.07462361210899068, "duration": 18.19569993019104, "step": 6000}
{"episode_reward": 170.32301860498745, "episode": 25.0, "critic_loss": 4.473978278160096, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -21.175206588745116, "actor_mean_entropy": 6.528577854156494, "alpha_loss": 0.39183809971809386, "alpha_value": 0.07394399724804147, "duration": 18.487818956375122, "step": 6250}
{"episode_reward": 170.08289616653636, "episode": 26.0, "critic_loss": 3.9040515766143797, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -22.039745925903322, "actor_mean_entropy": 6.5469887199401855, "alpha_loss": 0.40336131739616393, "alpha_value": 0.07324825282082358, "duration": 18.212528944015503, "step": 6500}
{"episode_reward": 108.28021395567167, "episode": 27.0, "critic_loss": 4.141654978752136, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -22.6423203125, "actor_mean_entropy": 6.567030155181885, "alpha_loss": 0.39947536277770995, "alpha_value": 0.0725274851342663, "duration": 18.2278995513916, "step": 6750}
{"episode_reward": 180.35072028202688, "episode": 28.0, "critic_loss": 3.951190628528595, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -23.466978073120117, "actor_mean_entropy": 6.610759326934814, "alpha_loss": 0.410353333234787, "alpha_value": 0.07181165165580014, "duration": 18.218305349349976, "step": 7000}
{"episode_reward": 178.96397654400533, "episode": 29.0, "critic_loss": 3.8278714113235472, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -24.217059936523437, "actor_mean_entropy": 6.578480659484863, "alpha_loss": 0.4158479278087616, "alpha_value": 0.07104977466363081, "duration": 18.205683946609497, "step": 7250}
{"episode_reward": 257.7458959675564, "episode": 30.0, "critic_loss": 3.7763637919425963, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -24.932312561035157, "actor_mean_entropy": 6.39139453125, "alpha_loss": 0.40360524225234984, "alpha_value": 0.07031289463097173, "duration": 18.30034375190735, "step": 7500}
{"episode_reward": 221.77753638924202, "episode": 31.0, "critic_loss": 3.8763163671493532, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -25.725483383178712, "actor_mean_entropy": 6.406163623809815, "alpha_loss": 0.3907332789897919, "alpha_value": 0.0695789272389118, "duration": 18.14083170890808, "step": 7750}
{"episode_reward": 251.08329393494444, "episode": 32.0, "critic_loss": 3.6338338980674743, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -26.487117736816405, "actor_mean_entropy": 6.341255832672119, "alpha_loss": 0.37900772333145144, "alpha_value": 0.06886071156550123, "duration": 18.19373106956482, "step": 8000}
{"episode_reward": 187.3044871918024, "episode": 33.0, "critic_loss": 3.7485446982383728, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -27.325018646240235, "actor_mean_entropy": 6.218495094299317, "alpha_loss": 0.3611395835876465, "alpha_value": 0.0681609286415021, "duration": 18.483168601989746, "step": 8250}
{"episode_reward": 303.37258454984146, "episode": 34.0, "critic_loss": 3.8007840900421144, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -28.141697860717773, "actor_mean_entropy": 6.128556652069092, "alpha_loss": 0.3446415948867798, "alpha_value": 0.0674952886553301, "duration": 18.196805238723755, "step": 8500}
{"episode_reward": 290.8390574085636, "episode": 35.0, "critic_loss": 3.7717022337913515, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -28.975362045288087, "actor_mean_entropy": 6.071224227905273, "alpha_loss": 0.33760578322410584, "alpha_value": 0.06683789787512048, "duration": 18.150755167007446, "step": 8750}
{"episode_reward": 241.64741831174663, "episode": 36.0, "critic_loss": 3.9856379566192626, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -29.861674102783205, "actor_mean_entropy": 6.01992244720459, "alpha_loss": 0.3216286565065384, "alpha_value": 0.06619546824878142, "duration": 18.198570728302002, "step": 9000}
{"episode_reward": 217.11961370779647, "episode": 37.0, "critic_loss": 4.521738079071045, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -30.70374201965332, "actor_mean_entropy": 6.011294727325439, "alpha_loss": 0.31107008981704715, "alpha_value": 0.06556624980292222, "duration": 18.175395727157593, "step": 9250}
{"episode_reward": 271.84586737512797, "episode": 38.0, "critic_loss": 4.4655255708694455, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -31.579116149902344, "actor_mean_entropy": 5.965771656036377, "alpha_loss": 0.2933766326904297, "alpha_value": 0.06494718287947222, "duration": 18.210920333862305, "step": 9500}
{"episode_reward": 248.5195224918903, "episode": 39.0, "critic_loss": 4.708955516815186, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -32.50045690917969, "actor_mean_entropy": 5.7981208801269535, "alpha_loss": 0.26526035559177397, "alpha_value": 0.06437451294424118, "duration": 18.164743185043335, "step": 9750}
{"episode_reward": 233.28685324883898, "episode": 40.0, "critic_loss": 4.834714050292969, "critic_target_Q_variance_m=1": 0.0, "critic_Q1_variance_k=1": 0.0, "critic_Q2_variance_k=1": 0.0, "actor_loss": -33.58491510009765, "actor_mean_entropy": 5.6461410827636715, "alpha_loss": 0.2567397756576538, "alpha_value": 0.06382620180678827, "duration": 18.152883529663086, "step": 10000}
